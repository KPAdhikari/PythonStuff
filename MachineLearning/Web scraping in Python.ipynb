{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping in Python\n",
    "\n",
    "**Reference:**\n",
    "* [Web scraping in Python (Part 1/2/3/4): Getting started](https://www.youtube.com/watch?v=r_xb0vF1uMc&list=PL0jQ8OgRoVEXLEKTVlj_5w9I8T1-2g2Bz&index=63) \n",
    "* The NY Times (July 21, 2017) article [Trump's Lies](https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html)\n",
    "* The corresponding [notebook from the tutor](https://github.com/justmarkham/trump-lies)\n",
    "\n",
    "## Contents\n",
    "### Part 1:\n",
    "\n",
    "* What is web scraping?\n",
    "* Exammining the New York Times article\n",
    "    * Examining the HTML\n",
    "    * Fact 1: HTML consists of tags\n",
    "    * Fact 2: Tags can have attributes\n",
    "    * Fact 3: Tags can be nested\n",
    "\n",
    "### Part 2:\n",
    "\n",
    "* Reading the web page into Python\n",
    "* Parsing the HTML using Beautiful Soup\n",
    "    * Collecting all of the records\n",
    "\n",
    "### Part 3:\n",
    "\n",
    "* Parsing the HTML using Beautiful Soup (Continued from above)\n",
    "    * Extracting the date\n",
    "    * Extracting the (Trump) lie(s)\n",
    "    * Extracting the explanation\n",
    "    * Extracting the URL\n",
    "    * Recap: Beautiful Soup methods and attributes\n",
    "\n",
    "### Part 4\n",
    "* Building the dataset\n",
    "    * Applying a tabular data structure\n",
    "    * Exporting the dataset to a CSV file.\n",
    "* Summary: 16 lines of Python code\n",
    "    * Appendix A: Web scraping advice\n",
    "    * Appendix B: Web scraping resources\n",
    "    * Appendix C: Alternative syntax for Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the web page into Python\n",
    "\n",
    "The first thing we need to do is to read the HTML for this article into Python, which we'll do using the requests library. (If you don't have it, you can `pip install requests` from the command line.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<!--[if (gt IE 9)|!(IE)]> <!--><html lang=\"en\" class=\"no-js page-interactive section-opinion page-theme-standard tone-opinion page-interactive-default limit-small layout-xlarge app-interactive\" itemid=\"https://www.nytimes.com/interactive/2017/06/23/opinion/trumps-lies.html\" itemtype=\"http://schema.org/NewsArticle\" itemscope xmlns:og=\"http://opengraphprotocol.org/schema/\"><!--<![endif]-->\n",
      "<!--[if IE 9]> <html lang=\"en\" class=\"no-js ie9 lt-ie10 page-interactive section-opinion page\n"
     ]
    }
   ],
   "source": [
    "# print the first 500 characters of the HTML\n",
    "print(r.text[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named bs4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-113147c4c2fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named bs4"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(r.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

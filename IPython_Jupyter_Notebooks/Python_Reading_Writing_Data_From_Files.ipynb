{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='GoTop'></a>\n",
    "# Contents \n",
    "* [File Operations using Python’s File Object](#FileOperationsUsingFileObject)\n",
    "* [JSON encoding and decoding with Python](#JSONencodingAndDecodingWithPython)\n",
    "* [Reading And Processing Excel Data With Pandas](#ReadingAndProcessingExcelDataWithPandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python — Reading and Writing data from Files\n",
    "Exploring how to read the data from different files like csv, excel, JSON, html and xml.\n",
    "\n",
    "We will first start with Python’s built-in file object and then dive deeper into how to read different types of files using pandas library\n",
    "\n",
    "References:\n",
    "* https://medium.com/datadriveninvestor/python-reading-and-writing-data-from-files-d3b70441416e Written by Renu Khandelwal (Loves learning, sharing and discovering myself. Retail SME and passionate about Machine Learning)\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GoTop](#GoTop) <a id='FileOperationsUsingFileObject'></a>\n",
    "## File Operations using Python’s File Object\n",
    "We will use a file object to which we will pass two arguments — filename and the mode (read, write, append etc) in which we want to operate on the file.\n",
    "\n",
    "    open(Filename,Mode)\n",
    "\n",
    "Different modes are\n",
    "* r : file will be opened in read only mode. This is the default mode\n",
    "* w : file will be opened in write only mode.  If the file does not exists then it will create one and if a file is opened in “w” mode and a file already exists then the existing files content will be overwritten.\n",
    "* a : file will be opened in append mode and the data will be written at the end of the file\n",
    "* r+ : file will be opened in read and write mode\n",
    "\n",
    "Always make sure to close the file after the reading or writing is done.\n",
    "\n",
    "### File Types — Text and Binary\n",
    "\n",
    "Files are opened in text mode by default that allows you to read and write data as strings of text.\n",
    "\n",
    "If you want to open the file in the binary mode then append “b” to the mode.\n",
    "\n",
    "### Opening file in write only mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just opened and wrote 'This is a test file created by open() method (in 'w' mode) of 'file' object.\n",
      " to the 'file_1.txt' file.\n"
     ]
    }
   ],
   "source": [
    "filename = 'file_1.txt'\n",
    "file = open(filename, \"w\") #Creates new one if the file doesn't exist already\n",
    "text2write = \"This is a test file created by open() method (in 'w' mode) of 'file' object.\\n\"\n",
    "file.write(text2write)\n",
    "print(\"Just opened and wrote '\" + text2write + \" to the '\" + filename + \"' file.\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have written the data, we will read the contents of the file\n",
    "\n",
    "### Reading the file in read only mode\n",
    "\n",
    "**readline()** reads a single line from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test file created by open() method (in 'w' mode) of 'file' object.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"file_1.txt\", \"r\")\n",
    "str1 = file.readline()\n",
    "print(str1)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to the file in append mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"file_1.txt\", \"a\")\n",
    "file.write(\"This should be written at the end of the file\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the file in “r+” mode and reading all its content\n",
    "kp: **readlines()** seems to read all lines from the file and return an array of strings, with each element of the array containing a line of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test file created by open() method (in 'w' mode) of 'file' object.\n",
      "\n",
      "This should be written at the end of the file\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file = open(\"file_1.txt\", \"r+\")\n",
    "for str1 in file.readlines():\n",
    "    print(str1)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file with 'with statement'\n",
    "\n",
    "**With is a cleaner way** to work with file objects as **it does exception handling**. With statement **does automatic opening and closing of files so that you do not need to remember to close the file**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This is a test file created by open() method (in 'w' mode) of 'file' object.\\n\", 'This should be written at the end of the file\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"file_1.txt\") as file:\n",
    "    print(file.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also write the data to a file using with statement.** Since we have used “w” mode the existing files content will be overwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"This is a test file created by open() method (in 'w' mode) of 'file' object.\\n\", 'This should be written at the end of the file\\n', 'This line was appended using a with statement.\\n']\n"
     ]
    }
   ],
   "source": [
    "#with open(\"file_1.txt\", \"w\") as file:\n",
    "with open(\"file_1.txt\", \"a\") as file:\n",
    "    file.write(\"This line was appended using a with statement.\\n\")\n",
    "    \n",
    "with open(\"file_1.txt\", \"r\") as file:    \n",
    "    print(file.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will now use pandas library to read a comma separated value(csv) file\n",
    "## Some notes about Dictionary\n",
    "References: https://www.geeksforgeeks.org/add-a-keyvalue-pair-to-dictionary-in-python/, https://www.geeksforgeeks.org/python-dictionary/\n",
    "\n",
    "(\n",
    "\n",
    "kp: [**Dictionary**](https://www.geeksforgeeks.org/python-dictionary/) is a data structure consisting of **key-value** pairs. In a Python dictionary, each key-value pair is separated by a colon ':', whereas each key is separated by a 'comma'.\n",
    "In Python, a Dictionary can be created by placing sequence of elements within curly {} braces, separated by ‘comma’. Dictionary holds a pair of values, one being the Key and the other corresponding pair element being its Key:value. Values in a dictionary can be of any datatype and can be duplicated, whereas keys can’t be repeated and must be immutable.\n",
    "\n",
    "Dictionary can also be created by the built-in function dict(). An empty dictionary can be created by just placing to curly braces{}.\n",
    "\n",
    "**Note** – Dictionary keys are case sensitive, same name but different cases of Key will be treated distinctly.\n",
    "\n",
    "A Dictionary in Python works similar to the Dictionary in a real world. Keys of a Dictionary must be unique and of immutable data type such as Strings, Integers and tuples, but the key-values can be repeated and be of any type.\n",
    "\n",
    "**Note** – Keys in a dictionary doesn’t allows Polymorphism.\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty Dictionary: \n",
      "{}\n",
      "\n",
      "Dictionary with the use of Integer Keys: \n",
      "{1: 'Geeks', 2: 'For', 3: 'Geeks'}\n",
      "\n",
      "Dictionary with the use of Mixed Keys: \n",
      "{'Name': 'Geeks', 1: [1, 2, 3, 4]}\n",
      "\n",
      "Dictionary with the use of dict(): \n",
      "{1: 'Geeks', 2: 'For', 3: 'Geeks'}\n",
      "\n",
      "Dictionary with each item as a pair: \n",
      "{1: 'Geeks', 2: 'For'}\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty Dictionary \n",
    "Dict = {} \n",
    "print(\"Empty Dictionary: \") \n",
    "print(Dict) \n",
    "  \n",
    "# Creating a Dictionary  \n",
    "# with Integer Keys \n",
    "Dict = {1: 'Geeks', 2: 'For', 3: 'Geeks'} \n",
    "print(\"\\nDictionary with the use of Integer Keys: \") \n",
    "print(Dict) \n",
    "  \n",
    "# Creating a Dictionary  \n",
    "# with Mixed keys \n",
    "Dict = {'Name': 'Geeks', 1: [1, 2, 3, 4]} \n",
    "print(\"\\nDictionary with the use of Mixed Keys: \") \n",
    "print(Dict) \n",
    "  \n",
    "# Creating a Dictionary \n",
    "# with dict() method \n",
    "Dict = dict({1: 'Geeks', 2: 'For', 3:'Geeks'}) \n",
    "print(\"\\nDictionary with the use of dict() method: \") \n",
    "print(Dict) \n",
    "  \n",
    "# Creating a Dictionary \n",
    "# with each item as a Pair \n",
    "Dict = dict([(1, 'Geeks'), (2, 'For')]) \n",
    "print(\"\\nDictionary with each item as a pair: \") \n",
    "print(Dict) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to a csv file and reading from a csv file\n",
    "\n",
    "We will first create some data in a dictionary called data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Name': ['Jack', 'Jill', 'Em', 'David'],\n",
       " 'Profession': ['Manager', 'Analyst', 'Data scientist', 'VP'],\n",
       " 'Experience': [10, 5, 2, 20],\n",
       " 'Education': ['MBA', 'BS', 'MS', 'MBA']}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data ={\"Name\":['Jack', 'Jill', 'Em', 'David'],\n",
    "           \"Profession\":['Manager', 'Analyst', 'Data scientist', 'VP'],\n",
    "           \"Experience\":[10,5,2,20],\n",
    "           \"Education\":['MBA', 'BS', 'MS','MBA']}\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a dataframe “df” from the dictionary and then write the data from dataframe to a csv file — “emp.csv”.\n",
    "\n",
    "For creating a dataframe we need to import pandas library first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/Desktop/BigFls/CLAS12/GitProj/KPAdhikari/PythonStuff/IPython_Jupyter_Notebooks\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"pandas_employees.csv\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file will be created in your default Jupyter directory. To know the default directory, use **!pwd** which prints working directory and you can find the new file “pandas_employees.csv”.\n",
    "\n",
    "kp: When I checked the file, I saw the following in it:\n",
    "```\n",
    ",Name,Profession,Experience,Education\n",
    "0,Jack,Manager,10,MBA\n",
    "1,Jill,Analyst,5,BS\n",
    "2,Em,Data scientist,2,MS\n",
    "3,David,VP,20,MBA\n",
    "```\n",
    "Now that we have written the data to a csv file, let’s read the data from csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Manager</td>\n",
       "      <td>10</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jill</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>5</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Em</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>2</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>David</td>\n",
       "      <td>VP</td>\n",
       "      <td>20</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Name      Profession  Experience Education\n",
       "0           0   Jack         Manager          10       MBA\n",
       "1           1   Jill         Analyst           5        BS\n",
       "2           2     Em  Data scientist           2        MS\n",
       "3           3  David              VP          20       MBA"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data = pd.read_csv(\"pandas_employees.csv\")\n",
    "csv_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data type for csv_data is a dataframe. so we can use all of the dataframe operations. (To know more about [dataframe](https://medium.com/@arshren/python-data-structures-dataframe-888fef6872bf) and [dictionary](https://medium.com/@arshren/python-data-structures-dictionary-9b746b94b421).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to an excel file and reading from an excel file\n",
    "\n",
    "Here we will use the same df dataframe to write the data to an excel file in a sheet name “employee_name”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"pandas_employees.xls\",sheet_name =\"employee_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, above line didn't work giving me \"ImportError: No Module named xlwt\". So, I googled about it and [this](https://stackoverflow.com/questions/9848299/importerror-no-module-named-xlwt) forum guided me to do the following, after which it seemed to work.\n",
    "```\n",
    "KPAd's FunPrompt $ pip3 install xlwt\n",
    "Collecting xlwt\n",
    "  Downloading https://files.pythonhosted.org/packages/44/48/def306413b25c3d01753603b1a222a011b8621aed27cd7f89cbc27e6b0f4/xlwt-1.3.0-py2.py3-none-any.whl (99kB)\n",
    "     |████████████████████████████████| 102kB 1.3MB/s \n",
    "Installing collected packages: xlwt\n",
    "Successfully installed xlwt-1.3.0\n",
    "KPAd's FunPrompt $\n",
    "```\n",
    "Finally, it worked and it did produce above .xls file, which I was able to open with the MS-Excel that showed the following in 5 rows and 5 columns:\n",
    "```\n",
    "\tName\tProfession\t    Experience\tEducation\n",
    "0\tJack\tManager\t        10\t        MBA\n",
    "1\tJill\tAnalyst\t        5\t        BS\n",
    "2\tEm\t    Data scientist\t2\t        MS\n",
    "3\tDavid\tVP\t            20\t        MBA\n",
    "```\n",
    "But, when I tried to open it in the browser (within the notebook server) by simply clicking the file name, it open a new tab with the following message (which is okay, because, I think it can only open **txt, csv, json** files that way (means in the human readable way).):\n",
    "```\n",
    "Error! /Users/kpadhikari/Desktop/BigFls/CLAS12/GitProj/KPAdhikari/PythonStuff/IPython_Jupyter_Notebooks/pandas_employees.xls is not UTF-8 encoded\n",
    "Saving disabled.\n",
    "See Console for more details.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let’s read the data from the excel file** pandas_employees.xls, with sheet name **“employee_data”** into a dataframe xls_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jack</td>\n",
       "      <td>Manager</td>\n",
       "      <td>10</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jill</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>5</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Em</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>2</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>David</td>\n",
       "      <td>VP</td>\n",
       "      <td>20</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Name      Profession  Experience Education\n",
       "0           0   Jack         Manager          10       MBA\n",
       "1           1   Jill         Analyst           5        BS\n",
       "2           2     Em  Data scientist           2        MS\n",
       "3           3  David              VP          20       MBA"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xls_data = pd.read_excel(\"pandas_employees.xls\", sheetname =\"employee_data\")\n",
    "#kp: TypeError: read_excel() got an unexpected keyword argument `sheetname`\n",
    "#\n",
    "#xls_data = pd.read_excel(\"pandas_employees.xls\")\n",
    "#kp: ImportError: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.\n",
    "#\n",
    "xls_data = pd.read_excel(\"pandas_employees.xls\", sheet_name =\"employee_data\")\n",
    "#kp: Without the \"xlrd\" installed, I kept on getting following error.\n",
    "#kp: ImportError: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.\n",
    "#\n",
    "xls_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I kept on getting `ImportError: Missing optional dependency 'xlrd'. Install xlrd >= 1.0.0 for Excel support Use pip or conda to install xlrd.` so, I did the following to get above code working.\n",
    "```\n",
    "KPAd's FunPrompt $ pip3 install xlrd\n",
    "Collecting xlrd\n",
    "  Downloading https://files.pythonhosted.org/packages/b0/16/63576a1a001752e34bf8ea62e367997530dc553b689356b9879339cf45a4/xlrd-1.2.0-py2.py3-none-any.whl (103kB)\n",
    "     |████████████████████████████████| 112kB 2.0MB/s \n",
    "Installing collected packages: xlrd\n",
    "Successfully installed xlrd-1.2.0\n",
    "KPAd's FunPrompt $ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing data to a JSON file\n",
    "\n",
    "Here we will use the same dataframe df to write to a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('pandas_employees.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contents of the emp.json file\n",
    "\n",
    "{“Education”:{“0”:”MBA”,”1\":”BS”,”2\":”MS”,”3\":”MBA”},”Experience”:{“0”:10,”1\":5,”2\":2,”3\":20},”Name”:{“0”:”Jack”,”1\":”Jill”,”2\":”Em”,”3\":”David”},”Profession”:{“0”:”Manager”,”1\":”Analyst”,”2\":”Data scientist”,”3\":”VP”}}\n",
    "\n",
    "Now that we have written the data to a json file, let’s read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jack</td>\n",
       "      <td>Manager</td>\n",
       "      <td>10</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jill</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>5</td>\n",
       "      <td>BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Em</td>\n",
       "      <td>Data scientist</td>\n",
       "      <td>2</td>\n",
       "      <td>MS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>VP</td>\n",
       "      <td>20</td>\n",
       "      <td>MBA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name      Profession  Experience Education\n",
       "0   Jack         Manager          10       MBA\n",
       "1   Jill         Analyst           5        BS\n",
       "2     Em  Data scientist           2        MS\n",
       "3  David              VP          20       MBA"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp= pd.read_json(\"pandas_employees.json\")\n",
    "emp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a json object then we can put the contents to a List using **json.loads()** and then use all operation of a list for data manipulation.\n",
    "\n",
    "Read here for operation of a [List](https://medium.com/@arshren/python-data-structures-list-9131e7386c8d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'office': {'medical': [{'room-number': 100,\n",
       "    'use': 'reception',\n",
       "    'sq-ft': 50,\n",
       "    'price': 75},\n",
       "   {'room-number': 101, 'use': 'waiting', 'sq-ft': 250, 'price': 75},\n",
       "   {'room-number': 102, 'use': 'examination', 'sq-ft': 125, 'price': 150},\n",
       "   {'room-number': 103, 'use': 'examination', 'sq-ft': 125, 'price': 150},\n",
       "   {'room-number': 104, 'use': 'office', 'sq-ft': 150, 'price': 100}]},\n",
       " 'parking': {'location': 'premium', 'style': 'covered', 'price': 750}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "area_json =\"\"\"\n",
    "{ \"office\": \n",
    "    {\"medical\": [\n",
    "      { \"room-number\": 100,\n",
    "        \"use\": \"reception\",\n",
    "        \"sq-ft\": 50,\n",
    "        \"price\": 75\n",
    "      },\n",
    "      { \"room-number\": 101,\n",
    "        \"use\": \"waiting\",\n",
    "        \"sq-ft\": 250,\n",
    "        \"price\": 75\n",
    "      },\n",
    "      { \"room-number\": 102,\n",
    "        \"use\": \"examination\",\n",
    "        \"sq-ft\": 125,\n",
    "        \"price\": 150\n",
    "      },\n",
    "      { \"room-number\": 103,\n",
    "        \"use\": \"examination\",\n",
    "        \"sq-ft\": 125,\n",
    "        \"price\": 150\n",
    "      },\n",
    "      { \"room-number\": 104,\n",
    "        \"use\": \"office\",\n",
    "        \"sq-ft\": 150,\n",
    "        \"price\": 100\n",
    "      }\n",
    "    ]},\n",
    "    \n",
    "    \"parking\": {\n",
    "      \"location\": \"premium\",\n",
    "      \"style\": \"covered\",\n",
    "      \"price\": 750\n",
    "    }\n",
    "} \n",
    "\"\"\"\n",
    "home_data = json.loads(area_json)\n",
    "home_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kp Note:** Initially, I didn't have 'import json' in above code. I got that idea from [this](https://stackoverflow.com/questions/42987068/global-name-json-is-not-defined/42987108) forum, because, initially, I was getting the error: **name 'json' is not defined**, so I had to google about it. Before this site, I went to [another forum](https://stackoverflow.com/questions/41001973/python-3-5-1-nameerror-name-json-is-not-defined) which was saying the following:\n",
    "```\n",
    "You should at first install simplejson to your system to be able to import it:\n",
    "\n",
    "   sudo pip3 install simplejson\n",
    "\n",
    "Then in your code you are now able to import it:\n",
    "\n",
    "   import simplejson as json\n",
    "\n",
    "From now on you will be able to access simplejson package using json.\n",
    "```\n",
    "But, I got the feeling that json may already be a part of pandas and so I googled further about it and it seems I was right. I already had the 'json' in my thing but "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can also use a python data and dump into a json object.\n",
    "\n",
    "Here we will use the data dictionary that we created earlier and dump as json data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Name\": [\"Jack\", \"Jill\", \"Em\", \"David\"], \"Profession\": [\"Manager\", \"Analyst\", \"Data scientist\", \"VP\"], \"Experience\": [10, 5, 2, 20], \"Education\": [\"MBA\", \"BS\", \"MS\", \"MBA\"]}'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data = json.dumps(data)\n",
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data from a URL\n",
    "\n",
    "we will use two libraries for retrieving data from a URL — **request and beautifulsoup**. we will also use **re** to use **regular expression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kp:** Initially, I got `ModuleNotFoundError: No module named 'bs4'` error below. But, it worked once I installed 'bs4' as follows:\n",
    "```\n",
    "KPAd's FunPrompt $ pip3 install bs4\n",
    "Collecting bs4\n",
    "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
    "Collecting beautifulsoup4 (from bs4)\n",
    "  Downloading https://files.pythonhosted.org/packages/1a/b7/34eec2fe5a49718944e215fde81288eec1fa04638aa3fb57c1c6cd0f98c3/beautifulsoup4-4.8.0-py3-none-any.whl (97kB)\n",
    "     |████████████████████████████████| 102kB 1.9MB/s \n",
    "Collecting soupsieve>=1.2 (from beautifulsoup4->bs4)\n",
    "  Downloading https://files.pythonhosted.org/packages/0b/44/0474f2207fdd601bb25787671c81076333d2c80e6f97e92790f8887cf682/soupsieve-1.9.3-py2.py3-none-any.whl\n",
    "Building wheels for collected packages: bs4\n",
    "  Building wheel for bs4 (setup.py) ... done\n",
    "  Stored in directory: /Users/kpadhikari/Library/Caches/pip/wheels/a0/b0/b2/4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
    "Successfully built bs4\n",
    "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
    "Successfully installed beautifulsoup4-4.8.0 bs4-0.0.1 soupsieve-1.9.3\n",
    "KPAd's FunPrompt $ \n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the url from [one of my posts](https://medium.com/@arshren/power-of-habit-how-to-accomplishing-big-goals-by-making-small-changes-5872a788fcb8) on medium and retrieve the text. we use the get method of request library to download the page. response will now have the content of the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kp: 'url' below is just the string object variable.\n",
    "url = \"https://medium.com/@arshren/power-of-habit-how-to-accomplishing-big-goals-by-making-small-changes-5872a788fcb8\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**response.content** will contain the contents of the html page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kp: I disabled the following line to reduce the size of the saved file (from about 144 kB to 34 kB)\n",
    "#response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use Beautifulsoup constructor and pass the html content that we have in response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content,'html.parser')\n",
    "#kp: Running this code didn't increase the file size, \n",
    "#    so the content of the URL is not really loaded yet (perhaps just some reference or pointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will now extract the Title by using the find method and then use get_text to extract the title.\n",
    "\n",
    "we then find all the “p” tags in the html page with class property containing text like “graf graf — p”. Here we use regular expression as we want to find class property for the p tag with values like “graf graf — p”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "title  = soup.find('title').get_text()\n",
    "\n",
    "#any_data = soup.find_all('p', class_=re.compile(\"graf graf--p\")) #kp: didn't give anything\n",
    "any_data = soup.find_all('div', class_=re.compile(\"ar\"))          #kp: this one worked (see print-loop result below)\n",
    "#any_data2 = soup.find_all('section', class_=re.compile(\"ar\"))    #kp: didn't work\n",
    "any_data3 = soup.find_all('style', type_=re.compile(\"text/css\"))  #kp: didn't work\n",
    "any_data4 = soup.find_all('meta', property_=re.compile(\"og\"))     #kp: this too didn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will now iterate through any_data, which is a Resultset of bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power of Habit — How to accomplish big goals by making small changes\n"
     ]
    }
   ],
   "source": [
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in any_data4:\n",
    "   print(p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Become a memberSign inGet started\n",
      "\n",
      "Become a memberSign inGet started\n",
      "Become a memberSign in\n",
      "Renu KhandelwalFollowAug 13, 2018 · 4 min read\n",
      "Renu KhandelwalFollow\n",
      "Renu KhandelwalFollow\n",
      "59 \n",
      "59 \n",
      "59 \n",
      "Self ImprovementHabitsReadingMotivationInspirational59 clapsWritten byRenu KhandelwalFollowLoves learning, sharing and discovering myself. Retail SME and passionate about Machine LearningFollowWrite the first response\n",
      "Self ImprovementHabitsReadingMotivationInspirational59 clapsWritten byRenu KhandelwalFollowLoves learning, sharing and discovering myself. Retail SME and passionate about Machine LearningFollowWrite the first response\n",
      "\n",
      "\n",
      "59 claps\n",
      "59 claps\n",
      "\n",
      "\n",
      "\n",
      "Renu KhandelwalFollow\n",
      "Renu KhandelwalFollow\n",
      "\n",
      "Discover MediumWelcome to a place where words matter. On Medium, smart voices and original ideas take center stage - with no ads in sight. WatchMake Medium yoursFollow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox. ExploreBecome a memberGet unlimited access to the best stories on Medium — and support writers while you’re at it. Just $5/month. Upgrade\n",
      "Discover MediumWelcome to a place where words matter. On Medium, smart voices and original ideas take center stage - with no ads in sight. WatchMake Medium yoursFollow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox. ExploreBecome a memberGet unlimited access to the best stories on Medium — and support writers while you’re at it. Just $5/month. Upgrade\n",
      "AboutHelpLegal\n",
      "AboutHelpLegal\n"
     ]
    }
   ],
   "source": [
    "for p in any_data:\n",
    "   print(p.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://stackoverflow.com/questions/26435689/how-to-use-re-compile-with-class-in-beautifulsoup\n",
    "\n",
    "According to ([Beautiful Soup documentation - Search by CSS class](http://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-by-css-class)), if you want to search for tags that match two or more CSS classes, you should use a CSS selector.\n",
    "\n",
    "soup.select('.mod.result')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop through directories looking for TXT files\n",
    "Reference: https://stackoverflow.com/questions/13299731/python-need-to-loop-through-directories-looking-for-txt-files\n",
    "Q: I need to loop through a directory looking for .txt files, and then read and process them individually. I would like to set this up so that whatever directory the script is in is treated as the root of this action. For example if the script is in /bsepath/workDir, then it would loop over all of the files in workDir and its children.\n",
    "\n",
    "Other references:\n",
    "* https://stackoverflow.com/questions/10377998/how-can-i-iterate-over-files-in-a-given-directory \n",
    "* https://stackoverflow.com/questions/11726349/python-looping-through-input-file\n",
    "* https://stackoverflow.com/questions/16129652/accessing-json-elements\n",
    "* https://stackoverflow.com/questions/10986065/looping-over-filenames-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "\n",
    "def findFiles (path, filter):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in fnmatch.filter(files, filter):\n",
    "            yield os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use it like this, and it will find all text files somewhere within the given path (recursively):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for textFile in findFiles(r'C:\\Users\\poke\\Documents', '*.txt'):\n",
    "for textFile in findFiles(r'/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data', '*.json'):  \n",
    "    print(textFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Wouters-2015/Wouters-2015-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Gueulette-1996/Gueulette-1996-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Folkard-1996/Folkard-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Folkard-1996/Folkard-1996-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Belli-2000/Belli-2000-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Butterworth-2012/Butterworth-2012.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Britten-2013/Britten-2013-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Chaudhary-2014/Chaudhary-2014.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Tang-1997/Tang-1997-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Schuff-2002/Schuff-2002-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Ando-2001/Ando-2001-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Calugaru-2011/Calugaru-2011-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Belli-1998/Belli-1998-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Matsumoto-2014/Matsumoto-2014-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Hei-1988/Hei-1988-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Howard-2017/Howard-2017-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Howard-2018/ijpt-04-03-06_s02.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Howard-2018/Howard-2018-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Wouters-1996/Wouters-1996-Fig5a-photons-Co60-V79-WNRE-Win8.1.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Folkard-1989/Folkard-1989-residuals.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Grosse-2014/Grosse-2014.txt\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Bettega-1998/Bettega-1998-residuals.txt\n"
     ]
    }
   ],
   "source": [
    "for textFile in findFiles(r'/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data', '*.txt'):  \n",
    "    print(textFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Aoki-Nakano-2014/kpProducedFile.csv\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Aoki-Nakano-2014/tryingAgain.json.csv\n"
     ]
    }
   ],
   "source": [
    "for textFile in findFiles(r'/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data', '*.csv'):  \n",
    "    print(textFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kp: Following also works but I am disabling it because I want to minimize the size of this file because it\n",
    "#    prints a lot of file names as there are a lot of them with .dat extension.\n",
    "#\n",
    "# for textFile in findFiles(r'/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data', '*.dat'):  \n",
    " #   print(textFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Coutrakon-1997/Coutrakon-1997.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Gueulette-1997/Gueulette-1997.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Slonina-2014/Slonina-2014.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Robertson-1994/Robertson-1994.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Hering-1986/Hering-1986.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Marshall-2016/Marshall-2016.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Wouters-2015/Wouters-2015.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Gueulette-1996/Gueulette-1996.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Aoki-Nakano-2014/Aoki-Nakano-2014.pdf\n",
      "/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data/Ibanez-2009/Ibanez-2009.pdf\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for textFile in findFiles(r'/Users/kpadhikari/Box Sync/KpDocuments/EVMSpostdocRelated/RBE-Data', '*.pdf'):  \n",
    "    if i < 10:\n",
    "        print(textFile)\n",
    "    i+=1  #Equivalent to i++ or i = i+1 in C/C++/Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3B-protons-60MeV-HFIB15.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3B-photons-6MV-HFIB15.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3A-protons-60MeV-HFIB2.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3B-protons-200MeV-line-5.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-photons-C060-line-C.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-2-sff.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3B-protons-200MeV-line-8.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3B-protons-200MeV-line-4.json\n",
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3B-protons-200MeV-line-4-sff.json\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for textFile in findFiles(r'/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff', '*.json'):  \n",
    "    if j < 10:\n",
    "        print(textFile)\n",
    "    j+=1  #Equivalent to i++ or i = i+1 in C/C++/Java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://linuxconfig.org/how-to-parse-data-from-json-into-python\n",
    "import json\n",
    "json_data = '{\"a\": 1, \"d\": 4, \"e\": 5, \"b\": 2, \"c\": 3 }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python uses the **loads** method from the **json** to load JSON from a string. Did you notice the quotes around that dictionary that you created for the JSON? That's because Python treats JSON as a string unless it's coming from a file. You don't really need to worry about it too much. Just know that this form handles data while **load** handles files. Try to load and print the JSON data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"a\": 1,\n",
      "    \"b\": 2,\n",
      "    \"c\": 3,\n",
      "    \"d\": 4,\n",
      "    \"e\": 5\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "parsed_json = (json.loads(json_data))\n",
    "print(json.dumps(parsed_json, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It won't look much different, but Python sees it in a usable form now. You can save it to a variable and iterate over it to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 1\n",
      "d: 4\n",
      "e: 5\n",
      "b: 2\n",
      "c: 3\n"
     ]
    }
   ],
   "source": [
    "loaded_json = json.loads(json_data)\n",
    "for x in loaded_json:\n",
    "\tprint(\"%s: %d\" % (x, loaded_json[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, loaded_json contains a dictionary, not a string that looks like one. \n",
    "### Parse To An Object\n",
    "JSON is actually an object in JavaScript, so it would make sense to want to import it as an object in Python. There are a few ways to do this, but most involve creating a class that you instantiate by populating it with data from the JSON. There really isn't a direct conversion.\n",
    "\n",
    "There is a fairly direct way to do it by loading the JSON into an object's **`__`dict`__`** property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "class Test(object):\n",
    "    def __init__(self, data):\n",
    "\t    self.__dict__ = json.loads(data)\n",
    "\n",
    "test1 = Test(json_data)\n",
    "print(test1.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse a JSON File\n",
    "You're really not going to need to parse JSON from within a Python program. That doesn't make much sense in practicality. You will need to read and parse it from files, though, and that's why you set up that [distros.json](distros.json) file.\n",
    "\n",
    "A **with** can simplify the process of reading and closing the file, so that's the structure to use here. The other thing to note is the **load** method replaces **loads** because this is a file. Otherwise, the process is mostly the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debian\n",
      "Ubuntu\n",
      "Fedora\n",
      "CentOS\n",
      "OpenSUSE\n",
      "Arch Linux\n",
      "Gentoo\n"
     ]
    }
   ],
   "source": [
    "with open('distros.json', 'r') as f:\n",
    "    distros_dict = json.load(f)\n",
    "\n",
    "for distro in distros_dict:\n",
    "    print(distro['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing one of the files provided by Dr. Pawel Ambrozewicz\n",
    "The file looks as follows:\n",
    "```\n",
    "{\n",
    "    \"Data\": {\n",
    "        \"dose_data\": \"0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86\",\n",
    "        \"error_data\": \"0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001\",\n",
    "        \"survival_data\": \"0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471\"\n",
    "    },\n",
    "    \"Experiment\": {\n",
    "        \"Biophysical_info\": {\n",
    "            \"cell_line\": \"HFIB2\",\n",
    "            \"energy\": \"6MV\",\n",
    "            \"let\": \"-keV/$\\\\mu$m\",\n",
    "            \"modality\": \"photons\"\n",
    "        },\n",
    "        \"Original_values\": {\n",
    "            \"alpha\": \"0.689\",\n",
    "            \"alpha_X\": \"0.689\",\n",
    "            \"alpha_X_err\": \"0.164\",\n",
    "            \"alpha_err\": \"0.164\",\n",
    "            \"beta\": \"0.041\",\n",
    "            \"beta_X\": \"0.041\",\n",
    "            \"beta_X_err\": \"0.015\",\n",
    "            \"beta_err\": \"0.015\"\n",
    "        },\n",
    "        \"Publication\": {\n",
    "            \"author\": \"Slonina\",\n",
    "            \"year\": \"2014\"\n",
    "        }\n",
    "    },\n",
    "    \"Header\": {\n",
    "        \"created_by\": \"Plot Digitizer     2.6.8\",\n",
    "        \"date\": \"Date: 3/10/18     7:52:58 AM\",\n",
    "        \"dependence\": \"SF(Dose (Gy))\",\n",
    "        \"user\": \"pawel\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://stackoverflow.com/questions/33984903/json-decoder-jsondecodeerror-expecting-value-line-1-column-1-char-0\n",
    "\n",
    "json.loads() takes a JSON encoded string, not a filename. You want to use json.load() (no s) instead and pass in an open file object:\n",
    "\n",
    "with open('/Users/JoshuaHawley/clean1.txt') as jsonfile:\n",
    "    data = json.load(jsonfile)\n",
    "\n",
    "The open() command produces a file object that json.load() can then read from, to produce the decoded Python object for you. The with statement ensures that the file is closed again when done.\n",
    "\n",
    "The alternative is to read the data yourself and then pass it into json.loads().\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3B-photons-6MV-HFIB15.json  has a size of  1291 \n",
      "\n",
      "Data : {'dose_data': '0.9371 0.9317 0.9373 1.9201 1.9165 1.9203 2.9232 2.8958 2.9106 3.9063 3.8953 3.8937 4.8786 5.8836 5.8837 5.8784 5.8767 7.8647 7.8633 7.8672', 'error_data': '0.0443 0.0586 0.0616 0.0337 0.0268 0.0284 0.0130 0.0309 0.0116 0.0043 0.0095 0.0017 0.0030 0.0015 0.0009 0.0008 0.0010 0.0001 0.0001 0.0001', 'survival_data': '0.6168 0.5441 0.4614 0.2673 0.2327 0.1916 0.1455 0.1039 0.0816 0.052 0.0425 0.0331 0.0117 0.0058 0.0045 0.0033 0.0026 0.0005 0.0002 0.0001'}\n",
      "\n",
      "\n",
      "dose_data : 0.9371 0.9317 0.9373 1.9201 1.9165 1.9203 2.9232 2.8958 2.9106 3.9063 3.8953 3.8937 4.8786 5.8836 5.8837 5.8784 5.8767 7.8647 7.8633 7.8672\n",
      "error_data : 0.0443 0.0586 0.0616 0.0337 0.0268 0.0284 0.0130 0.0309 0.0116 0.0043 0.0095 0.0017 0.0030 0.0015 0.0009 0.0008 0.0010 0.0001 0.0001 0.0001\n",
      "survival_data : 0.6168 0.5441 0.4614 0.2673 0.2327 0.1916 0.1455 0.1039 0.0816 0.052 0.0425 0.0331 0.0117 0.0058 0.0045 0.0033 0.0026 0.0005 0.0002 0.0001\n",
      "Experiment : {'Biophysical_info': {'cell_line': 'HFIB15', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons'}, 'Original_values': {'alpha': '0.627', 'alpha_X': '0.627', 'alpha_X_err': '0.028', 'alpha_err': '0.028', 'beta': '0.048', 'beta_X': '0.048', 'beta_X_err': '0.014', 'beta_err': '0.014'}, 'Publication': {'author': 'Slonina', 'year': '2014'}}\n",
      "\n",
      "\n",
      "Biophysical_info : {'cell_line': 'HFIB15', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons'}\n",
      "key:  Biophysical_info\n",
      "\n",
      "All values of an Inner Dictionary:    HFIB15  6MV  -keV/$\\mu$m  photons \n",
      "\n",
      "Original_values : {'alpha': '0.627', 'alpha_X': '0.627', 'alpha_X_err': '0.028', 'alpha_err': '0.028', 'beta': '0.048', 'beta_X': '0.048', 'beta_X_err': '0.014', 'beta_err': '0.014'}\n",
      "Publication : {'author': 'Slonina', 'year': '2014'}\n",
      "Header : {'created_by': 'Plot Digitizer 2.6.8', 'date': 'Date: 11/23/18 9:29:45 PM', 'dependence': 'SF(Dose (Gy))', 'user': 'pawel'}\n",
      "\n",
      "\n",
      "created_by : Plot Digitizer 2.6.8\n",
      "date : Date: 11/23/18 9:29:45 PM\n",
      "dependence : SF(Dose (Gy))\n",
      "user : pawel\n"
     ]
    }
   ],
   "source": [
    "# https://stackabuse.com/reading-and-writing-json-to-a-file-in-python/\n",
    "# https://stackoverflow.com/questions/16573332/jsondecodeerror-expecting-value-line-1-column-1-char-0?rq=1\n",
    "# https://stackoverflow.com/questions/16573332/jsondecodeerror-expecting-value-line-1-column-1-char-0?rq=1\n",
    "import json\n",
    "import os\n",
    "\n",
    "# This code worked for some of the files and didn't for some others\n",
    "# It kept on reporting \"JSONDecodeError: Expecting value: line 1 column 1 (char 0)\"\n",
    "# etc (for example when trying Slonina-2014/Slonina-2014-Fig3B-protons-60MeV-HFIB15.json)\n",
    "# Therefore, I am trying to find out if pandas would help.\n",
    "#\n",
    "Dir = \"/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/{}\"\n",
    "myJson = Dir.format(\"Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\")\n",
    "myJson = Dir.format(\"Slonina-2014/Slonina-2014-Fig3A-protons-60MeV-HFIB2.json\")\n",
    "myJson = Dir.format(\"Slonina-2014/Slonina-2014-Fig3B-photons-6MV-HFIB15.json\")\n",
    "#myJson = Dir.format(\"Slonina-2014/Slonina-2014-Fig3B-protons-6MeV-HFIB15.json\")\n",
    "#myJson = Dir.format(\"Slonina-2014/Slonina-2014-Fig3B-protons-60MeV-HFIB15.json\")\n",
    "print(\"Input file: \", myJson, \" has a size of \", os.path.getsize(myJson),\"\\n\")\n",
    "printStr = \"\"\n",
    "#with open('data.txt') as json_file:\n",
    "with open(myJson, 'r') as json_file:\n",
    "#with open(myJson,encoding='utf-16', errors='ignore') as json_file:    \n",
    "#with open(myJson,encoding='utf-8', errors='ignore') as json_file:  \n",
    "    data = json.load(json_file)\n",
    "    #if len(json_file.readlines()) != 0:\n",
    "    #    json_file.seek(0)\n",
    "#    if json_file:  #checking whether json_string is empty beforehand:\n",
    "#        data = json.load(json_file)\n",
    "#    else:\n",
    "#        print(myJoson, \"not readable.\")\n",
    "#        #return\n",
    "    \n",
    "# https://stackoverflow.com/questions/6077675/why-am-i-seeing-typeerror-string-indices-must-be-integers\n",
    "# In the given file: we have dictionaries as part of elements in a bigger dictionary.\n",
    "for key, value in data.items():  #works\n",
    "    print(key,\":\", value) #works   \n",
    "    print(\"\\n\")\n",
    "    for k, v in value.items():\n",
    "        #printStr = printStr + \" \" + v #TypeError: can only concatenate str (not \"dict\") to str\n",
    "        print(k,\":\", v)\n",
    "        if k == 'Biophysical_info':\n",
    "            print(\"key: \", k)\n",
    "            for kk, vv in v.items():\n",
    "                printStr = printStr + \"  \" + vv\n",
    "            print(\"\\nAll values of an Inner Dictionary: \", printStr, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "List = []\n",
    "print(List)\n",
    "print(len(List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['str1', 'str2', 'str3', 'str4', 'str5']\n"
     ]
    }
   ],
   "source": [
    "List.clear()\n",
    "for i in [1, 2, 3, 4, 5]:\n",
    "    List.append(\"str\" + str(i))\n",
    "print(List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "['str0', 'str3', 'str6', 'str9', 'str12']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    #List.insert(i,\"str\" + str(3*i))\n",
    "    print(i)\n",
    "    List[i] = \"str\" + str(3*i)\n",
    "   # List[i]\n",
    "print(List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Data': {'dose_data': '0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86', 'error_data': '0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001', 'survival_data': '0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471'}, 'Experiment': {'Biophysical_info': {'cell_line': 'HFIB2', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons'}, 'Original_values': {'alpha': '0.689', 'alpha_X': '0.689', 'alpha_X_err': '0.164', 'alpha_err': '0.164', 'beta': '0.041', 'beta_X': '0.041', 'beta_X_err': '0.015', 'beta_err': '0.015'}, 'Publication': {'author': 'Slonina', 'year': '2014'}}, 'Header': {'created_by': 'Plot Digitizer     2.6.8', 'date': 'Date: 3/10/18     7:52:58 AM', 'dependence': 'SF(Dose (Gy))', 'user': 'pawel'}}\n"
     ]
    }
   ],
   "source": [
    "# 'data' from above 'data = json.load(json_file)' is a dictionary\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dose_data : 0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86\n",
      "error_data : 0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001\n",
      "survival_data : 0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Biophysical_info : {'cell_line': 'HFIB2', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons'}\n",
      "Original_values : {'alpha': '0.689', 'alpha_X': '0.689', 'alpha_X_err': '0.164', 'alpha_err': '0.164', 'beta': '0.041', 'beta_X': '0.041', 'beta_X_err': '0.015', 'beta_err': '0.015'}\n",
      "Publication : {'author': 'Slonina', 'year': '2014'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "created_by : Plot Digitizer     2.6.8\n",
      "date : Date: 3/10/18     7:52:58 AM\n",
      "dependence : SF(Dose (Gy))\n",
      "user : pawel\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This is my List of size:  21\n",
      "['0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86', '0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001', '0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471', 'HFIB2', '6MV', '-keV/$\\\\mu$m', 'photons', '0.689', '0.689', '0.164', '0.164', '0.041', '0.041', '0.015', '0.015', 'Slonina', '2014', 'Plot Digitizer     2.6.8', 'Date: 3/10/18     7:52:58 AM', 'SF(Dose (Gy))', 'pawel']\n",
      "\n",
      "And this is my Dictionary of size:  21\n",
      "{'dose_data': '0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86', 'error_data': '0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001', 'survival_data': '0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471', 'cell_line': 'HFIB2', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons', 'alpha': '0.689', 'alpha_X': '0.689', 'alpha_X_err': '0.164', 'alpha_err': '0.164', 'beta': '0.041', 'beta_X': '0.041', 'beta_X_err': '0.015', 'beta_err': '0.015', 'author': 'Slonina', 'year': '2014', 'created_by': 'Plot Digitizer     2.6.8', 'date': 'Date: 3/10/18     7:52:58 AM', 'dependence': 'SF(Dose (Gy))', 'user': 'pawel'}\n"
     ]
    }
   ],
   "source": [
    "# https://stackabuse.com/reading-and-writing-json-to-a-file-in-python/\n",
    "# https://www.geeksforgeeks.org/python-set-4-dictionary-keywords-python/\n",
    "import json\n",
    "myJson = \"/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\"\n",
    "printStr = \"\"\n",
    "valuesList = [] # new list\n",
    "dic = dict()    # new dictionary\n",
    "#valueList.clear() #not necessary\n",
    "with open(myJson, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "for key, value in data.items():  \n",
    "    #print(key,\":\", value, \"\\n\\n\")  \n",
    "    #json.dumps(key)\n",
    "        \n",
    "    for k, v in value.items(): \n",
    "        if key == 'Data' or key == 'Header':\n",
    "            valuesList.append(v)\n",
    "            dic[k] = v #This is equivalent to append (it adds a key-value pair to the dictionary)\n",
    "            \n",
    "        #printStr = printStr + \" \" + v #TypeError: can only concatenate str (not \"dict\") to str\n",
    "        print(k,\":\", v)\n",
    "        if key == 'Experiment':\n",
    "            #print(\"key: \", k)\n",
    "            for kk, vv in v.items():\n",
    "                valuesList.append(vv)\n",
    "                dic[kk] = vv\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "print(\"\\nThis is my List of size: \", len(valuesList))    \n",
    "print(valuesList)\n",
    "\n",
    "print(\"\\nAnd this is my Dictionary of size: \", len(dic))\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next ready for creating and writing on an excel file\n",
    "References:\n",
    "* https://www.geeksforgeeks.org/python-create-and-write-on-excel-file-using-xlsxwriter-module/\n",
    "* https://www.geeksforgeeks.org/writing-excel-sheet-using-python/\n",
    "* https://stackoverflow.com/questions/53224690/how-to-write-json-text-to-excel-file\n",
    "\n",
    "#### Installing 'xlsxwriter' and 'xlwt'\n",
    "```\n",
    "KPAd's FunPrompt $ pip3 install xlsxwriter\n",
    "Collecting xlsxwriter\n",
    "  Downloading https://files.pythonhosted.org/packages/82/50/780122e4790328c195475d6e49a07fb69593508355dfee98bfb22686d9e8/XlsxWriter-1.2.1-py2.py3-none-any.whl (140kB)\n",
    "     |████████████████████████████████| 143kB 1.7MB/s \n",
    "Installing collected packages: xlsxwriter\n",
    "Successfully installed xlsxwriter-1.2.1\n",
    "[1]+  Done                    open -a Emacs distros.json\n",
    "KPAd's FunPrompt $\n",
    "KPAd's FunPrompt $ pip3 install xlwt\n",
    "Requirement already satisfied: xlwt in /usr/local/lib/python3.7/site-packages (1.3.0)\n",
    "KPAd's FunPrompt $\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kp: These lines are mine:\n",
      "[OrderedDict([('Source ID', 123), ('WordCount', 50), ('Key Words', ['Blah blah blah', 'Foo']), ('Frequency', [9, 12, 1, 2, 3]), ('Proper Nouns', ['UN', 'USA']), ('Location', 'Mordor')]), OrderedDict([('Source ID', 124), ('WordCount', 50), ('Key Words', ['Blah blah blah', 'Foo']), ('Frequency', [9, 12, 1, 2, 3]), ('Proper Nouns', ['UN', 'USA']), ('Location', 'Mordor')])]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/35583963/writing-heirarchical-json-data-to-excel-xls-from-python\n",
    "from collections import OrderedDict\n",
    "import xlsxwriter\n",
    "import json\n",
    "\n",
    "def json_to_excel(ws, data, row=0, col=0):\n",
    "    if isinstance(data, list):\n",
    "        row -= 1\n",
    "        for value in data:\n",
    "            row = json_to_excel(ws, value, row+1, col)\n",
    "    elif isinstance(data, dict):\n",
    "        max_row = row\n",
    "        start_row = row\n",
    "        \n",
    "        # https://stackoverflow.com/questions/30418481/error-dict-object-has-no-attribute-iteritems\n",
    "        # Python 3 renamed dict.iteritems -> dict.items. – Blender May 23 '15 at 23:16\n",
    "        #for key, value in data.iteritems(): #AttributeError: 'collections.OrderedDict' object has no attribute 'iteritems'\n",
    "        for key, value in data.items():\n",
    "            row = start_row\n",
    "            ws.write(row, col, key)\n",
    "            row = json_to_excel(ws, value, row+1, col)\n",
    "            max_row = max(max_row, row)\n",
    "            col += 1\n",
    "        row = max_row\n",
    "    else:\n",
    "        ws.write(row, col, data)\n",
    "\n",
    "    return row\n",
    "\n",
    "text = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"Source ID\": 123,\n",
    "        \"WordCount\": 50,\n",
    "        \"Key Words\": [\"Blah blah blah\", \"Foo\"],\n",
    "        \"Frequency\": [9, 12, 1, 2, 3],\n",
    "        \"Proper Nouns\": [\"UN\", \"USA\"],\n",
    "        \"Location\": \"Mordor\"\n",
    "    },\n",
    "    {\n",
    "        \"Source ID\": 124,\n",
    "        \"WordCount\": 50,\n",
    "        \"Key Words\": [\"Blah blah blah\", \"Foo\"],\n",
    "        \"Frequency\": [9, 12, 1, 2, 3],\n",
    "        \"Proper Nouns\": [\"UN\", \"USA\"],\n",
    "        \"Location\": \"Mordor\"\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "data = json.loads(text, object_pairs_hook=OrderedDict)\n",
    "wb = xlsxwriter.Workbook(\"testExcelOutput1.xlsx\")\n",
    "ws = wb.add_worksheet()\n",
    "json_to_excel(ws, data)\n",
    "wb.close()  \n",
    "\n",
    "print(\"kp: These lines are mine:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kp: regular dictionary ...??? \n",
      "\n",
      "{'Data': {'dose_data': '0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86', 'error_data': '0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001', 'survival_data': '0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471'}, 'Experiment': {'Biophysical_info': {'cell_line': 'HFIB2', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons'}, 'Original_values': {'alpha': '0.689', 'alpha_X': '0.689', 'alpha_X_err': '0.164', 'alpha_err': '0.164', 'beta': '0.041', 'beta_X': '0.041', 'beta_X_err': '0.015', 'beta_err': '0.015'}, 'Publication': {'author': 'Slonina', 'year': '2014'}}, 'Header': {'created_by': 'Plot Digitizer     2.6.8', 'date': 'Date: 3/10/18     7:52:58 AM', 'dependence': 'SF(Dose (Gy))', 'user': 'pawel'}}\n"
     ]
    }
   ],
   "source": [
    "#kp: This cell here to test if I can also get the OrderedDict\n",
    "import json\n",
    "myJson = \"/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\"\n",
    "with open(myJson, 'r') as json_file:\n",
    "    Dict = json.load(json_file)  #regular dict\n",
    "\n",
    "print(\"kp: regular dictionary ...??? \\n\")\n",
    "print(Dict)\n",
    "\n",
    "#print(\"k\\n\\nkp: OrderedDict ...??? \\n\")\n",
    "#with open(myJson, 'r') as json_file:\n",
    "#    OD = json.loads(json_file, object_pairs_hook=OrderedDict) #TypeError: the JSON object must be str, bytes or bytearray, not TextIOWrapper\n",
    "#print(OD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/55154707/how-to-write-to-excel-in-python\n",
    "import xlsxwriter\n",
    "\n",
    "\n",
    "# Create an new Excel file and add a worksheet.\n",
    "#workbook = xlsxwriter.Workbook('C:/your_path/test.xlsx')\n",
    "workbook = xlsxwriter.Workbook('testExcel2.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Widen the first column to make the text clearer.\n",
    "worksheet.set_column('A:A', 20)\n",
    "\n",
    "# Add a bold format to use to highlight cells.\n",
    "bold = workbook.add_format({'bold': True})\n",
    "\n",
    "# Write some simple text.\n",
    "worksheet.write('A1', 'Hello')\n",
    "\n",
    "# Text with formatting.\n",
    "worksheet.write('A2', 'World', bold)\n",
    "\n",
    "# Write some numbers, with row/column notation.\n",
    "worksheet.write(2, 0, 123)\n",
    "worksheet.write(3, 0, 123.456)\n",
    "\n",
    "\n",
    "workbook.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "And this is my Dictionary of size:  21\n",
      "{'dose_data': '0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86', 'error_data': '0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001', 'survival_data': '0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471', 'cell_line': 'HFIB2', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons', 'alpha': '0.689', 'alpha_X': '0.689', 'alpha_X_err': '0.164', 'alpha_err': '0.164', 'beta': '0.041', 'beta_X': '0.041', 'beta_X_err': '0.015', 'beta_err': '0.015', 'author': 'Slonina', 'year': '2014', 'created_by': 'Plot Digitizer     2.6.8', 'date': 'Date: 3/10/18     7:52:58 AM', 'dependence': 'SF(Dose (Gy))', 'user': 'pawel'}\n"
     ]
    }
   ],
   "source": [
    "# Function that takes a json file and returns a dictionary of innermost elements\n",
    "import json\n",
    "myJson = \"/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\"\n",
    "\n",
    "def return_inner_dict(jsonFile):\n",
    "    dic = dict()    # new dictionary\n",
    "    #valueList.clear() #This will make the list an empty one without any cells/elements\n",
    "    with open(jsonFile, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        for key, value in data.items():  \n",
    "            #print(key,\":\", value, \"\\n\\n\")  \n",
    "            for k, v in value.items(): \n",
    "                if key == 'Data' or key == 'Header':\n",
    "                    dic[k] = v #This is equivalent to list.append(..) (it adds a key-value pair to the dictionary)\n",
    "            \n",
    "            #print(k,\":\", v)\n",
    "                if key == 'Experiment':\n",
    "                    for kk, vv in v.items():\n",
    "                        dic[kk] = vv\n",
    "        #print(\"\\n\\n\\n\")\n",
    "    return dic\n",
    "\n",
    "retDict = return_inner_dict(myJson)\n",
    "print(\"\\nAnd this is my Dictionary of size: \", len(retDict))\n",
    "print(retDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keysList: \n",
      " ['dose_data', 'error_data', 'survival_data', 'cell_line', 'energy', 'let', 'modality', 'alpha', 'alpha_X', 'alpha_X_err', 'alpha_err', 'beta', 'beta_X', 'beta_X_err', 'beta_err', 'author', 'year', 'created_by', 'date', 'dependence', 'user']\n",
      "keysDict: \n",
      " {'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, 'let': 6, 'modality': 7, 'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, 'beta': 12, 'beta_X': 13, 'beta_X_err': 14, 'beta_err': 15, 'author': 16, 'year': 17, 'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21}\n",
      "\n",
      " valuesList: \n",
      " ['0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86', '0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001', '0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471', 'HFIB2', '6MV', '-keV/$\\\\mu$m', 'photons', '0.689', '0.689', '0.164', '0.164', '0.041', '0.041', '0.015', '0.015', 'Slonina', '2014', 'Plot Digitizer     2.6.8', 'Date: 3/10/18     7:52:58 AM', 'SF(Dose (Gy))', 'pawel'] \n",
      "\n",
      "Total # of processed files:  540\n",
      "1 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3B-protons-60MeV-HFIB15.json is Empty, byte-size =  0 \n",
      "\n",
      "10 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-1.json is Empty, byte-size =  0 \n",
      "\n",
      "12 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-2a.json is Empty, byte-size =  0 \n",
      "\n",
      "15 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-3.json is Empty, byte-size =  0 \n",
      "\n",
      "51 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Gueulette-1996/Gueulette-1996-Fig1-protons-85MeV-distal-30mmSOBP.json is Empty, byte-size =  0 \n",
      "\n",
      "308 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Schuff-2002/Schuff-2002-Fig7-photons-Cs137-PDVC57.json is Empty, byte-size =  0 \n",
      "\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "366 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Belli-1998/Belli-1998-Fig1-30.5keVum.json is Empty, byte-size =  0 \n",
      "\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "515 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Miller-1995/Miller-1995-Fig1C-protons-15keVum.json is Empty, byte-size =  0 \n",
      "\n",
      "515 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Perris-1986/Perris-1986-Fig3a-photons-Co60-V79.json is Empty, byte-size =  0 \n",
      "\n",
      "517 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Perris-1986/Perris-1986-Fig3a-photons-Co60.json is Empty, byte-size =  0 \n",
      "\n",
      "Total # of processed files:  530\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/53224690/how-to-write-json-text-to-excel-file\n",
    "# https://www.digitalocean.com/community/tutorials/how-to-use-break-continue-and-pass-statements-when-working-with-loops-in-python-3\n",
    "# https://stackoverflow.com/questions/2104080/how-to-check-file-size-in-python\n",
    "\n",
    "\n",
    "import xlsxwriter\n",
    "import os\n",
    "\n",
    "keysList = ['dose_data', 'error_data', 'survival_data', 'cell_line', 'energy', 'let', 'modality', \n",
    "             'alpha', 'alpha_X', 'alpha_X_err', 'alpha_err', 'beta', 'beta_X', 'beta_X_err','beta_err',\n",
    "             'author', 'year', 'created_by', 'date', 'dependence', 'user']\n",
    "# Started from 1 because I had to use \"col = keysDict.get(key)\", which is supposed to return 0, when \n",
    "#    the 'key' is not found. But, if I start it by 0, it would return 0 even when the key 'dose_data' \n",
    "#    is found. Initially, I had started the values from 0.\n",
    "keysDict = {'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, 'let': 6, 'modality': 7, \n",
    "            'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, 'beta': 12, 'beta_X': 13, 'beta_X_err': 14, \n",
    "            'beta_err': 15, 'author': 16, 'year': 17, 'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21}\n",
    "\n",
    "#type(keysList)\n",
    "print(\"keysList: \\n\", keysList)\n",
    "print(\"keysDict: \\n\", keysDict)\n",
    "print(\"\\n valuesList: \\n\", valuesList, \"\\n\")\n",
    "             \n",
    "# Workbook() takes one, non-optional, argument  \n",
    "# which is the filename that we want to create. \n",
    "workbook = xlsxwriter.Workbook('testRBE.xlsx')\n",
    "\n",
    "# The workbook object is then used to add new  \n",
    "# worksheet via the add_worksheet() method. \n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Widen the first column to make the text clearer.\n",
    "worksheet.set_column('A:A', 20)\n",
    "worksheet.set_column(0,1, 20)\n",
    "worksheet.set_column(0,2, 20)\n",
    "\n",
    "# Add a bold format to use to highlight cells.\n",
    "bold = workbook.add_format({'bold': True})\n",
    "\n",
    "col = 0\n",
    "for aKey in keysList:\n",
    "    worksheet.write(0, col, aKey, bold)\n",
    "    col = col + 1\n",
    "\n",
    "#col = 0  # We need it (writing starts from col=0 on each row)\n",
    "#for aValue in valuesList: #works\n",
    "#for key, aValue in dic.items():    \n",
    "#    worksheet.write(1, col, aValue)\n",
    "#    col = col + 1\n",
    "\n",
    "#Just to count the total # of files to be processed\n",
    "k = 0\n",
    "for jsonFile in findFiles(r'/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff', '*.json'):  \n",
    "    k+=1  #Equivalent to i++ or i = i+1 in C/C++/Java    \n",
    "    \n",
    "print(\"Total # of processed files: \", k) \n",
    "\n",
    "\n",
    "####### Now iterating over several json files and writing their values in different rows.\n",
    "j = 0\n",
    "nFileMax =  1000 #10 #100000\n",
    "for jsonFile in findFiles(r'/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff', '*.json'):  \n",
    "    if j < nFileMax:\n",
    "        #print(jsonFile)\n",
    "        b = os.path.getsize(jsonFile)\n",
    "        #print(\"Input file: \", jsonFile, \" has a size of \", b,\"\\n\")\n",
    "        if b==0:\n",
    "            print(j,\"^th file: \", jsonFile, \"is Empty, byte-size = \", b,\"\\n\")\n",
    "            continue\n",
    "\n",
    "        retDict = return_inner_dict(jsonFile)\n",
    "        #print(retDict,\"\\n\\n\")\n",
    "\n",
    "        #col = 0  # We need it (writing starts from col=0 on each row)\n",
    "        for key, aValue in retDict.items():  \n",
    "            #col = keysDict[key] # Mostly worked but sometimes got \"KeyError: 'E'\"\n",
    "            # https://realpython.com/python-keyerror/\n",
    "            col = keysDict.get(key) #Returns 0 if key not found in the Dict\n",
    "            if col:\n",
    "                worksheet.write(j+1, col-1, aValue)\n",
    "            else:\n",
    "                print(\"Invalid key: \", key)\n",
    "                #continue\n",
    "            #col = col + 1\n",
    "        \n",
    "        j+=1  #Equivalent to i++ or i = i+1 in C/C++/Java    \n",
    "    \n",
    "print(\"Total # of processed files: \", j)    \n",
    "    \n",
    "# Now make a function that takes in file name, and return dictionary and use that in above block instead.\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keysDict: \n",
      " {'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, 'let': 6, 'modality': 7, 'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, 'beta': 12, 'beta_X': 13, 'beta_X_err': 14, 'beta_err': 15, 'author': 16, 'year': 17, 'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21}\n",
      "1 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3B-protons-60MeV-HFIB15.json is Empty, byte-size =  0 \n",
      "\n",
      "10 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-1.json is Empty, byte-size =  0 \n",
      "\n",
      "12 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-2a.json is Empty, byte-size =  0 \n",
      "\n",
      "15 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-3.json is Empty, byte-size =  0 \n",
      "\n",
      "51 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Gueulette-1996/Gueulette-1996-Fig1-protons-85MeV-distal-30mmSOBP.json is Empty, byte-size =  0 \n",
      "\n",
      "Dictionary has empty values?\n",
      "55 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Folkard-1996/Folkard-1996-Fig3a-protons-10keVum-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "98 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Britten-2013/Britten-2013-Fig2-protons-87MeV-20.5keVum-V79-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "109 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Britten-2013/Britten-2013-Fig2-protons-87MeV-20.5keVum-V79-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "252 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Tang-1997/Tang-1997-Fig2D-photons-Cs137-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "273 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Guan-2015/Guan-2015-LQM-params-LET-dep-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "282 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Guan-2015/Guan-2015-LQM-params-LET-dep.json gives empty-valued Dictionary \n",
      "\n",
      "302 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Schuff-2002/Schuff-2002-Fig7-photons-Cs137-PDVC57.json is Empty, byte-size =  0 \n",
      "\n",
      "Dictionary has empty values?\n",
      "358 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Belli-1998/Belli-1998-Fig1b-protons-7.7keVum-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "359 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Belli-1998/Belli-1998-Fig1-30.5keVum.json is Empty, byte-size =  0 \n",
      "\n",
      "Dictionary has empty values?\n",
      "368 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2H-protons-190MeV-HSG-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "371 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2F-protons-190MeV-HSG-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "372 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2F-protons-190MeV-HSG-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "418 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Howard-2018/Howard-2018-Fig3A-protons-71MeV-CHO-positionD1-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "473 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Howard-2018/Howard-2018-Fig3A-protons-71MeV-CHO-positionD1-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "503 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Miller-1995/Miller-1995-Fig1C-protons-15keVum.json is Empty, byte-size =  0 \n",
      "\n",
      "503 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Perris-1986/Perris-1986-Fig3a-photons-Co60-V79.json is Empty, byte-size =  0 \n",
      "\n",
      "505 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Perris-1986/Perris-1986-Fig3a-photons-Co60.json is Empty, byte-size =  0 \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-38c1ce683203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mretDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_inner_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;31m#print(retDict,\"\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_if_values_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-38c1ce683203>\u001b[0m in \u001b[0;36mreturn_inner_dict\u001b[0;34m(jsonFile)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Data'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Header'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;31m#This is equivalent to list.append(..) (it adds a key-value pair to the dictionary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "import json\n",
    "import os, fnmatch\n",
    "import math #For log() method to evaluate natural log (Ln)\n",
    "\n",
    "def findFiles (path, filter):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in fnmatch.filter(files, filter):\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "#\"\"\"          \n",
    "keysDict = {'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, \n",
    "            'let': 6, 'modality': 7, 'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, \n",
    "            'beta': 12, 'beta_X': 13, 'beta_X_err': 14, 'beta_err': 15, 'author': 16, 'year': 17, \n",
    "            'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21}\n",
    "print(\"keysDict: \\n\", keysDict)\n",
    "#\"\"\"  \n",
    "    \n",
    "# Function that takes a json file and returns a dictionary of innermost elements\n",
    "def return_inner_dict(jsonFile):\n",
    "    dic = dict()    # new dictionary\n",
    "    #valueList.clear() #This will make the list an empty one without any cells/elements\n",
    "    with open(jsonFile, 'r') as json_file: #This way file is auto-closed\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        for key, value in data.items():  \n",
    "            for k, v in value.items(): \n",
    "                if key == 'Data' or key == 'Header':\n",
    "                    dic[k] = v #This is equivalent to list.append(..) (it adds a key-value pair to the dictionary)\n",
    "            \n",
    "                if key == 'Experiment':\n",
    "                    for kk, vv in v.items():\n",
    "                        dic[kk] = vv\n",
    "    return dic\n",
    " \n",
    "\n",
    "\n",
    "####### Now iterating over several json files and writing their values in different rows.\n",
    "j = 0\n",
    "for jsonFile in findFiles(r'/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff', '*.json'):  \n",
    "    #print(jsonFile)\n",
    "    b = os.path.getsize(jsonFile)\n",
    "    if b==0:\n",
    "        print(j,\"^th file: \", jsonFile, \"is Empty, byte-size = \", b,\"\\n\")\n",
    "        continue\n",
    "\n",
    "    retDict = return_inner_dict(jsonFile)\n",
    "    #print(retDict,\"\\n\\n\")\n",
    "    if check_if_values_empty(retDict):\n",
    "        print (j,\"^th file: \", jsonFile, \"gives empty-valued Dictionary \\n\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    for key, aValue in retDict.items():  \n",
    "        #col = keysDict[key] # Mostly worked but sometimes got \"KeyError: 'E'\"\n",
    "        col = keysDict.get(key) #Returns 0 if key not found in the Dict\n",
    "        row = j+1\n",
    "        #print(\"row, col: \", row, col)\n",
    "    j+=1  #Equivalent to i++ or i = i+1 in C/C++/Java    \n",
    "    \n",
    "print(\"Total # of processed files: \", j)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now putting things together in the same place.\n",
    "\n",
    "Here, I collect all the essential chunks of the code that exist in different cells above (after cleaning up un-necessary parts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keysDict: \n",
      " {'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, 'let': 6, 'modality': 7, 'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, 'beta': 12, 'beta_X': 13, 'beta_X_err': 14, 'beta_err': 15, 'author': 16, 'year': 17, 'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21}\n",
      "1 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3B-protons-60MeV-HFIB15.json is Empty, byte-size =  0 \n",
      "\n",
      "10 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-1.json is Empty, byte-size =  0 \n",
      "\n",
      "12 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-2a.json is Empty, byte-size =  0 \n",
      "\n",
      "15 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-3.json is Empty, byte-size =  0 \n",
      "\n",
      "51 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Gueulette-1996/Gueulette-1996-Fig1-protons-85MeV-distal-30mmSOBP.json is Empty, byte-size =  0 \n",
      "\n",
      "Dictionary has empty values?\n",
      "55 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Folkard-1996/Folkard-1996-Fig3a-protons-10keVum-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "98 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Britten-2013/Britten-2013-Fig2-protons-87MeV-20.5keVum-V79-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "109 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Britten-2013/Britten-2013-Fig2-protons-87MeV-20.5keVum-V79-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "252 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Tang-1997/Tang-1997-Fig2D-photons-Cs137-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "273 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Guan-2015/Guan-2015-LQM-params-LET-dep-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "282 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Guan-2015/Guan-2015-LQM-params-LET-dep.json gives empty-valued Dictionary \n",
      "\n",
      "302 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Schuff-2002/Schuff-2002-Fig7-photons-Cs137-PDVC57.json is Empty, byte-size =  0 \n",
      "\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Dictionary has empty values?\n",
      "358 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Belli-1998/Belli-1998-Fig1b-protons-7.7keVum-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "359 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Belli-1998/Belli-1998-Fig1-30.5keVum.json is Empty, byte-size =  0 \n",
      "\n",
      "Dictionary has empty values?\n",
      "368 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2H-protons-190MeV-HSG-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "371 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2F-protons-190MeV-HSG-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "372 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2F-protons-190MeV-HSG-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Dictionary has empty values?\n",
      "418 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Howard-2018/Howard-2018-Fig3A-protons-71MeV-CHO-positionD1-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Dictionary has empty values?\n",
      "473 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Howard-2018/Howard-2018-Fig3A-protons-71MeV-CHO-positionD1-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "503 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Miller-1995/Miller-1995-Fig1C-protons-15keVum.json is Empty, byte-size =  0 \n",
      "\n",
      "503 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Perris-1986/Perris-1986-Fig3a-photons-Co60-V79.json is Empty, byte-size =  0 \n",
      "\n",
      "505 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Perris-1986/Perris-1986-Fig3a-photons-Co60.json is Empty, byte-size =  0 \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b6dac93bb3c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mretDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_inner_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0;31m#print(retDict,\"\\n\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_if_values_empty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-b6dac93bb3c0>\u001b[0m in \u001b[0;36mreturn_inner_dict\u001b[0;34m(jsonFile)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Data'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Header'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;31m#This is equivalent to list.append(..) (it adds a key-value pair to the dictionary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "import json\n",
    "import os, fnmatch\n",
    "import math #For log() method to evaluate natural log (Ln)\n",
    "\n",
    "def findFiles (path, filter):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in fnmatch.filter(files, filter):\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "            \n",
    "keysDict = {'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, \n",
    "            'let': 6, 'modality': 7, 'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, \n",
    "            'beta': 12, 'beta_X': 13, 'beta_X_err': 14, 'beta_err': 15, 'author': 16, 'year': 17, \n",
    "            'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21}\n",
    "print(\"keysDict: \\n\", keysDict)\n",
    " \n",
    "    \n",
    "# Function that takes a json file and returns a dictionary of innermost elements\n",
    "def return_inner_dict(jsonFile):\n",
    "    dic = dict()    # new dictionary\n",
    "    #valueList.clear() #This will make the list an empty one without any cells/elements\n",
    "    with open(jsonFile, 'r') as json_file: #This way file is auto-closed\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        for key, value in data.items():  \n",
    "            for k, v in value.items(): \n",
    "                if key == 'Data' or key == 'Header':\n",
    "                    dic[k] = v #This is equivalent to list.append(..) (it adds a key-value pair to the dictionary)\n",
    "            \n",
    "                if key == 'Experiment':\n",
    "                    for kk, vv in v.items():\n",
    "                        dic[kk] = vv\n",
    "    return dic\n",
    "\n",
    "\n",
    "def check_if_values_empty(Dict):\n",
    "    allValues = ''\n",
    "    for key, aValue in Dict.items():  \n",
    "        allValues = allValues + aValue\n",
    "    \n",
    "    #if allValues == None:\n",
    "    if len(allValues) == 0:\n",
    "        print(\"Dictionary has empty values?\")\n",
    "        return True\n",
    "    else:\n",
    "        #print(\"Dictionary has non-empty values:\\n\", allValues)\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def return_RBE(Dict):\n",
    "    taP = Dict.get('alpha')\n",
    "    tbP  = Dict.get('beta')\n",
    "    taX = Dict.get('alpha_X')\n",
    "    tbX  = Dict.get('beta_X')\n",
    "    \"\"\"\n",
    "    print('Dict: ', type(Dict), 'len(Dict)=', len(Dict), \n",
    "         taP, tbP, taX, tbX, type(taP), type(tbP), type(taX), type(tbX) )\n",
    "    \"\"\"\n",
    "    if taP == None or tbP == None or taX == None or tbX == None:\n",
    "        return -1.0\n",
    "    else:\n",
    "        if taP and tbP and taX and tbX:\n",
    "            alphaP = float(Dict.get('alpha')) \n",
    "            betaP  = float(Dict.get('beta'))\n",
    "            alphaX = float(Dict.get('alpha_X'))\n",
    "            betaX  = float(Dict.get('beta_X'))\n",
    "            lnSF = math.log(0.1) #natural log of SF = 0.1 (SF = 10%)\n",
    "\n",
    "            #sqrtNumer = math.sqrt(math.pow(alphaX, 2) - 4 * betaX * lnSF)\n",
    "            #sqrtDenom = math.sqrt(math.pow(alphaP, 2) - 4 * betaP * lnSF)\n",
    "            #sqrtNumer = math.sqrt(alpha_X**2 - 4*beta_X*lnSF)\n",
    "            #sqrtDenom = math.sqrt(alpha_P**2 - 4*beta_P*lnSF)\n",
    "\n",
    "            sqrtNumer = math.sqrt(alphaX * alphaX - 4*betaX*lnSF)\n",
    "            sqrtDenom = math.sqrt(alphaP * alphaP - 4*betaP*lnSF)\n",
    "            RBEnumer = (sqrtNumer - alphaX) * betaP\n",
    "            RBEdenom = (sqrtDenom - alphaP) * betaX\n",
    "            if RBEdenom == 0:\n",
    "                return -2.0\n",
    "            else:\n",
    "                RBE = RBEnumer/RBEdenom\n",
    "                return RBE\n",
    "        else:\n",
    "            return -3.0\n",
    "\n",
    "\n",
    "        \n",
    "def return_RBE_Err(Dict):\n",
    "    taP  = Dict.get('alpha')\n",
    "    tbP  = Dict.get('beta')\n",
    "    taX  = Dict.get('alpha_X')\n",
    "    tbX  = Dict.get('beta_X')\n",
    "    taPe  = Dict.get('alpha_err')\n",
    "    tbPe  = Dict.get('beta_err')\n",
    "    taXe  = Dict.get('alpha_X_err')\n",
    "    tbXe  = Dict.get('beta_X_err')\n",
    "\n",
    "    print(type(taP), type(tbP), type(taX), type(tbX), type(taPe), \\\n",
    "                  type(tbPe), type(taXe), type(tbXe), \\\n",
    "                  taP, tbP, taX, tbX, taPe, tbPe, taXe, tbXe)\n",
    "\n",
    "    \n",
    "    if taP == None or tbP == None or taX == None or tbX == None or \\\n",
    "    taPe == None or tbPe == None or taXe == None or tbXe == None:\n",
    "        return -1.0\n",
    "    else:\n",
    "        # you can just use strip() instead of strip('\\n') - it stripes all whitespaces automatically – yedpodtrzitko Feb 5 '17 at 19:08\n",
    "        # https://stackoverflow.com/questions/42013867/valueerror-could-not-convert-string-to-float-0-274697-n\n",
    "        u  = float(taP)   #For P\n",
    "        v  = float(tbP)   #For P\n",
    "        x  = float(taX)   #For X\n",
    "        y  = float(tbX)   #For X\n",
    "        # https://stackoverflow.com/questions/48075861/valueerror-could-not-convert-string-to-float\n",
    "        du = float(taPe.strip()) # str.strip(\"x\") removes x from str etc.\n",
    "        dv = float(tbPe.strip())\n",
    "        dx = float(taXe.strip())\n",
    "        dy = float(tbXe.strip())\n",
    "        lnSF = math.log(0.1) #natural log of SF = 0.1 (SF = 10%)\n",
    " \n",
    "\n",
    "        #if taP and tbP and taX and tbX and taPe and tbPe and taXe and tbXe:\n",
    "        if int(u) and int(v) and int(x) and int(y) and \\\n",
    "            int(du) and int(dv) and int(dx) and int(dy):\n",
    "\n",
    "\n",
    "            sqrtXU = math.sqrt(x - 4*u*lnSF)\n",
    "            sqrtYV = math.sqrt(y - 4*v*lnSF)\n",
    "            # Now the partial derivatives (df_dx means df/dx & so on)\n",
    "            # Derived by myself but also Verified @ https://www.derivative-calculator.net/#\n",
    "            # https://en.wikipedia.org/wiki/Propagation_of_uncertainty\n",
    "            # f = RBE = [(sqrt(x - 4 u lnSF) - x) / (sqrt(y - 4 v lnSF) - y)] * v/u\n",
    "            df_dx = ( v/(u*(sqrtYV - y))) * ( 1/(2*sqrtXU) - 1) \n",
    "            df_dy = - (v/u)*((sqrtXU - x)/math.pow((sqrtYV - y),2))*(1/(2*sqrtYV) - 1)\n",
    "            df_du = - (v/(u*u))*(sqrtXU - x)/(sqrtYV - y)  - 2*v*lnSF/(u*sqrtXU*(sqrtYV - y))\n",
    "            df_dv = (sqrtXU - x)/((sqrtYV - y)*u) \\\n",
    "                    + 2*v*lnSF*(sqrtXU - x)/(u*sqrtYV*math.pow((sqrtYV - y),2))\n",
    "            \n",
    "            RBEerr = math.sqrt(df_dx*df_dx * dx + df_dy*df_dy * dy \\\n",
    "                              + df_du*df_du * dy  + df_dv*df_dv * dv)\n",
    "            return RBEerr\n",
    "        else:\n",
    "            return -3.0\n",
    "        \n",
    "        \n",
    "# Creating an Excel file. \n",
    "workbook = xlsxwriter.Workbook('testRBE.xlsx')\n",
    "\n",
    "# workbook object used to add new worksheet via add_worksheet() method. \n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Widen the first 3-columns a little bit (contents are large strings).\n",
    "worksheet.set_column('A:A', 20)\n",
    "worksheet.set_column(0,1, 20)\n",
    "worksheet.set_column(0,2, 20)\n",
    "\n",
    "# Add a bold format to use to highlight cells.\n",
    "bold = workbook.add_format({'bold': True})\n",
    "\n",
    "#Writing Headers in the first row \n",
    "for hKeys, hValues in keysDict.items():\n",
    "    worksheet.write(0, hValues-1, hKeys, bold) #kp: row, col, values, style\n",
    "\n",
    "#Next to Last column is for RBE (which is calculated using eq 7 of Chen-Ahmad-2012.pdf)\n",
    "worksheet.write(0, len(keysDict), \"RBE\", bold) #kp: row, col, values, style\n",
    "\n",
    "#Last column is for RBEerr (which is calculated using eq 7 of Chen-Ahmad-2012.pdf\n",
    "#  for RBE and then error propagation formula (through partial derivatives)\n",
    "worksheet.write(0, len(keysDict) + 1, \"RBE_err\", bold) #kp: row, col, values, style\n",
    "\n",
    "    \n",
    "####### Now iterating over several json files and writing their values in different rows.\n",
    "j = 0\n",
    "for jsonFile in findFiles(r'/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff', '*.json'):  \n",
    "    #print(jsonFile)\n",
    "    b = os.path.getsize(jsonFile)\n",
    "    if b==0:\n",
    "        print(j,\"^th file: \", jsonFile, \"is Empty, byte-size = \", b,\"\\n\")\n",
    "        continue\n",
    "\n",
    "    retDict = return_inner_dict(jsonFile)\n",
    "    #print(retDict,\"\\n\\n\")\n",
    "    if check_if_values_empty(retDict):\n",
    "        print (j,\"^th file: \", jsonFile, \"gives empty-valued Dictionary \\n\")\n",
    "        continue\n",
    "    \n",
    "    if len(retDict) > 0:\n",
    "        RBE = return_RBE(retDict)\n",
    "        #RBE_Err = return_RBE_Err(retDict) # showed some intractable error (so abandoned 10/9/19)\n",
    "        \n",
    "    # First writing the RBE value in the last column\n",
    "    if RBE:\n",
    "        worksheet.write(j+1, len(keysDict), RBE)\n",
    "        #print('RBE=', RBE)\n",
    "    if RBE_Err:\n",
    "        worksheet.write(j+1, len(keysDict)+1, RBE_Err)\n",
    "\n",
    "    for key, aValue in retDict.items():  \n",
    "        #col = keysDict[key] # Mostly worked but sometimes got \"KeyError: 'E'\"\n",
    "        col = keysDict.get(key) #Returns 0 if key not found in the Dict\n",
    "        if col:\n",
    "            worksheet.write(j+1, col-1, aValue)\n",
    "        else:\n",
    "            print(\"Invalid key: \", key)\n",
    "            #continue\n",
    "        \n",
    "    j+=1  #Equivalent to i++ or i = i+1 in C/C++/Java    \n",
    "    \n",
    "print(\"Total # of processed files: \", j)    \n",
    "    \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More to read on:\n",
    "\n",
    "https://stackoverflow.com/questions/25605380/passing-directory-to-python-script-as-command-line-argument\n",
    "\n",
    "http://www.tutorialspoint.com/python/python_command_line_arguments.htm\n",
    "\n",
    "```py\n",
    "#!/usr/bin/python\n",
    "\n",
    "import sys, getopt\n",
    "\n",
    "def main(argv):\n",
    "   inputfile = ''\n",
    "   outputfile = ''\n",
    "   try:\n",
    "      opts, args = getopt.getopt(argv,\"hi:o:\",[\"ifile=\",\"ofile=\"])\n",
    "   except getopt.GetoptError:\n",
    "      print 'test.py -i <inputfile> -o <outputfile>'\n",
    "      sys.exit(2)\n",
    "   for opt, arg in opts:\n",
    "      if opt == '-h':\n",
    "         print 'test.py -i <inputfile> -o <outputfile>'\n",
    "         sys.exit()\n",
    "      elif opt in (\"-i\", \"--ifile\"):\n",
    "         inputfile = arg\n",
    "      elif opt in (\"-o\", \"--ofile\"):\n",
    "         outputfile = arg\n",
    "   print 'Input file is \"', inputfile\n",
    "   print 'Output file is \"', outputfile\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main(sys.argv[1:])\n",
    "```\n",
    "\n",
    "* https://docs.aspose.com/display/cellsjava/Inserting+and+Deleting+Rows+and+Columns+in+Python\n",
    "* https://openpyxl.readthedocs.io/en/stable/editing_worksheets.html\n",
    "\n",
    "* https://stackoverflow.com/questions/17299364/insert-row-into-excel-spreadsheet-using-openpyxl-in-python\n",
    "Insert row into Excel spreadsheet using openpyxl in Python\n",
    "\n",
    "Unfortunately there isn't really a better way to do in that read in the file, and use a library like xlwt to write out a new excel file (with your new row inserted at the top). Excel doesn't work like a database that you can read and and append to. You unfortunately just have to read in the information and manipulate in memory and write out to what is essentially a new file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GoTop](#GoTop)<a id='JSONencodingAndDecodingWithPython'></a>\n",
    "## JSON encoding and decoding with Python\n",
    "Refs:\n",
    "* https://pythonspot.com/json-encoding-and-decoding-with-python/ \n",
    "\n",
    "#### Introduction\n",
    "JSON (JavaScript Object Notation) is frequently used between a server and a web application. An example of JSON data:\n",
    "```json\n",
    "{\n",
    "    \"persons\": [\n",
    "        {\n",
    "            \"city\": \"Seattle\", \n",
    "            \"name\": \"Brian\"\n",
    "        }, \n",
    "        {\n",
    "            \"city\": \"Amsterdam\", \n",
    "            \"name\": \"David\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "The json module enables you to convert between JSON and Python Objects.\n",
    "\n",
    "### JSON conversion examples\n",
    "### Convert JSON to Python Object (Dict)\n",
    "To convert JSON to a Python [dict](https://pythonspot.com/python-dictionaries/) use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brian  , ----- ,  Seattle\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_data = '{\"name\": \"Brian\", \"city\": \"Seattle\"}'\n",
    "python_obj = json.loads(json_data)\n",
    "print(python_obj[\"name\"], \" , ----- , \", python_obj[\"city\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to Python Object (List)\n",
    "JSON data can be directly mapped to a Python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee\n",
      "tea\n",
      "water\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "array = '{\"drinks\": [\"coffee\", \"tea\", \"water\"]}'\n",
    "data = json.loads(array)\n",
    "\n",
    "for element in data['drinks']:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to Python Object (float)\n",
    "Floating points can be mapped using the decimal library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.573937639\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from decimal import Decimal\n",
    "\n",
    "jsondata = '{\"number\": 1.573937639}'\n",
    "\n",
    "x = json.loads(jsondata, parse_float=Decimal)\n",
    "print(x['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert JSON to Python Object (Example)\n",
    "JSON data often holds multiple objects, an example of how to use that below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brian\n",
      "David\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    " \n",
    "json_input = '{\"persons\": [{\"name\": \"Brian\", \"city\": \"Seattle\"}, {\"name\": \"David\", \"city\": \"Amsterdam\"} ] }'\n",
    "\n",
    "try:\n",
    "    decoded = json.loads(json_input)\n",
    " \n",
    "    # Access data\n",
    "    for x in decoded['persons']:\n",
    "        print (x['name'])\n",
    " \n",
    "except (ValueError, KeyError, TypeError):\n",
    "    print (\"JSON format error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Python Object (Dict) to JSON\n",
    "If you want to convert a Python Object to JSON use the json.dumps() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Name\": \"Luke\", \"Country\": \"Canada\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from decimal import Decimal\n",
    "\n",
    "d = {}\n",
    "d[\"Name\"] = \"Luke\"\n",
    "d[\"Country\"] = \"Canada\"\n",
    "\n",
    "print (json.dumps(d, ensure_ascii=False))\n",
    "# result {\"Country\": \"Canada\", \"Name\": \"Luke\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting JSON data to Python objects\n",
    "JSON data can be converted (deserialized) to Pyhon objects using the json.loads() function. A table of the mapping:\n",
    "```\n",
    "JSON \tPython\n",
    "===============\n",
    "object \t        dict\n",
    "array \t        list\n",
    "string \t        str\n",
    "number (int) \tint\n",
    "number (real) \tfloat\n",
    "true \t        True\n",
    "false \t        False\n",
    "null \t        None\n",
    "```\n",
    "### Pretty printing\n",
    "\n",
    "\n",
    "If you want to display JSON data you can use the json.dumps() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"city\": \"Seattle\",\n",
      "    \"name\": \"Brian\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_data = '{\"name\": \"Brian\", \"city\": \"Seattle\"}'\n",
    "python_obj = json.loads(json_data)\n",
    "print (json.dumps(python_obj, sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "And this is my Dictionary of size:  21\n",
      "{'dose_data': '0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86', 'error_data': '0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001', 'survival_data': '0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471', 'cell_line': 'HFIB2', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons', 'alpha': '0.689', 'alpha_X': '0.689', 'alpha_X_err': '0.164', 'alpha_err': '0.164', 'beta': '0.041', 'beta_X': '0.041', 'beta_X_err': '0.015', 'beta_err': '0.015', 'author': 'Slonina', 'year': '2014', 'created_by': 'Plot Digitizer     2.6.8', 'date': 'Date: 3/10/18     7:52:58 AM', 'dependence': 'SF(Dose (Gy))', 'user': 'pawel'}\n"
     ]
    }
   ],
   "source": [
    "# Function that takes a json file and returns a dictionary of innermost elements\n",
    "import json\n",
    "path = \"/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/\"\n",
    "file = \"Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\"\n",
    "myJson = path + file\n",
    "\n",
    "def return_inner_dict(jsonFile):\n",
    "    dic = dict()    # new dictionary\n",
    "    #valueList.clear() #This will make the list an empty one without any cells/elements\n",
    "    with open(jsonFile, 'r') as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "        for key, value in data.items():  \n",
    "            #print(key,\":\", value, \"\\n\\n\")  \n",
    "            for k, v in value.items(): \n",
    "                if key == 'Data' or key == 'Header':\n",
    "                    dic[k] = v #This is equivalent to list.append(..) (it adds a key-value pair to the dictionary)\n",
    "            \n",
    "            #print(k,\":\", v)\n",
    "                if key == 'Experiment':\n",
    "                    for kk, vv in v.items():\n",
    "                        dic[kk] = vv\n",
    "        #print(\"\\n\\n\\n\")\n",
    "    return dic\n",
    "\n",
    "retDict = return_inner_dict(myJson)\n",
    "print(\"\\nAnd this is my Dictionary of size: \", len(retDict))\n",
    "print(retDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `dumps()` function to create a JSON formatted string from a dictionary.\n",
    "    \n",
    "    print(json.dumps(my_dictionary))\n",
    "\n",
    "The output from this dumps command is quite complicated, because it won’t use any kind of indentation by default. To create a more readable output, you can add the `indent` parameter to the function call, which will add some hierarchy and indention to the output.\n",
    "\n",
    "    print(json.dumps(my_dictionary, indent=4))\n",
    "\n",
    "By default, the keys within a python dictionary are unsorted and the output of the `json.dumps()` function may be different when executing multiple times. I ran into this issue while writing some test cases, but setting the `sort_keys` parameter to true will solve the problem. This will sort the key values of the dictionary and will produce always the same output when using the same data.\n",
    "\n",
    "    print(json.dumps(my_dictionary, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\n",
      "\n",
      " Keys:  dict_keys(['Data', 'Experiment', 'Header']) \n",
      "\n",
      "{\"Data\": {\"dose_data\": \"0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86\", \"error_data\": \"0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001\", \"survival_data\": \"0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471\"}, \"Experiment\": {\"Biophysical_info\": {\"cell_line\": \"HFIB2\", \"energy\": \"6MV\", \"let\": \"-keV/$\\\\mu$m\", \"modality\": \"photons\"}, \"Original_values\": {\"alpha\": \"0.689\", \"alpha_X\": \"0.689\", \"alpha_X_err\": \"0.164\", \"alpha_err\": \"0.164\", \"beta\": \"0.041\", \"beta_X\": \"0.041\", \"beta_X_err\": \"0.015\", \"beta_err\": \"0.015\"}, \"Publication\": {\"author\": \"Slonina\", \"year\": \"2014\"}}, \"Header\": {\"created_by\": \"Plot Digitizer     2.6.8\", \"date\": \"Date: 3/10/18     7:52:58 AM\", \"dependence\": \"SF(Dose (Gy))\", \"user\": \"pawel\"}} \n",
      "\n",
      "{\n",
      "    \"Data\": {\n",
      "        \"dose_data\": \"0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86\",\n",
      "        \"error_data\": \"0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001\",\n",
      "        \"survival_data\": \"0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471\"\n",
      "    },\n",
      "    \"Experiment\": {\n",
      "        \"Biophysical_info\": {\n",
      "            \"cell_line\": \"HFIB2\",\n",
      "            \"energy\": \"6MV\",\n",
      "            \"let\": \"-keV/$\\\\mu$m\",\n",
      "            \"modality\": \"photons\"\n",
      "        },\n",
      "        \"Original_values\": {\n",
      "            \"alpha\": \"0.689\",\n",
      "            \"alpha_X\": \"0.689\",\n",
      "            \"alpha_X_err\": \"0.164\",\n",
      "            \"alpha_err\": \"0.164\",\n",
      "            \"beta\": \"0.041\",\n",
      "            \"beta_X\": \"0.041\",\n",
      "            \"beta_X_err\": \"0.015\",\n",
      "            \"beta_err\": \"0.015\"\n",
      "        },\n",
      "        \"Publication\": {\n",
      "            \"author\": \"Slonina\",\n",
      "            \"year\": \"2014\"\n",
      "        }\n",
      "    },\n",
      "    \"Header\": {\n",
      "        \"created_by\": \"Plot Digitizer     2.6.8\",\n",
      "        \"date\": \"Date: 3/10/18     7:52:58 AM\",\n",
      "        \"dependence\": \"SF(Dose (Gy))\",\n",
      "        \"user\": \"pawel\"\n",
      "    }\n",
      "} \n",
      "\n",
      "{\n",
      "    \"Data\": {\n",
      "        \"dose_data\": \"0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86\",\n",
      "        \"error_data\": \"0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001\",\n",
      "        \"survival_data\": \"0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471\"\n",
      "    },\n",
      "    \"Experiment\": {\n",
      "        \"Biophysical_info\": {\n",
      "            \"cell_line\": \"HFIB2\",\n",
      "            \"energy\": \"6MV\",\n",
      "            \"let\": \"-keV/$\\\\mu$m\",\n",
      "            \"modality\": \"photons\"\n",
      "        },\n",
      "        \"Original_values\": {\n",
      "            \"alpha\": \"0.689\",\n",
      "            \"alpha_X\": \"0.689\",\n",
      "            \"alpha_X_err\": \"0.164\",\n",
      "            \"alpha_err\": \"0.164\",\n",
      "            \"beta\": \"0.041\",\n",
      "            \"beta_X\": \"0.041\",\n",
      "            \"beta_X_err\": \"0.015\",\n",
      "            \"beta_err\": \"0.015\"\n",
      "        },\n",
      "        \"Publication\": {\n",
      "            \"author\": \"Slonina\",\n",
      "            \"year\": \"2014\"\n",
      "        }\n",
      "    },\n",
      "    \"Header\": {\n",
      "        \"created_by\": \"Plot Digitizer     2.6.8\",\n",
      "        \"date\": \"Date: 3/10/18     7:52:58 AM\",\n",
      "        \"dependence\": \"SF(Dose (Gy))\",\n",
      "        \"user\": \"pawel\"\n",
      "    }\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function that takes a json file and returns a dictionary of innermost elements\n",
    "import json\n",
    "\n",
    "print(myJson)\n",
    "\n",
    "with open(myJson, 'r') as json_file:\n",
    "    python_obj = json.load(json_file)\n",
    "    print(\"\\n Keys: \", python_obj.keys(), \"\\n\")\n",
    "    print (json.dumps(python_obj), \"\\n\")    \n",
    "    print (json.dumps(python_obj,indent=4), \"\\n\")    \n",
    "    print (json.dumps(python_obj, sort_keys=True, indent=4), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key 1 : type(value) <class 'str'>\n",
      "key 2 : type(value) <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\n",
    "    \"key 1\": \"value 1\",\n",
    "    \"key 2\": \"value 2\"\n",
    "}\n",
    "\n",
    "for key, value in my_dict.items():\n",
    "    print(key, \": type(value)\", type(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\n",
      "\n",
      " Keys:  dict_keys(['Data', 'Experiment', 'Header']) \n",
      "\n",
      "Data : type(value):  <class 'dict'> : len(value):  3\n",
      "Now, looking at each subdictionaries:\n",
      "\t Data dose_data : type(v):  <class 'str'> : len(v):  75\n",
      "\t Data error_data : type(v):  <class 'str'> : len(v):  104\n",
      "\t Data survival_data : type(v):  <class 'str'> : len(v):  134\n",
      "Experiment : type(value):  <class 'dict'> : len(value):  3\n",
      "Now, looking at each subdictionaries:\n",
      "\t Experiment Biophysical_info : type(v):  <class 'dict'> : len(v):  4\n",
      "\t Experiment Original_values : type(v):  <class 'dict'> : len(v):  8\n",
      "\t Experiment Publication : type(v):  <class 'dict'> : len(v):  2\n",
      "Header : type(value):  <class 'dict'> : len(value):  4\n",
      "Now, looking at each subdictionaries:\n",
      "\t Header created_by : type(v):  <class 'str'> : len(v):  24\n",
      "\t Header date : type(v):  <class 'str'> : len(v):  28\n",
      "\t Header dependence : type(v):  <class 'str'> : len(v):  13\n",
      "\t Header user : type(v):  <class 'str'> : len(v):  5\n"
     ]
    }
   ],
   "source": [
    "# Function that takes a json file and returns a dictionary of innermost elements\n",
    "import json\n",
    "\n",
    "print(myJson)\n",
    "\n",
    "with open(myJson, 'r') as json_file:\n",
    "    python_obj = json.load(json_file)\n",
    "    print(\"\\n Keys: \", python_obj.keys(), \"\\n\")\n",
    "    #print (json.dumps(python_obj, sort_keys=True, indent=4), \"\\n\") #works\n",
    "    for key, value in python_obj.items():\n",
    "        print(key, \": type(value): \", type(value),  \": len(value): \", len(value))\n",
    "        print(\"Now, looking at each subdictionaries:\")\n",
    "        for k, v in value.items():\n",
    "            print(\"\\t\", key, k, \": type(v): \", type(v),  \": len(v): \", len(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "dose_data\n",
      "error_data\n",
      "survival_data\n",
      "Experiment\n",
      "Biophysical_info\n",
      "cell_line\n",
      "energy\n",
      "let\n",
      "modality\n",
      "Original_values\n",
      "alpha\n",
      "alpha_X\n",
      "alpha_X_err\n",
      "alpha_err\n",
      "beta\n",
      "beta_X\n",
      "beta_X_err\n",
      "beta_err\n",
      "Publication\n",
      "author\n",
      "year\n",
      "Header\n",
      "created_by\n",
      "date\n",
      "dependence\n",
      "user\n"
     ]
    }
   ],
   "source": [
    "# I got 'isinstance(obj, MyClass)' idea from\n",
    "# https://stackoverflow.com/questions/707674/how-to-compare-type-of-an-object-in-python\n",
    "def returnDictKeysRecursive(obj):\n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            print(key)\n",
    "            if isinstance(value, dict):\n",
    "                returnDictKeysRecursive(value)\n",
    "\n",
    "with open(myJson, 'r') as json_file:\n",
    "    python_obj = json.load(json_file)\n",
    "    returnDictKeysRecursive(python_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len:  27 ['Data', 'dose_data', 'error_data', 'survival_data', 'Experiment', 'Biophysical_info', 'cell_line', 'energy', 'let', 'modality', 'Original_values', 'alpha', 'alpha_X', 'alpha_X_err', 'alpha_err', 'beta', 'beta_X', 'beta_X_err', 'beta_err', 'Publication', 'author', 'year', 'Header', 'created_by', 'date', 'dependence', 'user'] \n",
      "\n",
      "Len:  21 ['dose_data', 'error_data', 'survival_data', 'cell_line', 'energy', 'let', 'modality', 'alpha', 'alpha_X', 'alpha_X_err', 'alpha_err', 'beta', 'beta_X', 'beta_X_err', 'beta_err', 'author', 'year', 'created_by', 'date', 'dependence', 'user'] \n",
      "\n",
      "{'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, 'let': 6, 'modality': 7, 'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, 'beta': 12, 'beta_X': 13, 'beta_X_err': 14, 'beta_err': 15, 'author': 16, 'year': 17, 'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21} \n",
      "\n",
      "{'dose_data': '0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.925 3.925 5.9 5.9 5.9 5.9 7.86', 'error_data': '0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.0052 0.0069 0.0050 0.0020 0.0008 0.0003 0.0009 0.0004 0.0001', 'survival_data': '0.561245 0.391369 0.256977 0.189925 0.138746 0.145901 0.057546 0.087797 0.038226 0.024148 0.008795 0.004251 0.003369 0.002031 0.000471', 'cell_line': 'HFIB2', 'energy': '6MV', 'let': '-keV/$\\\\mu$m', 'modality': 'photons', 'alpha': '0.689', 'alpha_X': '0.689', 'alpha_X_err': '0.164', 'alpha_err': '0.164', 'beta': '0.041', 'beta_X': '0.041', 'beta_X_err': '0.015', 'beta_err': '0.015', 'author': 'Slonina', 'year': '2014', 'created_by': 'Plot Digitizer     2.6.8', 'date': 'Date: 3/10/18     7:52:58 AM', 'dependence': 'SF(Dose (Gy))', 'user': 'pawel'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function that takes a json file and returns a dictionary of innermost elements\n",
    "import json\n",
    "path = \"/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/\"\n",
    "file = \"Slonina-2014/Slonina-2014-Fig3A-photons-6MV-HFIB2.json\"\n",
    "myJson = path + file\n",
    "\n",
    "# I got 'isinstance(obj, MyClass)' idea from\n",
    "# https://stackoverflow.com/questions/707674/how-to-compare-type-of-an-object-in-python\n",
    "def returnAllKeysList(obj):\n",
    "    allKeys = []\n",
    "    def returnDictKeysRecursiveN(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key, value in obj.items():\n",
    "                #print(key)\n",
    "                allKeys.append(key)\n",
    "                if isinstance(value, dict):\n",
    "                    returnDictKeysRecursiveN(value)\n",
    "    #The recursive function has to be called, otherwise, it will be skipped\n",
    "    #   and the list will stay unappended and therefore, zero-sized.\n",
    "    returnDictKeysRecursiveN(obj)\n",
    "    return allKeys\n",
    "\n",
    "\n",
    "def returnDeepKeysList(obj):\n",
    "    deepKeys = []\n",
    "    def returnDictKeysRecursiveN(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            for key, value in obj.items():\n",
    "                if isinstance(value, dict):\n",
    "                    returnDictKeysRecursiveN(value)\n",
    "                else:\n",
    "                    #print(key)\n",
    "                    deepKeys.append(key)\n",
    "   \n",
    "    #The recursive function has to be called, otherwise, it will be skipped\n",
    "    #   and the list will stay unappended and therefore, zero-sized.\n",
    "    returnDictKeysRecursiveN(obj)\n",
    "    return deepKeys\n",
    "\n",
    "\n",
    "def returnDeepKeysDict(obj):\n",
    "    deepDict = dict()\n",
    "    val = 0\n",
    "    dVal = {'y' : 0} #https://technotroph.wordpress.com/2012/10/01/python-closures-and-the-python-2-7-nonlocal-solution/\n",
    "    def returnDictKeysRecursive(obj):\n",
    "        #https://stackoverflow.com/questions/11987358/why-nested-functions-can-access-variables-from-outer-functions-but-are-not-allo\n",
    "        nonlocal val #Valid only for Python 3.x ()\n",
    "\n",
    "        if isinstance(obj, dict):\n",
    "            for key, value in obj.items():\n",
    "                if isinstance(value, dict):\n",
    "                    returnDictKeysRecursive(value)\n",
    "                else:\n",
    "                    #print(key)\n",
    "                    #deepKeys.append(key)\n",
    "                    #val = val + 1\n",
    "                    dVal['y'] += 1   # Valid for both Python 2.x and 3.x\n",
    "                    #return dVal['y']\n",
    "\n",
    "                    #deepDict[key] = val #This is equivalent to append (it adds a key-value pair to the dictionary)\n",
    "                    deepDict[key] = dVal['y'] #This is equivalent to append (it adds a key-value pair to the dictionary)\n",
    "                    \n",
    "\n",
    "   \n",
    "    #The recursive function has to be called, otherwise, it will be skipped\n",
    "    #   and the list will stay unappended and therefore, zero-sized.\n",
    "    returnDictKeysRecursive(obj)\n",
    "    return deepDict\n",
    "\n",
    "def returnDeepDict(obj):\n",
    "    deepDict = dict()\n",
    "    val = 0\n",
    "    dVal = {'y' : \" \"} #https://technotroph.wordpress.com/2012/10/01/python-closures-and-the-python-2-7-nonlocal-solution/\n",
    "    def returnDictKeysRecursive(obj):\n",
    "        #https://stackoverflow.com/questions/11987358/why-nested-functions-can-access-variables-from-outer-functions-but-are-not-allo\n",
    "        nonlocal val #Valid only for Python 3.x (), so not used here.\n",
    "\n",
    "        if isinstance(obj, dict):\n",
    "            for key, value in obj.items():\n",
    "                if isinstance(value, dict):\n",
    "                    returnDictKeysRecursive(value)\n",
    "                else:\n",
    "                    #print(key)\n",
    "                    #deepKeys.append(key)\n",
    "                    #val = val + 1\n",
    "                    #dVal['y'] += 1   # Valid for both Python 2.x and 3.x\n",
    "                    dVal['y'] = value   # Valid for both Python 2.x and 3.x\n",
    "                    #return dVal['y']\n",
    "\n",
    "                    #deepDict[key] = val #This is equivalent to append (it adds a key-value pair to the dictionary)\n",
    "                    deepDict[key] = dVal['y'] #This is equivalent to append (it adds a key-value pair to the dictionary)\n",
    "                    \n",
    "\n",
    "   \n",
    "    #The recursive function has to be called, otherwise, it will be skipped\n",
    "    #   and the list will stay unappended and therefore, zero-sized.\n",
    "    returnDictKeysRecursive(obj)\n",
    "    return deepDict\n",
    "\n",
    "with open(myJson, 'r') as json_file:\n",
    "    python_obj = json.load(json_file)\n",
    "    #returnDictKeysRecursiveNN(python_obj)\n",
    "    AllKeys = returnAllKeysList(python_obj)\n",
    "    print(\"Len: \", len(AllKeys), AllKeys, \"\\n\")    \n",
    "    DeepKeys = returnDeepKeysList(python_obj)\n",
    "    print(\"Len: \", len(DeepKeys), DeepKeys, \"\\n\")\n",
    "    DeepKeysDict = returnDeepKeysDict(python_obj)\n",
    "    print(DeepKeysDict,\"\\n\")    \n",
    "    DeepDict = returnDeepDict(python_obj)\n",
    "    print(DeepDict, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notes on unphysical values of RBE and RBE_Err\n",
    "\n",
    "I assigned arbitrary negative values of -1, -2, -3, and -4 etc when evaluating these quantities.\n",
    "#### RBE\n",
    "* -1.0: when **if taP == None or tbP == None or taX == None or tbX == None:** condition is satisfied i.e. either of the strings for the four numbers are of None type.\n",
    "* -2.0: If the quantity at the denominator for RBE evaluation turs out to be zero, leading to undefined or infinite as the value for RBE.\n",
    "* -3.0: If **if taP and tbP and taX and tbX:** is not satisfied.\n",
    "\n",
    "#### RBE_Err\n",
    "* -1: when either of the 8 variables (such as taP  = Dict.get('alpha')) comes out to be of **None** or **None type**\n",
    "* -2: I realized, I haven't used it yet\n",
    "* -3: I give this value when **if int(u) and int(v) and int(x) and int(y) and int(du) and int(dv) and int(dx) and int(dy)** condition fails.\n",
    "* -4: Sometimes, despite all seeming to be fine, I got in tractable error such as **Python: ValueError: could not convert string to float: '0.012'** when I was trying to evaluate **dx = float(Dict.get('alpha_X_err'))** etc. Spent quite sometime to figure out the reason, but to no avail. So, I decided to put all eight such lines within the try block and assigned a value of -4.0 to the RBE_Err when the try block throws an **ValueError** exception.\n",
    "* **Zero division:** While calculating the partial derivatives, if Zero division occurred, I used exception to set it's value to zero. Sometimes, all four partial derivatives had such situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keysDict: \n",
      " {'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, 'let': 6, 'modality': 7, 'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, 'beta': 12, 'beta_X': 13, 'beta_X_err': 14, 'beta_err': 15, 'author': 16, 'year': 17, 'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21}\n",
      "1 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Slonina-2014/Slonina-2014-Fig3B-protons-60MeV-HFIB15.json is Empty, byte-size =  0 \n",
      "\n",
      "10 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-1.json is Empty, byte-size =  0 \n",
      "\n",
      "12 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-2a.json is Empty, byte-size =  0 \n",
      "\n",
      "15 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Robertson-1994/Robertson-1994-Fig3A-protons-155MeV-line-3.json is Empty, byte-size =  0 \n",
      "\n",
      "51 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Gueulette-1996/Gueulette-1996-Fig1-protons-85MeV-distal-30mmSOBP.json is Empty, byte-size =  0 \n",
      "\n",
      "Dictionary has empty values?\n",
      "55 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Folkard-1996/Folkard-1996-Fig3a-protons-10keVum-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "Dictionary has empty values?\n",
      "98 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Britten-2013/Britten-2013-Fig2-protons-87MeV-20.5keVum-V79-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "109 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Britten-2013/Britten-2013-Fig2-protons-87MeV-20.5keVum-V79-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "Dictionary has empty values?\n",
      "252 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Tang-1997/Tang-1997-Fig2D-photons-Cs137-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "273 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Guan-2015/Guan-2015-LQM-params-LET-dep-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "282 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Guan-2015/Guan-2015-LQM-params-LET-dep.json gives empty-valued Dictionary \n",
      "\n",
      "302 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Schuff-2002/Schuff-2002-Fig7-photons-Cs137-PDVC57.json is Empty, byte-size =  0 \n",
      "\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Caught ValueError Exception\n",
      "Dictionary has empty values?\n",
      "358 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Belli-1998/Belli-1998-Fig1b-protons-7.7keVum-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Caught ValueError Exception\n",
      "359 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Belli-1998/Belli-1998-Fig1-30.5keVum.json is Empty, byte-size =  0 \n",
      "\n",
      "Dictionary has empty values?\n",
      "368 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2H-protons-190MeV-HSG-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "371 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2F-protons-190MeV-HSG-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Dictionary has empty values?\n",
      "372 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Matsumoto-2014/Matsumoto-2014-Fig2F-protons-190MeV-HSG-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Dictionary has empty values?\n",
      "418 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Howard-2018/Howard-2018-Fig3A-protons-71MeV-CHO-positionD1-Win8.1-sff.json gives empty-valued Dictionary \n",
      "\n",
      "Invalid key:  E\n",
      "Invalid key:  mod\n",
      "Dictionary has empty values?\n",
      "473 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Howard-2018/Howard-2018-Fig3A-protons-71MeV-CHO-positionD1-Win8.1.json gives empty-valued Dictionary \n",
      "\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "df_dx: Caught ZeroDivisionError Exception\n",
      "df_dy: Caught ZeroDivisionError Exception\n",
      "df_du: Caught ZeroDivisionError Exception\n",
      "df_dv: Caught ZeroDivisionError Exception\n",
      "503 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Miller-1995/Miller-1995-Fig1C-protons-15keVum.json is Empty, byte-size =  0 \n",
      "\n",
      "503 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Perris-1986/Perris-1986-Fig3a-photons-Co60-V79.json is Empty, byte-size =  0 \n",
      "\n",
      "505 ^th file:  /Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson/Perris-1986/Perris-1986-Fig3a-photons-Co60.json is Empty, byte-size =  0 \n",
      "\n",
      "Total # of processed files:  518\n"
     ]
    }
   ],
   "source": [
    "import xlsxwriter\n",
    "import json\n",
    "import os, fnmatch\n",
    "import math #For log() method to evaluate natural log (Ln)\n",
    "\n",
    "def findFiles (path, filter):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in fnmatch.filter(files, filter):\n",
    "            yield os.path.join(root, file)\n",
    "            \n",
    "\"\"\"            \n",
    "keysDict = {'dose_data': 1, 'error_data': 2, 'survival_data': 3, 'cell_line': 4, 'energy': 5, \n",
    "            'let': 6, 'modality': 7, 'alpha': 8, 'alpha_X': 9, 'alpha_X_err': 10, 'alpha_err': 11, \n",
    "            'beta': 12, 'beta_X': 13, 'beta_X_err': 14, 'beta_err': 15, 'author': 16, 'year': 17, \n",
    "            'created_by': 18, 'date': 19, 'dependence': 20, 'user': 21}\n",
    "\"\"\"\n",
    "keysDict = returnDeepKeysDict(python_obj)\n",
    "print(\"keysDict: \\n\", keysDict)\n",
    " \n",
    "    \n",
    "# Function that takes a json file and returns a dictionary of innermost elements\n",
    "def return_inner_dict(jsonFile):\n",
    "    dic = dict()    # new dictionary\n",
    "    #valueList.clear() #This will make the list an empty one without any cells/elements\n",
    "    with open(jsonFile, 'r') as json_file: #This way file is auto-closed\n",
    "        data = json.load(json_file)\n",
    "\n",
    "        dic = returnDeepDict(data) #(python_obj)\n",
    "    return dic\n",
    "\n",
    "\n",
    "def check_if_values_empty(Dict):\n",
    "    allValues = ''\n",
    "    for key, aValue in Dict.items():  \n",
    "        #print(type(aValue), key, aValue)\n",
    "        allValues = allValues + aValue\n",
    "    \n",
    "    #if allValues == None:\n",
    "    if len(allValues) == 0:\n",
    "        print(\"Dictionary has empty values?\")\n",
    "        return True\n",
    "    else:\n",
    "        #print(\"Dictionary has non-empty values:\\n\", allValues)\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "def return_RBE(Dict):\n",
    "    taP = Dict.get('alpha')\n",
    "    tbP  = Dict.get('beta')\n",
    "    taX = Dict.get('alpha_X')\n",
    "    tbX  = Dict.get('beta_X')\n",
    "    \"\"\"\n",
    "    print('Dict: ', type(Dict), 'len(Dict)=', len(Dict), \n",
    "         taP, tbP, taX, tbX, type(taP), type(tbP), type(taX), type(tbX) )\n",
    "    \"\"\"\n",
    "    if taP == None or tbP == None or taX == None or tbX == None:\n",
    "        return -1.0\n",
    "    else:\n",
    "        if taP and tbP and taX and tbX:\n",
    "            alphaP = float(Dict.get('alpha')) \n",
    "            betaP  = float(Dict.get('beta'))\n",
    "            alphaX = float(Dict.get('alpha_X'))\n",
    "            betaX  = float(Dict.get('beta_X'))\n",
    "            lnSF = math.log(0.1) #natural log of SF = 0.1 (SF = 10%)\n",
    "\n",
    "            #sqrtNumer = math.sqrt(math.pow(alphaX, 2) - 4 * betaX * lnSF)\n",
    "            #sqrtDenom = math.sqrt(math.pow(alphaP, 2) - 4 * betaP * lnSF)\n",
    "            #sqrtNumer = math.sqrt(alpha_X**2 - 4*beta_X*lnSF)\n",
    "            #sqrtDenom = math.sqrt(alpha_P**2 - 4*beta_P*lnSF)\n",
    "\n",
    "            sqrtNumer = math.sqrt(alphaX * alphaX - 4*betaX*lnSF)\n",
    "            sqrtDenom = math.sqrt(alphaP * alphaP - 4*betaP*lnSF)\n",
    "            RBEnumer = (sqrtNumer - alphaX) * betaP\n",
    "            RBEdenom = (sqrtDenom - alphaP) * betaX\n",
    "            if RBEdenom == 0:\n",
    "                return -2.0\n",
    "            else:\n",
    "                RBE = RBEnumer/RBEdenom\n",
    "                return RBE\n",
    "        else:\n",
    "            return -3.0\n",
    "\n",
    "\n",
    "        \n",
    "def return_RBE_Err(Dict):\n",
    "    #print(Dict)\n",
    "    taP  = Dict.get('alpha')\n",
    "    tbP  = Dict.get('beta')\n",
    "    taX  = Dict.get('alpha_X')\n",
    "    tbX  = Dict.get('beta_X')\n",
    "    taPe  = Dict.get('alpha_err')\n",
    "    tbPe  = Dict.get('beta_err')\n",
    "    taXe  = Dict.get('alpha_X_err')\n",
    "    tbXe  = Dict.get('beta_X_err')\n",
    "    \"\"\"\n",
    "    print(type(taP), type(tbP), type(taX), type(tbX), type(taPe), \\\n",
    "                  type(tbPe), type(taXe), type(tbXe), \\\n",
    "                  taP, tbP, taX, tbX, taPe, tbPe, taXe, tbXe)\n",
    "    \"\"\"\n",
    "    \n",
    "    if taP == None or tbP == None or taX == None or tbX == None or \\\n",
    "    taPe == None or tbPe == None or taXe == None or tbXe == None:\n",
    "        return -1.0\n",
    "    else:\n",
    "        lnSF = math.log(0.1) #natural log of SF = 0.1 (SF = 10%)\n",
    " \n",
    "        try:\n",
    "            #print(int('a'))\n",
    "            # you can just use strip() instead of strip('\\n') - it stripes all whitespaces automatically – yedpodtrzitko Feb 5 '17 at 19:08\n",
    "            # https://stackoverflow.com/questions/42013867/valueerror-could-not-convert-string-to-float-0-274697-n\n",
    "            u  = float(taP)   #For P\n",
    "            v  = float(tbP)   #For P\n",
    "            x  = float(taX)   #For X\n",
    "            y  = float(tbX)   #For X\n",
    "            # https://stackoverflow.com/questions/48075861/valueerror-could-not-convert-string-to-float\n",
    "            du = float(taPe.strip()) # str.strip(\"x\") removes x from str etc.\n",
    "            dv = float(tbPe.strip())\n",
    "            dx = float(Dict.get('alpha_X_err')) #float(taXe.strip())\n",
    "            dy = float(tbXe.strip())\n",
    "\n",
    "        except ValueError:\n",
    "            print ('Caught ValueError Exception')\n",
    "            return -4.0\n",
    "\n",
    "        if taP and tbP and taX and tbX and taPe and tbPe and taXe and tbXe:\n",
    "        #if int(u) and int(v) and int(x) and int(y) and \\\n",
    "        #    int(du) and int(dv) and int(dx) and int(dy):\n",
    "        #if u and v and x and y and du and dv and dx and dy:\n",
    "\n",
    "\n",
    "            sqrtXU = math.sqrt(x - 4*u*lnSF)\n",
    "            sqrtYV = math.sqrt(y - 4*v*lnSF)\n",
    "            # Now the partial derivatives (df_dx means df/dx & so on)\n",
    "            # Derived by myself but also Verified @ https://www.derivative-calculator.net/#\n",
    "            # https://en.wikipedia.org/wiki/Propagation_of_uncertainty\n",
    "            # f = RBE = [(sqrt(x - 4 u lnSF) - x) / (sqrt(y - 4 v lnSF) - y)] * v/u\n",
    "            try:\n",
    "                df_dx = ( v/(u*(sqrtYV - y))) * ( 1/(2*sqrtXU) - 1) \n",
    "            except ZeroDivisionError:\n",
    "                print('df_dx: Caught ZeroDivisionError Exception')\n",
    "                df_dx = 0\n",
    "\n",
    "            try:\n",
    "                df_dy = - (v/u)*((sqrtXU - x)/math.pow((sqrtYV - y),2))*(1/(2*sqrtYV) - 1)\n",
    "            except ZeroDivisionError:\n",
    "                print('df_dy: Caught ZeroDivisionError Exception')\n",
    "                df_dy = 0\n",
    "            try:\n",
    "                df_du = - (v/(u*u))*(sqrtXU - x)/(sqrtYV - y)  - 2*v*lnSF/(u*sqrtXU*(sqrtYV - y))\n",
    "            except ZeroDivisionError:\n",
    "                print('df_du: Caught ZeroDivisionError Exception')\n",
    "                df_du = 0\n",
    "            try:\n",
    "                df_dv = (sqrtXU - x)/((sqrtYV - y)*u) \\\n",
    "                    + 2*v*lnSF*(sqrtXU - x)/(u*sqrtYV*math.pow((sqrtYV - y),2))\n",
    "            except ZeroDivisionError:\n",
    "                print('df_dv: Caught ZeroDivisionError Exception')\n",
    "                df_dv = 0\n",
    "            \"\"\"   \n",
    "            RBEerr = math.sqrt(df_dx*df_dx * dx + df_dy*df_dy * dy \\\n",
    "                              + df_du*df_du * dy  + df_dv*df_dv * dv)\n",
    "                              \"\"\"\n",
    "            RBEerr = math.sqrt(df_dx*df_dx * dx*dx + df_dy*df_dy * dy*dy \\\n",
    "                              + df_du*df_du * du*du  + df_dv*df_dv * dv*dv)\n",
    "            return RBEerr\n",
    "        else:\n",
    "            return -3.0\n",
    "        \n",
    "        \n",
    "# Creating an Excel file. \n",
    "workbook = xlsxwriter.Workbook('testRBE.xlsx')\n",
    "\n",
    "# workbook object used to add new worksheet via add_worksheet() method. \n",
    "worksheet = workbook.add_worksheet()\n",
    "\n",
    "# Widen the first 3-columns a little bit (contents are large strings).\n",
    "worksheet.set_column('A:A', 20)\n",
    "worksheet.set_column(0,1, 20)\n",
    "worksheet.set_column(0,2, 20)\n",
    "\n",
    "# Add a bold format to use to highlight cells.\n",
    "bold = workbook.add_format({'bold': True})\n",
    "\n",
    "#Writing Headers in the first row \n",
    "for hKeys, hValues in keysDict.items():\n",
    "    worksheet.write(0, hValues-1, hKeys, bold) #kp: row, col, values, style\n",
    "\n",
    "#Next to Last column is for RBE (which is calculated using eq 7 of Chen-Ahmad-2012.pdf)\n",
    "worksheet.write(0, len(keysDict), \"RBE\", bold) #kp: row, col, values, style\n",
    "\n",
    "#Last column is for RBEerr (which is calculated using eq 7 of Chen-Ahmad-2012.pdf\n",
    "#  for RBE and then error propagation formula (through partial derivatives)\n",
    "worksheet.write(0, len(keysDict) + 1, \"RBE_err\", bold) #kp: row, col, values, style\n",
    "\n",
    "    \n",
    "####### Now iterating over several json files and writing their values in different rows.\n",
    "j = 0\n",
    "#for jsonFile in findFiles(r'/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff', '*.json'):  \n",
    "for jsonFile in findFiles(r'/Users/kpadhikari/GitProj/KPAdhikari/EVMS_stuff/ArticlesWdSSFsAndJson', \\\n",
    "                          '*.json'):  \n",
    "    #print(jsonFile)\n",
    "    b = os.path.getsize(jsonFile)\n",
    "    if b==0:\n",
    "        print(j,\"^th file: \", jsonFile, \"is Empty, byte-size = \", b,\"\\n\")\n",
    "        continue\n",
    "\n",
    "    retDict = return_inner_dict(jsonFile)\n",
    "    #print(jsonFile, b, \" len(retDict): \", len(retDict))\n",
    "    #print(retDict,\"\\n\\n\")\n",
    "    if check_if_values_empty(retDict):\n",
    "        print (j,\"^th file: \", jsonFile, \"gives empty-valued Dictionary \\n\")\n",
    "        continue\n",
    "    \n",
    "    if len(retDict) > 0:\n",
    "        RBE = return_RBE(retDict)\n",
    "        RBE_Err = return_RBE_Err(retDict) # showed some intractable error (so abandoned 10/9/19)\n",
    "        \n",
    "    # First writing the RBE value in the last column\n",
    "    if RBE:\n",
    "        worksheet.write(j+1, len(keysDict), RBE)\n",
    "        #print('RBE=', RBE)\n",
    "        \n",
    "    if RBE_Err:\n",
    "        worksheet.write(j+1, len(keysDict)+1, RBE_Err)\n",
    "        \n",
    "\n",
    "    for key, aValue in retDict.items():  \n",
    "        #col = keysDict[key] # Mostly worked but sometimes got \"KeyError: 'E'\"\n",
    "        col = keysDict.get(key) #Returns 0 if key not found in the Dict\n",
    "        if col:\n",
    "            worksheet.write(j+1, col-1, aValue)\n",
    "        else:\n",
    "            print(\"Invalid key: \", key)\n",
    "            #continue\n",
    "        \n",
    "    j+=1  #Equivalent to i++ or i = i+1 in C/C++/Java    \n",
    "    \n",
    "print(\"Total # of processed files: \", j)    \n",
    "    \n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GoTop](#GoTop) <a id='ReadingAndProcessingExcelDataWithPandas'></a>\n",
    "## Reading And Processing Excel Data With [Pandas](https://pythonspot.com/read-excel-with-pandas/)\n",
    "Here, I am going to use the Excel file 'testRBE.xlsx' generated by above cell (requires running the previous cell first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headings:\n",
      "Index(['dose_data', 'error_data', 'survival_data', 'cell_line', 'energy',\n",
      "       'let', 'modality', 'alpha', 'alpha_X', 'alpha_X_err', 'alpha_err',\n",
      "       'beta', 'beta_X', 'beta_X_err', 'beta_err', 'author', 'year',\n",
      "       'created_by', 'date', 'dependence', 'user', 'RBE', 'RBE_err'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "\n",
    "#The method read_excel() reads the data into a Pandas Data Frame\n",
    "#df = pd.read_excel('testRBE.xlsx', sheetname='Sheet1') #TypeError: read_excel() got an unexpected keyword argument `sheetname`\n",
    "df = pd.read_excel('testRBE.xlsx')\n",
    "\n",
    "print(\"Column headings:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.9...\n",
       "1      0.9371 0.9317 0.9373 1.9201 1.9165 1.9203 2.92...\n",
       "2      1.1 1.1 1.1 2.1 2.1 2.1 2.1 3.08 3.08 3.08 4.0...\n",
       "3      2.4614 2.99502 3.52933 4.07486 4.57265 5.05268...\n",
       "4      2.98916 3.65812 4.32923 4.95304 5.73888 6.5380...\n",
       "                             ...                        \n",
       "513              0.51308 1.04227 2.07162 3.10034 4.14437\n",
       "514              0.36658 0.74813 1.51122 2.25187 3.00748\n",
       "515              0.46903 0.96961 1.95428 2.96388 3.96447\n",
       "516              0.50563 0.98524 1.96363 2.98491 4.98347\n",
       "517               0.47691 0.99366 2.03569 3.07822 4.1207\n",
       "Name: dose_data, Length: 518, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df['dose_data'])# works\n",
    "df['dose_data'] #Same result as above one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To iterate over all the rows/values of a particular column.\n",
    "#for i in df.index:\n",
    "#    print(df['RBE'][i])  #Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13520097966132488\n"
     ]
    }
   ],
   "source": [
    "print(df['RBE'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   set_of_numbers equal_or_lower_than_4?\n",
      "0               1                   True\n",
      "1               2                   True\n",
      "2               3                   True\n",
      "3               4                   True\n",
      "4               5                  False\n",
      "5               6                  False\n",
      "6               7                  False\n",
      "7               8                  False\n",
      "8               9                  False\n",
      "9              10                  False\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "Numbers = {'set_of_numbers': [1,2,3,4,5,6,7,8,9,10]}\n",
    "dft = DataFrame(Numbers,columns=['set_of_numbers'])\n",
    "\n",
    "dft['equal_or_lower_than_4?'] = dft['set_of_numbers'].apply(lambda x: 'True' if x <= 4 else 'False')\n",
    "\n",
    "print (dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5\n"
     ]
    }
   ],
   "source": [
    "print(dft['set_of_numbers'].mean()) #kp: imagine pairing up 1,10; 2,9 etc to make five elevens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(dft['set_of_numbers'].apply(lambda x: x if x <= 4 else 0 ).mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: set_of_numbers, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dft['set_of_numbers'].apply(lambda x: x if x <= 4 else 0 ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting rows in pandas DataFrame based on conditions\n",
    "Refs: \n",
    "* https://www.geeksforgeeks.org/selecting-rows-in-pandas-dataframe-based-on-conditions/\n",
    "* https://www.geeksforgeeks.org/python-pandas-extracting-rows-using-loc/\n",
    "\n",
    "Python is a great language for doing data analysis, primarily because of the fantastic ecosystem of data-centric Python packages. Pandas is one of those packages and makes importing and analyzing data much easier.\n",
    "\n",
    "Pandas provide a unique method to retrieve rows from a Data frame. **`DataFrame.loc[]`** method is a method that takes only index labels and returns row or dataframe if the index label exists in the caller data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result dataframe :\n",
      "    set_of_numbers equal_or_lower_than_4?\n",
      "4               5                  False\n",
      "5               6                  False\n",
      "6               7                  False\n",
      "7               8                  False\n",
      "8               9                  False\n",
      "9              10                  False\n"
     ]
    }
   ],
   "source": [
    "# selecting rows based on condition \n",
    "#rslt_df = dataframe.loc[(dataframe['Age'] == 21) & dataframe['Stream'].isin(options)] \n",
    "rslt_df = dft.loc[dft['set_of_numbers'] > 4]\n",
    "print('\\nResult dataframe :\\n', rslt_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.loc[dft['set_of_numbers'] > 4]['set_of_numbers'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8708286933869707"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.loc[dft['set_of_numbers'] > 4]['set_of_numbers'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7637626158259734"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft.loc[dft['set_of_numbers'] > 4]['set_of_numbers'].sem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard error of mean versus standard deviation\n",
    "(From https://en.wikipedia.org/wiki/Standard_error)\n",
    "\n",
    "In scientific and technical literature, experimental data are often summarized either using the mean and standard deviation of the sample data or the mean with the standard error. This often leads to confusion about their interchangeability. However, the mean and standard deviation are descriptive statistics, whereas the standard error of the mean is descriptive of the random sampling process. The standard deviation of the sample data is a description of the variation in measurements, while the standard error of the mean is a probabilistic statement about how the sample size will provide a better bound on estimates of the population mean, in light of the central limit theorem.[6]\n",
    "\n",
    "Put simply, the standard error of the sample mean is an estimate of how far the sample mean is likely to be from the population mean, whereas the standard deviation of the sample is the degree to which individuals within the sample differ from the sample mean.[7] If the population standard deviation is finite, the standard error of the mean of the sample will tend to zero with increasing sample size, because the estimate of the population mean will improve, while the standard deviation of the sample will tend to approximate the population standard deviation as the sample size increases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean, Standard Deviation (Std), and Standard Error of the Mean (SEM) of RBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3015959833256114"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using only those rows which have RBE > 0\n",
    "## kp: Doesn't exclude the values of 1.0 which are mostly from photon measurements.\n",
    "df.loc[df['RBE'] > 0]['RBE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6096575044330234"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['RBE'] > 0]['RBE'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036965915973938564"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['RBE'] > 0]['RBE'].sem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x10e15bbd0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df.hist(column='RBE') # didn't show the plot\n",
    "df.hist(column='RBE', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11ab40e90>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[df['RBE'] > 0].hist(column='RBE', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11ab59fd0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[(df['RBE'] > 0) & (df['RBE'] < 4 )].hist(column='RBE', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dose_data        270\n",
       "error_data       270\n",
       "survival_data    270\n",
       "cell_line        270\n",
       "energy           256\n",
       "let              256\n",
       "modality         256\n",
       "alpha            270\n",
       "alpha_X          270\n",
       "alpha_X_err      256\n",
       "alpha_err        270\n",
       "beta             270\n",
       "beta_X           270\n",
       "beta_X_err       256\n",
       "beta_err         270\n",
       "author           256\n",
       "year             256\n",
       "created_by       269\n",
       "date             258\n",
       "dependence       269\n",
       "user             269\n",
       "RBE              270\n",
       "RBE_err          236\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting # of rows or values for each column.\n",
    "df.loc[(df['RBE'] > 0) & (df['RBE'] < 4 )].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of                                              dose_data  \\\n",
       "0    0.975 0.975 1.95 1.95 1.95 2.95 2.95 3.925 3.9...   \n",
       "1    0.9371 0.9317 0.9373 1.9201 1.9165 1.9203 2.92...   \n",
       "2    1.1 1.1 1.1 2.1 2.1 2.1 2.1 3.08 3.08 3.08 4.0...   \n",
       "4    2.98916 3.65812 4.32923 4.95304 5.73888 6.5380...   \n",
       "14   2.77 3.72782 4.6139 5.49766 5.99775 6.4888 6.9...   \n",
       "..                                                 ...   \n",
       "510          0.8672 2.1824 3.3746 4.3794 5.4758 6.9867   \n",
       "511    0.45813 0.96001 1.94598 2.96899 3.94777 4.97858   \n",
       "512       0.50192 1.0169 2.05496 3.0858 4.1166 5.15486   \n",
       "516            0.50563 0.98524 1.96363 2.98491 4.98347   \n",
       "517             0.47691 0.99366 2.03569 3.07822 4.1207   \n",
       "\n",
       "                                            error_data  \\\n",
       "0    0.0406 0.0259 0.0234 0.0114 0.0274 0.0133 0.00...   \n",
       "1    0.0443 0.0586 0.0616 0.0337 0.0268 0.0284 0.01...   \n",
       "2    0.0437 0.0592 0.0614 0.0234 0.0125 0.0234 0.02...   \n",
       "4    0.0935 0.1033 0.0919 0.0885 0.0716 0.0524 0.03...   \n",
       "14   0.0453 0.0574 0.0568 0.0497 0.0468 0.0425 0.03...   \n",
       "..                                                 ...   \n",
       "510          0.0775 0.0466 0.0299 0.0166 0.0112 0.0045   \n",
       "511          0.0887 0.0652 0.0415 0.0164 0.0135 0.0078   \n",
       "512          0.0796 0.0763 0.0399 0.0202 0.0090 0.0044   \n",
       "516                 0.0960 0.0818 0.0651 0.0439 0.0310   \n",
       "517                 0.1054 0.0931 0.0698 0.0112 0.0040   \n",
       "\n",
       "                                         survival_data  cell_line   energy  \\\n",
       "0    0.561245 0.391369 0.256977 0.189925 0.138746 0...      HFIB2      6MV   \n",
       "1    0.6168 0.5441 0.4614 0.2673 0.2327 0.1916 0.14...     HFIB15      6MV   \n",
       "2    0.476535 0.308691 0.26827 0.242528 0.152355 0....      HFIB2    60MeV   \n",
       "4    0.648753 0.552893 0.461019 0.380798 0.29142 0....   V79-WNRE   155MeV   \n",
       "14   0.653716 0.522288 0.410044 0.308874 0.261367 0...   V79-WNRE     Co60   \n",
       "..                                                 ...        ...      ...   \n",
       "510          0.7851 0.5279 0.3029 0.1881 0.0877 0.0271       C320      4MV   \n",
       "511  0.732582 0.576396 0.426509 0.183467 0.119379 0...  C3H10T1/2  3.18MeV   \n",
       "512  0.705601 0.676471 0.380198 0.1788 0.085904 0.0...  C3H10T1/2  1.46MeV   \n",
       "516        0.914074 0.84156 0.575654 0.388259 0.200621  C3H10T1/2     Co60   \n",
       "517       0.692239 0.552152 0.284028 0.106974 0.041448  C3H10T1/2  0.87MeV   \n",
       "\n",
       "             let modality  alpha  alpha_X alpha_X_err  ...  beta_X_err  \\\n",
       "0    -keV/$\\mu$m  photons  0.689    0.689       0.164  ...       0.015   \n",
       "1    -keV/$\\mu$m  photons  0.627    0.627       0.028  ...       0.014   \n",
       "2    -keV/$\\mu$m  protons  0.855    0.689       0.164  ...       0.015   \n",
       "4              -  protons  0.060    0.087       0.000  ...       0.000   \n",
       "14             -  photons  0.087    0.087       0.000  ...       0.000   \n",
       "..           ...      ...    ...      ...         ...  ...         ...   \n",
       "510      -$\\mu$m  photons  0.160    0.110       0.028  ...       0.010   \n",
       "511            -  protons  0.470    0.240       0.060  ...       0.013   \n",
       "512            -  protons  0.430    0.240       0.060  ...       0.013   \n",
       "516            -  photons  0.240    0.240       0.060  ...       0.013   \n",
       "517            -  protons  0.550    0.240       0.060  ...       0.013   \n",
       "\n",
       "     beta_err     author  year                created_by  \\\n",
       "0       0.015    Slonina  2014  Plot Digitizer     2.6.8   \n",
       "1       0.014    Slonina  2014      Plot Digitizer 2.6.8   \n",
       "2       0.047    Slonina  2014      Plot Digitizer 2.6.8   \n",
       "4       0.000  Robertson  1994      Plot Digitizer 2.6.8   \n",
       "14      0.000  Robertson  1994      Plot Digitizer 2.6.8   \n",
       "..        ...        ...   ...                       ...   \n",
       "510     0.015     Kagawa  2002      Plot Digitizer 2.6.8   \n",
       "511     0.014    Bettega  1998      Plot Digitizer 2.6.8   \n",
       "512     0.013    Bettega  1998      Plot Digitizer 2.6.8   \n",
       "516     0.013    Bettega  1998      Plot Digitizer 2.6.8   \n",
       "517     0.031    Bettega  1998  Plot Digitizer     2.6.8   \n",
       "\n",
       "                             date     dependence   user       RBE   RBE_err  \n",
       "0    Date: 3/10/18     7:52:58 AM  SF(Dose (Gy))  pawel  1.000000  0.042785  \n",
       "1       Date: 11/23/18 9:29:45 PM  SF(Dose (Gy))  pawel  1.000000  0.033980  \n",
       "2        Date: 3/10/18 6:13:14 PM  SF(Dose (Gy))  pawel  1.180692  0.109128  \n",
       "4       Date: 4/18/19 11:26:28 AM  SF(Dose (Gy))  pawel  1.053528       NaN  \n",
       "14       Date: 4/25/19 1:44:42 PM  SF(Dose (Gy))  pawel  1.000000       NaN  \n",
       "..                            ...            ...    ...       ...       ...  \n",
       "510      Date: 11/1/18 9:03:57 PM  SF(Dose (Gy))  pawel  1.039822  0.106351  \n",
       "511     Date: 1/30/18 12:54:53 PM  SF(Dose (Gy))  pawel  1.586767  0.071380  \n",
       "512      Date: 1/30/18 1:04:02 PM  SF(Dose (Gy))  pawel  1.676500  0.050923  \n",
       "516     Date: 1/30/18 12:50:41 PM  SF(Dose (Gy))  pawel  1.000000  0.101889  \n",
       "517  Date: 1/30/18     1:18:40 PM  SF(Dose (Gy))  pawel  2.077551  0.084891  \n",
       "\n",
       "[270 rows x 23 columns]>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting # of rows or values for each column.\n",
    "df.loc[(df['RBE'] > 0) & (df['RBE'] < 4 )].count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean, Standard Deviation (Std), and Standard Error of the Mean (SEM) of RBE_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1310867142672295"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using only those rows which have RBE > 0\n",
    "df.loc[df['RBE_err'] > 0]['RBE_err'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26147489578456967"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using only those rows which have RBE > 0\n",
    "df.loc[df['RBE_err'] > 0]['RBE_err'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01758870487073011"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using only those rows which have RBE > 0\n",
    "df.loc[df['RBE_err'] > 0]['RBE_err'].sem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11af54250>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df.hist(column='RBE')\n",
    "df.hist(column='RBE_err', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11b05edd0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[df['RBE_err'] > 0].hist(column='RBE_err', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x11b303450>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.loc[(df['RBE_err'] > 0) & (df['RBE_err'] < 0.4 )].hist(column='RBE_err', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation and Comment after I came home from the meeting with PA/CK.\n",
    "When I went to the routine for RBE_err calculation to change the formula, I also found a typo of 'dy' in the third term where it was supposed to be 'du'. Similarly, when I squared each of those four factors after the typo correction, the SEM on errors came out to be about 0.017 (as close as Paganetti's value, which was 0.02).\n",
    "```py\n",
    "    \"\"\"\n",
    "            RBEerr = math.sqrt(df_dx*df_dx * dx + df_dy*df_dy * dy \\\n",
    "                              + df_du*df_du * dy  + df_dv*df_dv * dv)\n",
    "                              \"\"\"\n",
    "            RBEerr = math.sqrt(df_dx*df_dx * dx*dx + df_dy*df_dy * dy*dy \\\n",
    "                              + df_du*df_du * du*du  + df_dv*df_dv * dv*dv)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

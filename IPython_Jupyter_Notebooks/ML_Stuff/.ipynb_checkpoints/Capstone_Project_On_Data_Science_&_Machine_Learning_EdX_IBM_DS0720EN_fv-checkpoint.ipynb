{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61436a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/GitStuff/KPAdhikari/PythonStuff/IPython_Jupyter_Notebooks/ML_Stuff\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ddae88",
   "metadata": {},
   "source": [
    "### Project Description\n",
    "This capstone project is the last of a set of online [IBM (edX)](https://www.edx.org/school/ibm) courses on Data Science and Machine Learning that I took last year (2021) to get certificates (can be provided upon request or see my [credly badges](https://www.credly.com/users/krishna-adhikari.3c8047b8/badges)).  Following is the list of the courses that I successfully compelted before doing this project.\n",
    "\n",
    "1. Python Basics for Data Science\n",
    "2. SQL for Data Science\n",
    "3. Introduction to Data Science\n",
    "4. Data Science Tools\n",
    "5. The Data Science Method\n",
    "6. Visualizing Data with Python\n",
    "7. Analyzing Data with Python\n",
    "8. Machine Learning with Python: A Practical Introduction\n",
    "9. Data Science and Machine Learning Capstone Project\n",
    "\n",
    "In this project, I will be analyzing a historical data-set to allegedly help the State of New York efficiently handle complaints related to the housing and buildings that they receive through their 311 system. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279989a1",
   "metadata": {},
   "source": [
    "####  Prerequisites\n",
    "<font color=\"red\"> I may have to remove or modify this section </font>\n",
    "\n",
    "To successfully complete this capstone project, one must understand how to use data science techniques such as data analysis, data visualization, and machine learning by using Python. I completed this project after completing the other 8 courses listed above.\n",
    "\n",
    "#### Learning Objectives\n",
    "<font color=\"red\"> I may have to remove or modify this section </font>\n",
    "\n",
    "The objective of this project is to:\n",
    "* Showcase my data science and machine learning skills to solve real business problems.\n",
    "* Use data science methodologies to define and formulate a real-world business problem.\n",
    "* Use my data analysis tools to ingest a dataset, clean it, and wrangle it.\n",
    "* Use my data visualization skills to visualize the data and extract meaningful patterns to guide the modelling process.\n",
    "* Use my machine learning skills to build a predictive model to help a business function more efficiently.\n",
    "\n",
    "#### GRADING SCHEME\n",
    "<font color=\"red\"> I may have to remove or modify this section </font>\n",
    "    \n",
    "This was a graded project.\n",
    "The course contained 5 Graded Quizzes, 1 per module. Each Graded Quiz carried an equal weight of 20% of the total grade.\n",
    "  \n",
    "   The minimum passing mark for the course is 70%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5a4a66",
   "metadata": {},
   "source": [
    "### Organization of the Capstone Project\n",
    "\n",
    "This Capstone Project is organized in five modules. Each module should take about 1 week (2 to 4 hrs) to complete. \n",
    "\n",
    "#### Module 1 (Project Overview and Setup) \n",
    "In this Module you will get an overview of the Problem that you have to solve. The Problem you have to solve is broken into 4 specific questions. Those 4 questions are provided in the Problem Statement section of this module. \n",
    "\n",
    "#### Module 2 (Problem Set I: Identify Top Complaint Type) \n",
    "In this Module you will focus on solving the Question 1 provided in Problem Statement section of Module 1. This module includes a graded quiz with questions related to the Question you are addressing in this module.\n",
    "\n",
    "####  (Problem Set II: Identify Areas most affected by Top Complaint Type) \n",
    "In this Module you will focus on solving the Question 2 provided in Problem Statement section of Module 1. This module includes a graded quiz with questions related to the Question you are addressing in this module.\n",
    "\n",
    "#### Module 4 (Problem Set III: Identify Relationship between Building Characteristics and Top Complaint Type) \n",
    "In this Module you will focus on solving the Question 3 provided in Problem Statement section of Module 1. This module includes a graded quiz with questions related to the Question you are addressing in this module.\n",
    "\n",
    "#### Module 5 (Problem Set IV: Predict Top Complaint Type) \n",
    "In this Module you will focus on solving the Question 4 provided in Problem Statement section of Module 1. This module includes a graded quiz with questions related to the Question you are addressing in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70084d22",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "The people of New Yorker use the 311 system to report complaints about the non-emergency problems to local authorities. Various agencies in New York are assigned these problems. The Department of Housing Preservation and Development of New York City is the agency that processes 311 complaints that are related to housing and buildings.\n",
    "\n",
    "In the last few years, the number of 311 complaints coming to the Department of Housing Preservation and Development has increased significantly. Although these complaints are not necessarily urgent, the large volume of complaints and the sudden increase is impacting the overall efficiency of operations of the agency.\n",
    "\n",
    "Therefore, the Department of Housing Preservation and Development has approached your organization to help them manage the large volume of 311 complaints they are receiving every year.\n",
    "\n",
    "The agency needs answers to several questions. The answers to those questions must be supported by data and analytics. These are their questions:\n",
    "\n",
    "1. Which type of complaint should the Department of Housing Preservation and Development of New York City focus on first?\n",
    "2. Should the Department of Housing Preservation and Development of New York City focus on any particular set of boroughs, ZIP codes, or street (where the complaints are severe) for the specific type of complaints you identified in response to Question 1?\n",
    "3. Does the Complaint Type that you identified in response to question 1 have an obvious relationship with any particular characteristic or characteristics of the houses or buildings?\n",
    "4. Can a predictive model be built for a future prediction of the possibility of complaints of the type that you have identified in response to question 1?\n",
    "\n",
    "Your organization has assigned you as the lead data scientist to provide the answers to these questions. You need to work on getting answers to them in this Capstone Project by following the standard approach of data science and machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42768fa4",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "In order to answer these problems, I will analyze two datasets from the Department of Housing Preservation and Development of New York City.\n",
    "\n",
    "#### 311 complaint dataset\n",
    "\n",
    "I downloaded the data using [this](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0720EN-SkillsNetwork/labs/Module%201/data/311_Service_Requests_from_2010_to_Present_min.csv) link. This dataset will be used to address the questions of the project.\n",
    "\n",
    "This dataset is also available at https://data.cityofnewyork.us/Social-Services/311-Service-Requests-from-2010-to-Present/erm2-nwe9. (Note: This link points to live data which is updated on daily basis. Using this will not match the results of the questions as they are set as per the fixed dataset that is already mentioned above.) One can download part of this data by using SODA API.\n",
    "\n",
    "It is advised that it's good idea to download only the data that is related to the Department of Housing Preservation and Development. Also, it's better to restrict the data to the limited number of fields. Otherwise, the data size will be unnecessarily large, creating lots of issues such as making it very slow to process and analyze.\n",
    "\n",
    "#### PLUTO dataset for housing\n",
    "\n",
    "This dataset for housing can be accessed from https://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyc_pluto_18v1.zip. After downloading the data, I use only the part that is specific to the borough that I am interested in based on my analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c480c3",
   "metadata": {},
   "source": [
    "### Pickle in Python\n",
    "I used the raw data download at the beginning. But, later I used corresponding pickle files that I made out of the original data set.\n",
    "\n",
    "#### What is Pickling?\n",
    "\n",
    "When working with dictionaries, DataFrames, or any other data type, you might want to save them to a file, so you can use them later on or send them to someone else. This is what Python pickle module is for: it serializes objects so they can be saved to a file, and loaded in a program again later on.\n",
    "\n",
    "Pickle is used for serializing and de-serializing Python object structures, also called marshalling or flattening. Serialization refers to the process of converting an object in memory to a byte stream that can be stored on disk or sent over a network. Later on, this character stream can then be retrieved and de-serialized back to a Python object. The conversion of an object from one representation (data in Random Access Memory (RAM)) to another (text on disk), while the latter is the process of encoding data with fewer bits, in order to save disk space.\n",
    "#### Why we need Pickling?\n",
    "\n",
    "Storing the state of an object in a file or database can save time to process huge datasets in many data science projects. For example, you only need to pre-process the dataset once and save the model into a disk. Later you just need to deserialize it and reuse the pre-cooked model as many times as you want. This is definitely preferred to pre-processing it each time.\n",
    "#### What can pickle be used for?\n",
    "\n",
    "Pickling is useful for applications where you need some degree of persistency in your data. Your programs state data can be saved to disk, so you can continue working on it later on. Pickle is very useful for when you're working with machine learning algorithms, where you want to save them to be able to make new predictions at a later time, without having to rewrite everything or train the model all over again.\n",
    "#### When not to use pickle\n",
    "\n",
    "If you want to use data across different programming languages, pickle is not recommended. Its protocol is specific to Python, thus, cross-language compatibility is not guaranteed. The same holds for different versions of Python itself. Unpickling a file that was pickled in a different version of Python may not always work properly, so you have to make sure that you're using the same version and perform an update if necessary.\n",
    "#### What can be pickled?\n",
    "\n",
    "You can pickle objects with the following data types: Booleans, Integers, Floats, Complex numbers, (normal and Unicode) Strings, Tuples, Lists, Sets, and Dictionaries that ontain picklable objects. All the data types be pickled, but you can also do the same for classes and functions, for example, if they are defined at the top level of a module.\n",
    "\n",
    "#### Pickle in the peer graded assignment\n",
    "\n",
    "In the case of the capstone project, the 2 datasets are already present but they are very huge and reading them through the traditional approach each time is time consuming.\n",
    "\n",
    "So first time read it . Later convert it into byte stream (serialize) and the file which is in the serialized form is the pickle file.\n",
    "\n",
    "Here you are serializing the dataframe object(converting to bytes ) and saving it using a pickle file in the steps\n",
    "\n",
    "df.to_pickle('./df_raw.pkl')\n",
    "\n",
    "Later uploading it to cloud storage using the command.\n",
    "\n",
    "client_cred.upload_file('./df_raw.pkl',bucket,'df_raw_cos.pkl')\n",
    "\n",
    "To upload the file we need the client_credentials.\n",
    "\n",
    "This is present in the autogenerated code.\n",
    "\n",
    "For convenience in naming variables assign the autogenerated client credential variable to a new variable client_cred.\n",
    "\n",
    "client_cred= client_32cef856d9ba404c8f3df1dfc0c8cd51\n",
    "\n",
    "Note: The autogenerated client credentials variable is usually in this format.It will have the word prefix as client followed by alphanumeric characters. For Example : client32cef856d9ba404c8f3df1dfc0c8cd51) The autogenerated variable name may vary in the notebook.Assign the one generated in your notebook.\n",
    "\n",
    "Next we want to get back the dataframe from its saved location. For that we need to do the following steps.\n",
    "\n",
    "Download the file from Cloud Object Store:\n",
    "\n",
    "client_cred.download_file(Bucket=bucket,Key='df_raw_cos.pkl',Filename='./df_raw_local.pkl') Hence we need the bucket variable value.\n",
    "\n",
    "Here you are downloading the uploaded pickle file using your credentials information,converting the bytestream back to dataframe and reading the dataframe.\n",
    "\n",
    "So initially we create a bucket variable and assign it to. Next we replace the *** string with the bucket string that you got when you created a Panda Dataframe from the uploaded file in the previous section.\n",
    "\n",
    "The bucket string value is got from the Bucket key value present in the autogenerated code:\n",
    "\n",
    "clientcredentials.get_object(Bucket=\" \")\n",
    "\n",
    "Author(s)\n",
    "\n",
    "Malika Singla\n",
    "\n",
    "Other Contributor(s)\n",
    "\n",
    "Lakshmi Holla\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ee609",
   "metadata": {},
   "source": [
    "## More On Pickle\n",
    "Source: https://wiki.python.org/moin/UsingPickle\n",
    "\n",
    "### Flying Pickle Alert!\n",
    "Pickle files can be hacked. If you receive a raw pickle file over the network, don't trust it! It could have malicious code in it, that would run arbitrary python when you try to de-pickle it.\n",
    "\n",
    "However, if you are doing your own pickle writing and reading, you're safe. (Provided no one else has access to the pickle file, of course.)\n",
    "\n",
    "### What can you Pickle?\n",
    "Generally you can pickle any object if you can pickle every attribute of that object. Classes, functions, and methods cannot be pickled -- if you pickle an object, the object's class is not pickled, just a string that identifies what class it belongs to. This works fine for most pickles (but note the discussion about long-term storage of pickles).\n",
    "\n",
    "With pickle protocol v1, you cannot pickle open file objects, network connections, or database connections. When you think about it, it makes sense -- pickle cannot will the connection for file object to exist when you unpickle your object, and the process of creating that connection goes beyond what pickle can automatically do for you. If you really want to pickle something that has an attribute that is causing problems, look at the pickle documentation for **`__getstate__, __setstate__, and __getinitargs__`** -- using these you can exclude problematic attributes.\n",
    "\n",
    "With pickle protocol v2, you are able to pickle open file objects. This will change in a future version of Python. See this bug report for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ad4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

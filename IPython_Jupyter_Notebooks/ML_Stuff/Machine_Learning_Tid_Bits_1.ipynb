{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kpadhikari/Desktop/BigFls/CLAS12/GitProj/KPAdhikari/PythonStuff/IPython_Jupyter_Notebooks/ML_Stuff\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "#import pandas\n",
    "from pprint import pprint # we use this to pretty print some stuff later\n",
    "# everything in iminuit is done through the Minuit object, so we import it\n",
    "from iminuit import Minuit\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Tutorial On Machine Learning Pipelines With Scikit-Learn\n",
    "15/10/2020\n",
    "\n",
    "Ref: https://analyticsindiamag.com/hands-on-tutorial-on-machine-learning-pipelines-with-scikit-learn/\n",
    "\n",
    "With increasing demand in [machine learning](https://analyticsindiamag.com/top-8-books-on-machine-learning-in-cybersecurity-one-must-read/) and [data science in businesses](https://analyticsindiamag.com/23-latest-data-science-jobs-from-tech-giants-like-amazon-google-more/), for upgraded data strategizing there’s a need for a better workflow to ensure robustness in [data modelling](https://analyticsindiamag.com/50-latest-data-science-and-analytics-jobs-that-opened-last-week/). **Machine learning has certain steps** to be followed namely – **data collection, data preprocessing (cleaning and [feature engineering](https://analyticsindiamag.com/image-feature-extraction-using-scikit-image-a-hands-on-guide/)), model training, validation and prediction** on the test data (which is previously unseen by model). \n",
    "\n",
    "Here testing data needs to go through the same preprocessing as training data. For this iterative process, pipelines are used which can automate the entire process for both training and testing data. It ensures reusability of the model by reducing the redundant part, thereby speeding up the process. This could prove to be very effective during the [**production workflow**](https://analyticsindiamag.com/machine-learning-research-management-dan-malowany/).\n",
    "\n",
    "In this article, I’ll be discussing how to implement a machine learning pipeline using scikit-learn.\n",
    "\n",
    "### Advantages of using Pipeline:\n",
    "* Automating the workflow being iterative.\n",
    "* Easier to fix bugs \n",
    "* Production Ready\n",
    "* Clean code writing standards\n",
    "* Helpful in iterative hyperparameter tuning and cross-validation evaluation\n",
    "\n",
    "### Challenges in using Pipeline:\n",
    "* Proper data cleaning\n",
    "* Data Exploration and Analysis\n",
    "* Efficient feature engineering\n",
    "\n",
    "### Scikit-Learn Pipeline\n",
    "The sklearn.pipeline module implements utilities to build a composite estimator, as a chain of transforms and estimators.\n",
    "\n",
    "I’ve used the Iris dataset which is readily available in scikit-learn’s datasets library. The 6 columns in this dataset are: Id, SepalLength(in cm), SepalWidth(in cm), PetalLength(in cm), PetalWidth(in cm), Species(Target). 50samples containing 3 classes-Iris setosa, Iris Virginica, Iris versicolor.\n",
    "\n",
    "After loading the data, split it into training and testing then build pipeline object wherein standardization is done using StandardScalar() and dimensionality reduction using PCA(principal component analysis) both of these with be fit and transformed(these are transformers), lastly the model to use is declared here it is LogisticRegression, this is the estimator. The pipeline is fitted and the model performance score is determined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "iris_df=load_iris()\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_df.data,iris_df.target,test_size=0.3,random_state=0)\n",
    "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
    "                     ('pca1',PCA(n_components=2)),                     ('lr_classifier',LogisticRegression(random_state=0))])\n",
    "model = pipeline_lr.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    OUTPUT - 0.8666666666666667\n",
    "\n",
    "With the pipeline, we preprocess the training data and fit the model in a single line of code. In contrast, without a pipeline, we have to do normalization, dimensionality reduction, and model training in separate steps. This becomes especially messy if we have to deal with both numerical and categorical variables.\n",
    "\n",
    "Use the following two lines of code inside the Pipeline object for filling missing values and change categorical values to numeric. (Since iris dataset doesn’t contain these we are not using)\n",
    "\n",
    "```py\n",
    "('imputer', SimpleImputer(strategy='most_frequent')) #filling missing values\n",
    "\n",
    "(‘onehot', OneHotEncoder(handle_unknown='ignore'))    #convert categorical \n",
    "```\n",
    "\n",
    "Make sure to import OneHotEncoder and SimpleImputer modules from sklearn!\n",
    "\n",
    "### Stacking Multiple Pipelines to Find the Model with the Best Accuracy\n",
    "\n",
    "We build different pipelines for each algorithm and the fit to see which performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test Accuracy:0.8666666666666667\n",
      "Decision Tree Test Accuracy:0.9111111111111111\n",
      "Support Vector Machine Test Accuracy:0.9333333333333333\n",
      "K Nearest Neighbor Test Accuracy:0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
    "                     ('pca1',PCA(n_components=2)), \n",
    "                     ('lr_classifier',LogisticRegression())])\n",
    "pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
    "                     ('pca2',PCA(n_components=2)),\n",
    "                     ('dt_classifier',DecisionTreeClassifier())])\n",
    "pipeline_svm = Pipeline([('scalar3', StandardScaler()),\n",
    "                      ('pca3', PCA(n_components=2)),\n",
    "                      ('clf', svm.SVC())])\n",
    "pipeline_knn=Pipeline([('scalar4',StandardScaler()),\n",
    "                     ('pca4',PCA(n_components=2)),\n",
    "                     ('knn_classifier',KNeighborsClassifier())])\n",
    "#pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest, pipeline_knn]\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_svm, pipeline_knn]\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'Support Vector Machine',3:'K Nearest Neighbor'}\n",
    "for pipe in pipelines:\n",
    "  pipe.fit(X_train, y_train)\n",
    "for i,model in enumerate(pipelines):\n",
    "    print(\"{} Test Accuracy:{}\".format(pipe_dict[i],model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    OUTPUT:\n",
    "    Logistic Regression Test Accuracy: 0.8666666666666667\n",
    "    Decision Tree Test Accuracy: 0.9111111111111111\n",
    "    Support Vector Machine Test Accuracy: 0.9333333333333333\n",
    "    K Nearest Neighbor Test Accuracy: 0.9111111111111111\n",
    "    From the results, it’s clear that Support Vector Machines(SVM) perform better than other models.\n",
    "\n",
    "### Hyperparameter Tuning in Pipeline\n",
    "With pipelines, you can easily perform a **grid-search over a set of parameters** for each step of this meta-estimator to find the best performing parameters. To do this you first need to create a **parameter grid** for your chosen model. One important thing to note is that you need to append the name that you have given the classifier part of your pipeline to each parameter name. In my code above I have called this ‘randomforestclassifier’ so I have added randomforestclassifier__ to each parameter. Next, I created a grid search object which includes the original pipeline. When I then call fit, the transformations are applied to the data, before a cross-validated grid-search is performed over the parameter grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "pipe = make_pipeline((RandomForestClassifier()))\n",
    "grid_param = [\n",
    "{\"randomforestclassifier\": [RandomForestClassifier()],\n",
    "\"randomforestclassifier__n_estimators\":[10,100,1000],                    \n",
    " \"randomforestclassifier__max_depth\":[5,8,15,25,30,None],                 \n",
    " \"randomforestclassifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "\"randomforestclassifier__max_leaf_nodes\": [2, 5,10]}]\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) \n",
    "best_model = gridsearch.fit(X_train,y_train)\n",
    "best_model.score(X_test,y_test)\n",
    "print(best_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    OUTPUT - 0.9777777777777777\n",
    "\n",
    "### Conclusion\n",
    "This is a basic pipeline implementation. In real-life data science, scenario data would need to be prepared first then applied pipeline for rest processes. Building quick and efficient machine learning models is what pipelines are for. Pipelines are high in demand as it helps in coding better and extensible in implementing big data projects. Automating the applied machine learning workflow and saving time invested in redundant preprocessing work.\n",
    "\n",
    "The complete code of the above implementation is available at the AIM’s GitHub repository. Please visit [this link](https://github.com/analyticsindiamagazine/AIM-Code-Repo/blob/main/Developers%20Corner/ML%20pipeline.ipynb) to find the notebook with codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle in Python\n",
    "Ref: https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0720EN-SkillsNetwork/labs/Module 1/pickle.md.html\n",
    "\n",
    "Time Effort: 30 mins\n",
    "\n",
    "#### Learning Objective :\n",
    "\n",
    "    What is Pickling?\n",
    "\n",
    "    Why we need Pickling?\n",
    "\n",
    "    What can pickle be used for?\n",
    "\n",
    "    When not to use pickle\n",
    "\n",
    "    What can be pickled?\n",
    "\n",
    "    Pickle in the peer graded assignment\n",
    "\n",
    "#### What is Pickling?\n",
    "When working with dictionaries, DataFrames, or any other data type, you might want to save them to a file, so you can use them later on or send them to someone else. This is what Python pickle module is for: it serializes objects so they can be saved to a file, and loaded in a program again later on.\n",
    "\n",
    "Pickle is used for **serializing and de-serializing** Python object structures, also called marshalling or flattening. Serialization refers to the process of converting an object in memory to a byte stream that can be stored on disk or sent over a network. Later on, this character stream can then be retrieved and de-serialized back to a Python object. The conversion of an object from one representation (data in Random Access Memory (RAM)) to another (text on disk), while the latter is the process of encoding data with fewer bits, in order to save disk space.\n",
    "\n",
    "#### Why we need Pickling?\n",
    "Storing the state of an object in a file or database can save time to process huge datasets in many data science projects. For example, you only need to pre-process the dataset once and save the model into a disk. Later you just need to deserialize it and reuse the pre-cooked model as many times as you want. This is definitely preferred to pre-processing it each time.\n",
    "\n",
    "#### What can pickle be used for?\n",
    "Pickling is useful for applications where you need some degree of persistency in your data. Your programs state data can be saved to disk, so you can continue working on it later on. Pickle is very useful for when you're working with machine learning algorithms, where you want to save them to be able to make new predictions at a later time, without having to rewrite everything or train the model all over again.\n",
    "\n",
    "#### When not to use pickle\n",
    "If you want to use data across different programming languages, pickle is not recommended. Its protocol is specific to Python, thus, cross-language compatibility is not guaranteed. The same holds for different versions of Python itself. Unpickling a file that was pickled in a different version of Python may not always work properly, so you have to make sure that you're using the same version and perform an update if necessary.\n",
    "\n",
    "#### What can be pickled?\n",
    "You can pickle objects with the following data types: Booleans, Integers, Floats, Complex numbers, (normal and Unicode) Strings, Tuples, Lists, Sets, and Dictionaries that ontain picklable objects. All the data types be pickled, but you can also do the same for classes and functions, for example, if they are defined at the top level of a module.\n",
    "\n",
    "#### Pickle in the peer graded assignment\n",
    "In the case of the capstone project, the 2 datasets are already present but they are very huge and reading them through the traditional approach each time is time consuming.\n",
    "\n",
    "So first time read it . Later convert it into byte stream (serialize) and the file which is in the serialized form is the pickle file.\n",
    "\n",
    "Here you are serializing the dataframe object(converting to bytes ) and saving it using a pickle file in the steps\n",
    "```py\n",
    "df.to_pickle('./df_raw.pkl')\n",
    "```\n",
    "Later uploading it to cloud storage using the command.\n",
    "```py\n",
    "client_cred.upload_file('./df_raw.pkl',bucket,'df_raw_cos.pkl')\n",
    "```\n",
    "To upload the file we need the client_credentials.\n",
    "\n",
    "This is present in the autogenerated code.\n",
    "\n",
    "For convenience in naming variables assign the autogenerated client credential variable to a new variable client_cred.\n",
    "```py\n",
    "client_cred= client_32cef856d9ba404c8f3df1dfc0c8cd51\n",
    "```\n",
    "**Note: The autogenerated client credentials variable is usually in this format.It will have the word prefix as client followed by alphanumeric characters. For Example : client32cef856d9ba404c8f3df1dfc0c8cd51) The autogenerated variable name may vary in the notebook.Assign the one generated in your notebook.**\n",
    "\n",
    "Next we want to get back the dataframe from its saved location. For that we need to do the following steps.\n",
    "\n",
    "Download the file from Cloud Object Store:\n",
    "\n",
    "    client_cred.download_file(Bucket=bucket,Key='df_raw_cos.pkl',Filename='./df_raw_local.pkl') \n",
    "    \n",
    "Hence we need the bucket variable value.\n",
    "\n",
    "Here you are downloading the uploaded pickle file using your credentials information,converting the bytestream back to dataframe and reading the dataframe.\n",
    "\n",
    "So initially we create a bucket variable and assign it to. Next we replace the *** string with the bucket string that you got when you created a Panda Dataframe from the uploaded file in the previous section.\n",
    "\n",
    "The bucket string value is got from the Bucket key value present in the autogenerated code:\n",
    "\n",
    "    clientcredentials.get_object(Bucket=\" \")\n",
    "Author(s)\n",
    "\n",
    "Malika Singla\n",
    "\n",
    "Other Contributor(s)\n",
    "Lakshmi Holla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tmp: Some work as part of EdX course \"Data Science and Machine Learning Capstone Project\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas\n",
    "from pprint import pprint # we use this to pretty print some stuff later\n",
    "# everything in iminuit is done through the Minuit object, so we import it\n",
    "from iminuit import Minuit\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def makeSavePickles(file):\n",
    "    df = pd.read_csv('{}.csv'.format(file))    \n",
    "    df.to_pickle('{}.pkl'.format(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3361: DtypeWarning: Columns (19,20,22,23,64,65,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3361: DtypeWarning: Columns (20,23,24,26,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3361: DtypeWarning: Columns (19,20,22,23,64,65,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3361: DtypeWarning: Columns (19,20,22,23,24,64,65,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "path = \"/Users/kpadhikari/Desktop/BigFls/DS_ML\"\n",
    "\n",
    "#### Here I want to make pkl files of all 5 PLUTO data sets (corresponding to 5 NYC boroughs)\n",
    "####   Later I will disable these lines (pkl files have smaller size than corresponding .csv\n",
    "####    and also it saves time to load them up later on into a dataframe.)\n",
    "#### I was wrong to say that pkl files are always smaller in size than the corresponding\n",
    "####    csv/ASCII files (I said that based on my observation of the 311 dataset. In fact all of\n",
    "####    the PLUTO data file got bigger when converted to pkl (see below))\n",
    "#makeSavePickles('{}/PLUTO_for_WEB/BK_18v1'.format(path)) #Brooklyn: 82.5 MB to 193.3 MB\n",
    "#makeSavePickles('{}/PLUTO_for_WEB/BX_18v1'.format(path)) #Bronx:  26.9 MB to 62.4 MB\n",
    "#makeSavePickles('{}/PLUTO_for_WEB/MN_18v1'.format(path)) #Manhattan: 13.6 to 29.8 MB\n",
    "#makeSavePickles('{}/PLUTO_for_WEB/QN_18v1'.format(path)) #Queens:    96.6 to 225.2 MB\n",
    "#makeSavePickles('{}/PLUTO_for_WEB/SI_18v1'.format(path)) #Staten Island: 37.2 to 86 MB\n",
    "\n",
    "\n",
    "#This is a big file (2.4G)\n",
    "file = \"311_Service_Requests_from_2010_to_Present_min\" #older (differently formatted?)\n",
    "\n",
    "#excel_data_df = pandas.read_excel('records.xlsx', sheet_name='Employees')\n",
    "#df = pandas.read_excel('tableRBEs_orgAndOurs.xlsx') #, sheet_name='Employees')\n",
    "#df0 = pd.read_excel('{}/{}'.format(path,file)) #, sheet_name='Employees')\n",
    "#df0 = pd.read_csv('{}/{}.csv'.format(path,file)) #, sheet_name='Employees')\n",
    "#df0.head()\n",
    "#df0 = None\n",
    "#df0.head() #AttributeError: 'NoneType' object has no attribute 'head'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####display(df0.columns)\n",
    "#display(df0.info)\n",
    "#####display(df0.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0720EN-SkillsNetwork/labs/Module%201/pickle.md.html\n",
    "# Following line created a .pkl file of size 658.9 MB, while the original csv file had a size of 2.55 GB \n",
    "#      (which is about 75% reduction in size)\n",
    "###### df0.to_pickle('/Users/kpadhikari/Desktop/BigFls/DS_ML/311_Service_Requests_from_2010_to_Present_min.pkl')\n",
    "## \n",
    "## Now reading the pickle file that was first created out of the dataframe that was made out of .csv data\n",
    "dfpk0 = pd.read_pickle('{}/{}.pkl'.format(path,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unique Key', 'Created Date', 'Closed Date',\n",
       "       'Complaint Type', 'Location Type', 'Incident Zip', 'Incident Address',\n",
       "       'Street Name', 'Address Type', 'City', 'Status',\n",
       "       'Resolution Description', 'Borough', 'Latitude', 'Longitude'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                  int64\n",
       "Unique Key                  int64\n",
       "Created Date               object\n",
       "Closed Date                object\n",
       "Complaint Type             object\n",
       "Location Type              object\n",
       "Incident Zip              float64\n",
       "Incident Address           object\n",
       "Street Name                object\n",
       "Address Type               object\n",
       "City                       object\n",
       "Status                     object\n",
       "Resolution Description     object\n",
       "Borough                    object\n",
       "Latitude                  float64\n",
       "Longitude                 float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unique Key</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Closed Date</th>\n",
       "      <th>Complaint Type</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Incident Zip</th>\n",
       "      <th>Incident Address</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Address Type</th>\n",
       "      <th>City</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution Description</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45531130</td>\n",
       "      <td>02/02/2020 06:09:17 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>RESIDENTIAL BUILDING</td>\n",
       "      <td>10019.0</td>\n",
       "      <td>426 WEST   52 STREET</td>\n",
       "      <td>WEST   52 STREET</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Open</td>\n",
       "      <td>The following complaint conditions are still o...</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>40.765132</td>\n",
       "      <td>-73.988993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45529784</td>\n",
       "      <td>02/02/2020 02:15:24 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNSANITARY CONDITION</td>\n",
       "      <td>RESIDENTIAL BUILDING</td>\n",
       "      <td>11204.0</td>\n",
       "      <td>1751 67 STREET</td>\n",
       "      <td>67 STREET</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>Open</td>\n",
       "      <td>The following complaint conditions are still o...</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.618484</td>\n",
       "      <td>-73.992673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>45527528</td>\n",
       "      <td>02/02/2020 02:27:41 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>RESIDENTIAL BUILDING</td>\n",
       "      <td>11372.0</td>\n",
       "      <td>87-15 37 AVENUE</td>\n",
       "      <td>37 AVENUE</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>Jackson Heights</td>\n",
       "      <td>Open</td>\n",
       "      <td>The following complaint conditions are still o...</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>40.750269</td>\n",
       "      <td>-73.879432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45530329</td>\n",
       "      <td>02/02/2020 12:13:18 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>RESIDENTIAL BUILDING</td>\n",
       "      <td>10458.0</td>\n",
       "      <td>2405 SOUTHERN BOULEVARD</td>\n",
       "      <td>SOUTHERN BOULEVARD</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>Open</td>\n",
       "      <td>The following complaint conditions are still o...</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>40.853773</td>\n",
       "      <td>-73.881558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>45528814</td>\n",
       "      <td>02/02/2020 01:59:44 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>APPLIANCE</td>\n",
       "      <td>RESIDENTIAL BUILDING</td>\n",
       "      <td>11209.0</td>\n",
       "      <td>223 78 STREET</td>\n",
       "      <td>78 STREET</td>\n",
       "      <td>ADDRESS</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>Open</td>\n",
       "      <td>The following complaint conditions are still o...</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.629745</td>\n",
       "      <td>-74.030533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unique Key            Created Date Closed Date  \\\n",
       "0           0    45531130  02/02/2020 06:09:17 AM         NaN   \n",
       "1           1    45529784  02/02/2020 02:15:24 PM         NaN   \n",
       "2           2    45527528  02/02/2020 02:27:41 AM         NaN   \n",
       "3           3    45530329  02/02/2020 12:13:18 PM         NaN   \n",
       "4           4    45528814  02/02/2020 01:59:44 PM         NaN   \n",
       "\n",
       "         Complaint Type         Location Type  Incident Zip  \\\n",
       "0        HEAT/HOT WATER  RESIDENTIAL BUILDING       10019.0   \n",
       "1  UNSANITARY CONDITION  RESIDENTIAL BUILDING       11204.0   \n",
       "2        HEAT/HOT WATER  RESIDENTIAL BUILDING       11372.0   \n",
       "3        HEAT/HOT WATER  RESIDENTIAL BUILDING       10458.0   \n",
       "4             APPLIANCE  RESIDENTIAL BUILDING       11209.0   \n",
       "\n",
       "          Incident Address         Street Name Address Type             City  \\\n",
       "0     426 WEST   52 STREET    WEST   52 STREET      ADDRESS         NEW YORK   \n",
       "1           1751 67 STREET           67 STREET      ADDRESS         BROOKLYN   \n",
       "2          87-15 37 AVENUE           37 AVENUE      ADDRESS  Jackson Heights   \n",
       "3  2405 SOUTHERN BOULEVARD  SOUTHERN BOULEVARD      ADDRESS            BRONX   \n",
       "4            223 78 STREET           78 STREET      ADDRESS         BROOKLYN   \n",
       "\n",
       "  Status                             Resolution Description    Borough  \\\n",
       "0   Open  The following complaint conditions are still o...  MANHATTAN   \n",
       "1   Open  The following complaint conditions are still o...   BROOKLYN   \n",
       "2   Open  The following complaint conditions are still o...     QUEENS   \n",
       "3   Open  The following complaint conditions are still o...      BRONX   \n",
       "4   Open  The following complaint conditions are still o...   BROOKLYN   \n",
       "\n",
       "    Latitude  Longitude  \n",
       "0  40.765132 -73.988993  \n",
       "1  40.618484 -73.992673  \n",
       "2  40.750269 -73.879432  \n",
       "3  40.853773 -73.881558  \n",
       "4  40.629745 -74.030533  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(dfpk0.columns)\n",
    "#display(df0.info)\n",
    "display(dfpk0.dtypes)\n",
    "dfpk0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module 1: Quiz\n",
    "* Q1: The dataset contains complaints logged since what date?\n",
    "* Q2: The dataset contains complaints logged till what date?\n",
    "* Q3: How many incidents have a missing Incident Address?\n",
    "* Q4: How many valid ZIP Codes exist in the Bronx PLUTO dataset?\n",
    "* Q5: How many valid ZIP Codes exist in the Queens PLUTO dataset?\n",
    "\n",
    "References for some of the ideas below:\n",
    "* https://towardsdatascience.com/4-tricks-you-should-know-to-parse-date-columns-with-pandas-read-csv-27355bb2ad0e\n",
    "* https://stackoverflow.com/questions/57859504/pandas-transform-date-string-from-format-mm-d-yyyy-and-mm-dd-yyyy-to-dd-mm-yyyy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/1/2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/5/2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/10/2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/17/2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date\n",
       "0   12/1/2008\n",
       "1   12/5/2008\n",
       "2  12/10/2008\n",
       "3  12/17/2008"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# example data frame with dates in the format mm/d/yyyy and mm/dd/yyyy\n",
    "dfdtEx = pd.DataFrame({'date' : ['12/1/2008','12/5/2008','12/10/2008','12/17/2008']})\n",
    "display(dfdtEx.head())\n",
    "print(dfdtEx['date'].isna().sum()) #Counting Empty or Not-available or Missing values in the 'date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.01.2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.05.2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.10.2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.17.2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date\n",
       "0  12.01.2008\n",
       "1  12.05.2008\n",
       "2  12.10.2008\n",
       "3  12.17.2008"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdtEx['date'] = pd.to_datetime(dfdtEx['date'])\n",
    "dfdtEx['date'] = dfdtEx['date'].dt.strftime('%m.%d.%Y')\n",
    "dfdtEx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to extract days, months, years or so, pandas has a special dt functionality for datetime types, hence, you need to convert your column first into that type.\n",
    "\n",
    "You can access days and months like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-10</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-17</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  month  day  year\n",
       "0 2008-12-01     12    1  2008\n",
       "1 2008-12-05     12    5  2008\n",
       "2 2008-12-10     12   10  2008\n",
       "3 2008-12-17     12   17  2008"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdtEx['date'] = pd.to_datetime(dfdtEx['date'])\n",
    "dfdtEx['month'] = dfdtEx['date'].dt.month\n",
    "dfdtEx['day'] = dfdtEx['date'].dt.day\n",
    "dfdtEx['year'] = dfdtEx['date'].dt.year\n",
    "dfdtEx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2008-12-01 00:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2008-12-17 00:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(min(dfdtEx['date']))\n",
    "display(max(dfdtEx['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01/01/2010 02:31:13 PM'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'12/31/2019 12:59:12 PM'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(min(dfpk0['Created Date']))\n",
    "display(max(dfpk0['Created Date']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dfpk0.head() above showed dates from 2020 but the max method showed it to be 2019, so I suspect, I have to first parse the above date column to **datetime** type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-07 16:00:00\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/51235708/parsing-string-to-datetime-while-accounting-for-am-pm-in-pandas\n",
    "#https://www.dataindependent.com/pandas/pandas-to-datetime/ \n",
    "print(pd.to_datetime(\"2018 - 07 - 07 04 - PM\", format='%Y - %m - %d %I - %p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.dataindependent.com/pandas/pandas-to-datetime/\n",
    "#dfpk0['Created Date'] = pd.to_datetime(dfpk0['Created Date']) #didn't work\n",
    "dfpk0['Created Date'] = pd.to_datetime(dfpk0['Created Date'], format='%m/%d/%Y %H:%M:%S %p') #kp: Removes AM or PM\n",
    "#dfpk0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-01-01 02:31:13')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2020-02-02 12:55:36')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(min(dfpk0['Created Date']))\n",
    "display(max(dfpk0['Created Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52825\n"
     ]
    }
   ],
   "source": [
    "print(dfpk0['Incident Address'].isna().sum()) #Counting Empty or Not-available or Missing values in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (19,20,22,23,64,65,80) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>CD</th>\n",
       "      <th>CT2010</th>\n",
       "      <th>CB2010</th>\n",
       "      <th>SchoolDist</th>\n",
       "      <th>Council</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>FireComp</th>\n",
       "      <th>...</th>\n",
       "      <th>ZMCode</th>\n",
       "      <th>Sanborn</th>\n",
       "      <th>TaxMap</th>\n",
       "      <th>EDesigNum</th>\n",
       "      <th>APPBBL</th>\n",
       "      <th>APPDate</th>\n",
       "      <th>PLUTOMapID</th>\n",
       "      <th>FIRM07_FLAG</th>\n",
       "      <th>PFIRM15_FLAG</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BX</td>\n",
       "      <td>2260</td>\n",
       "      <td>1</td>\n",
       "      <td>201</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>L029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209S016</td>\n",
       "      <td>20901.0</td>\n",
       "      <td>E-143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BX</td>\n",
       "      <td>2260</td>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>L029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209S016</td>\n",
       "      <td>20901.0</td>\n",
       "      <td>E-143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BX</td>\n",
       "      <td>2260</td>\n",
       "      <td>10</td>\n",
       "      <td>201</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>L029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209S016</td>\n",
       "      <td>20901.0</td>\n",
       "      <td>E-143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BX</td>\n",
       "      <td>2260</td>\n",
       "      <td>17</td>\n",
       "      <td>201</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>L029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209S016</td>\n",
       "      <td>20901.0</td>\n",
       "      <td>E-143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BX</td>\n",
       "      <td>2260</td>\n",
       "      <td>18</td>\n",
       "      <td>201</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>L029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209S016</td>\n",
       "      <td>20901.0</td>\n",
       "      <td>E-143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Borough  Block  Lot   CD  CT2010  CB2010  SchoolDist  Council  ZipCode  \\\n",
       "0      BX   2260    1  201    19.0  1022.0         7.0      8.0  10454.0   \n",
       "1      BX   2260    4  201    19.0  1022.0         7.0      8.0  10454.0   \n",
       "2      BX   2260   10  201    19.0  1022.0         7.0      8.0  10454.0   \n",
       "3      BX   2260   17  201    19.0  1022.0         7.0      8.0  10454.0   \n",
       "4      BX   2260   18  201    19.0  1022.0         7.0      8.0  10454.0   \n",
       "\n",
       "  FireComp  ...  ZMCode  Sanborn   TaxMap  EDesigNum  APPBBL APPDate  \\\n",
       "0     L029  ...     NaN  209S016  20901.0      E-143     0.0     NaN   \n",
       "1     L029  ...     NaN  209S016  20901.0      E-143     0.0     NaN   \n",
       "2     L029  ...     NaN  209S016  20901.0      E-143     0.0     NaN   \n",
       "3     L029  ...     NaN  209S016  20901.0      E-143     0.0     NaN   \n",
       "4     L029  ...     NaN  209S016  20901.0      E-143     0.0     NaN   \n",
       "\n",
       "  PLUTOMapID FIRM07_FLAG PFIRM15_FLAG Version  \n",
       "0          1         NaN          NaN    18V1  \n",
       "1          1         NaN          NaN    18V1  \n",
       "2          1         NaN          NaN    18V1  \n",
       "3          1         NaN          NaN    18V1  \n",
       "4          1         NaN          NaN    18V1  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfbx = pd.read_csv('{}/PLUTO_for_WEB/BX_18v1.csv'.format(path))\n",
    "display(dfbx.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3170: DtypeWarning: Columns (19,20,22,23,64,65,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>CD</th>\n",
       "      <th>CT2010</th>\n",
       "      <th>CB2010</th>\n",
       "      <th>SchoolDist</th>\n",
       "      <th>Council</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>FireComp</th>\n",
       "      <th>...</th>\n",
       "      <th>ZMCode</th>\n",
       "      <th>Sanborn</th>\n",
       "      <th>TaxMap</th>\n",
       "      <th>EDesigNum</th>\n",
       "      <th>APPBBL</th>\n",
       "      <th>APPDate</th>\n",
       "      <th>PLUTOMapID</th>\n",
       "      <th>FIRM07_FLAG</th>\n",
       "      <th>PFIRM15_FLAG</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11101.0</td>\n",
       "      <td>L115</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>401 011</td>\n",
       "      <td>40101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000060e+09</td>\n",
       "      <td>09/20/2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QN</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11101.0</td>\n",
       "      <td>L115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>401 011</td>\n",
       "      <td>40101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QN</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11101.0</td>\n",
       "      <td>L115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>401 011</td>\n",
       "      <td>40101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000060e+09</td>\n",
       "      <td>08/07/2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QN</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11101.0</td>\n",
       "      <td>L115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>401 011</td>\n",
       "      <td>40101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000060e+09</td>\n",
       "      <td>09/20/2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QN</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11101.0</td>\n",
       "      <td>L115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>401 011</td>\n",
       "      <td>40101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.000060e+09</td>\n",
       "      <td>09/08/2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Borough  Block  Lot   CD  CT2010  CB2010  SchoolDist  Council  ZipCode  \\\n",
       "0      QN      6    1  402     1.0     NaN        30.0     26.0  11101.0   \n",
       "1      QN      6    3  402     1.0  1015.0        30.0     26.0  11101.0   \n",
       "2      QN      6    8  402     1.0  1011.0        30.0     26.0  11101.0   \n",
       "3      QN      6   20  402     1.0     NaN        30.0     26.0  11101.0   \n",
       "4      QN      6   30  402     1.0     NaN        30.0     26.0  11101.0   \n",
       "\n",
       "  FireComp  ...  ZMCode  Sanborn   TaxMap  EDesigNum        APPBBL  \\\n",
       "0     L115  ...       Y  401 011  40101.0        NaN  4.000060e+09   \n",
       "1     L115  ...     NaN  401 011  40101.0        NaN  0.000000e+00   \n",
       "2     L115  ...     NaN  401 011  40101.0        NaN  4.000060e+09   \n",
       "3     L115  ...     NaN  401 011  40101.0        NaN  4.000060e+09   \n",
       "4     L115  ...     NaN  401 011  40101.0        NaN  4.000060e+09   \n",
       "\n",
       "      APPDate PLUTOMapID FIRM07_FLAG PFIRM15_FLAG Version  \n",
       "0  09/20/2013          1         1.0          1.0    18V1  \n",
       "1         NaN          1         1.0          1.0    18V1  \n",
       "2  08/07/2013          1         1.0          1.0    18V1  \n",
       "3  09/20/2013          1         1.0          1.0    18V1  \n",
       "4  09/08/2017          1         1.0          1.0    18V1  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfqn = pd.read_csv('{}/PLUTO_for_WEB/QN_18v1.csv'.format(path))\n",
    "display(dfqn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipCode\n",
       "10451.0     1228\n",
       "10452.0     1548\n",
       "10453.0     2102\n",
       "10454.0     1746\n",
       "10455.0     1793\n",
       "10456.0     2876\n",
       "10457.0     3028\n",
       "10458.0     2769\n",
       "10459.0     2605\n",
       "10460.0     2892\n",
       "10461.0     7499\n",
       "10462.0     4671\n",
       "10463.0     2247\n",
       "10464.0     1550\n",
       "10465.0     8163\n",
       "10466.0     9229\n",
       "10467.0     4673\n",
       "10468.0     1627\n",
       "10469.0    11349\n",
       "10470.0     2334\n",
       "10471.0     2352\n",
       "10472.0     4329\n",
       "10473.0     4870\n",
       "10474.0     1220\n",
       "10475.0      823\n",
       "11370.0        2\n",
       "Name: ZipCode, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Grouping and perform count over each group\n",
    "dfzc =  dfbx.groupby('ZipCode')['ZipCode'].count()\n",
    "display(dfzc)\n",
    "display(dfzc.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipCode\n",
       "11001.0    1241\n",
       "11004.0    2502\n",
       "11005.0       1\n",
       "11040.0     589\n",
       "11101.0    3263\n",
       "           ... \n",
       "11692.0    2384\n",
       "11693.0    1963\n",
       "11694.0    3743\n",
       "11695.0       6\n",
       "11697.0      13\n",
       "Name: ZipCode, Length: 65, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dfbx.groupby('ZipCode')['ZipCode'].sum()\n",
    "dfzc =  dfqn.groupby('ZipCode')['ZipCode'].count()\n",
    "display(dfzc)\n",
    "display(dfzc.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: What Is the Top Complaint Type?\n",
    "Estimated time needed: 2 hours\n",
    "\n",
    "### Objective for Exercise:\n",
    "Use data science methodologies to define and formulate a real-world business problem.\n",
    "The goal of this exercise is to find the answer to the Question 1 of the problem statement:\n",
    "\n",
    "**Which type of complaint should the Department of Housing Preservation and Development of New York City focus on first?**\n",
    "\n",
    "In this exercise, you need to read back the 311 datasets that you stored in Cloud Object Store and explore the dataset.\n",
    "\n",
    "By the end of this exercise, you need to figure out the correct Complaint Type that the Department of Housing Preservation and Development of New York City should focus on.\n",
    "\n",
    "\n",
    "### Module 2: Quiz\n",
    "* What is the total number of complaints that exist in the dataset?\n",
    "* How many different Complaint Types can you find in the dataset, including duplicates entries of the same type?\n",
    "* How many Elevator complaints can you find in the dataset?\n",
    "* How many Electric complaints can you find in the dataset?\n",
    "* Using 800,000 as a threshold, what complaint type(s) do you recommend the Department of Housing Preservation and Development of New York City address first? Select all that apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unique Key', 'Created Date', 'Closed Date',\n",
       "       'Complaint Type', 'Location Type', 'Incident Zip', 'Incident Address',\n",
       "       'Street Name', 'Address Type', 'City', 'Status',\n",
       "       'Resolution Description', 'Borough', 'Latitude', 'Longitude'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                         int64\n",
       "Unique Key                         int64\n",
       "Created Date              datetime64[ns]\n",
       "Closed Date                       object\n",
       "Complaint Type                    object\n",
       "Location Type                     object\n",
       "Incident Zip                     float64\n",
       "Incident Address                  object\n",
       "Street Name                       object\n",
       "Address Type                      object\n",
       "City                              object\n",
       "Status                            object\n",
       "Resolution Description            object\n",
       "Borough                           object\n",
       "Latitude                         float64\n",
       "Longitude                        float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                6019843\n",
       "Unique Key                6019843\n",
       "Created Date              6019843\n",
       "Closed Date               5893186\n",
       "Complaint Type            6019843\n",
       "Location Type             5967019\n",
       "Incident Zip              5939146\n",
       "Incident Address          5967018\n",
       "Street Name               5967018\n",
       "Address Type              5935078\n",
       "City                      5939569\n",
       "Status                    6019843\n",
       "Resolution Description    6012017\n",
       "Borough                   6019843\n",
       "Latitude                  5939172\n",
       "Longitude                 5939172\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dfpk0.columns)\n",
    "#display(df0.info)\n",
    "display(dfpk0.dtypes)\n",
    "display(dfpk0.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the answer to \"**What is the total number of complaints that exist in the dataset?**\" is **6019843** because that's the maximum # of rows (the lower values of count() for other columns comes because of the fact that they have some rows with missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complaint Type\n",
       "AGENCY                          9\n",
       "APPLIANCE                  112831\n",
       "Appliance                       4\n",
       "CONSTRUCTION                 5078\n",
       "DOOR/WINDOW                205278\n",
       "ELECTRIC                   307310\n",
       "ELEVATOR                     6725\n",
       "Electric                        1\n",
       "FLOORING/STAIRS            137402\n",
       "GENERAL                    151308\n",
       "GENERAL CONSTRUCTION       500863\n",
       "General                      1163\n",
       "HEAT/HOT WATER            1261574\n",
       "HEATING                    887850\n",
       "HPD Literature Request      52824\n",
       "Mold                            1\n",
       "NONCONST                   260890\n",
       "OUTSIDE BUILDING             7142\n",
       "Outside Building                6\n",
       "PAINT - PLASTER            361257\n",
       "PAINT/PLASTER              346438\n",
       "PLUMBING                   711130\n",
       "Plumbing                       11\n",
       "SAFETY                      51529\n",
       "STRUCTURAL                     16\n",
       "Safety                        424\n",
       "UNSANITARY CONDITION       451643\n",
       "Unsanitary Condition         5499\n",
       "VACANT APARTMENT                6\n",
       "WATER LEAK                 193631\n",
       "Name: Complaint Type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfzc =  dfpk0.groupby('Complaint Type')['Complaint Type'].count()\n",
    "display(dfzc)\n",
    "display(dfzc.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the answer to **How many different Complaint Types can you find in the dataset, including duplicates entries of the same type?** is **30**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the answer to **How many Elevator complaints can you find in the dataset?** is **6725**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the answer to **How many Electric complaints can you find in the dataset?** is **307311**, which is a total of 307310 for ELECTRIC type and 1 for 'electric' type, which are the same thing but perhaps due to some memory issues by the data recorder, the new complaint type 'electric' was created again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the answer to **Using 800,000 as a threshold, what complaint type(s) do you recommend the Department of Housing Preservation and Development of New York City address first? Select all that apply.** is **(B) Heating** and **(E)Both of 'Heat/Hot Water'**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 3: What Areas Should the Agency Focus On?\n",
    "Estimated time needed: 2 hours\n",
    "\n",
    "### Objective for Exercise:\n",
    "Use your data analysis tools to ingest a dataset, clean it, and wrangle it.\n",
    "The goal of this exercise is to do explore the data to find the answer to the Question 2 problem statement:\n",
    "\n",
    "Should the Department of Housing Preservation and Development of New York City focus on any particular set of boroughs, ZIP codes, or street (where the complaints are severe) for the specific type of complaints you identified in response to Question 1?\n",
    "\n",
    "In this exercise, you will use 311 Dataset to determine whether to focus on any particular borough, ZIP code, or street (where the complaints are severe) for the specific Complaint Type you decided to focus at the end of the last exercise.\n",
    "\n",
    "\n",
    "\n",
    "### Module 3: Quiz on Affected Areas\n",
    "* For the complaint types that you selected in the previous module that had at least 800,000 complaints logged, which borough had the highest number of complaints submitted?\n",
    "* For the complaint types that you selected in the previous module that had a total number that exceeded 800,000 complaints, which borough had the lowest number of complaints submitted?\n",
    "* For the complaint types that you selected in the previous module that had at least 800,000 complaints logged, which ZIP code had the highest number of complainted submitted?\n",
    "* For the complaint types that you selected in the previous module that had at least 800,000 complaints logged, the address 89-21 Elmhurst Avenue had the highest number of complainted submitted?\n",
    "* For the complaint types that you selected in the previous module that had at least 800,000 complaints logged, how many of the submitted tickets were closed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) IF condition with OR\n",
    "Ref: https://datatofish.com/if-condition-in-pandas-dataframe/\n",
    "\n",
    "In the final case, let’s apply these conditions:\n",
    "\n",
    "* If the name is ‘Bill’ or ‘Emma,’ then assign the value of ‘Match’\n",
    "* Otherwise, if the name is neither ‘Bill’ nor ‘Emma,’ then assign the value of ‘Mismatch’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First_name\n",
       "0        Jon\n",
       "1       Bill\n",
       "2      Maria\n",
       "3       Emma"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  First_name name_match\n",
      "0        Jon   Mismatch\n",
      "1       Bill      Match\n",
      "2      Maria   Mismatch\n",
      "3       Emma      Match\n"
     ]
    }
   ],
   "source": [
    "#https://datatofish.com/if-condition-in-pandas-dataframe/\n",
    "#dfct['name_match'] = dfpk0['First_name'].apply(lambda x: 'Match' if x == 'Bill' else 'Mismatch')\n",
    "#(5) IF condition with OR\n",
    "import pandas as pd\n",
    "\n",
    "names = {'First_name': ['Jon','Bill','Maria','Emma']}\n",
    "df = pd.DataFrame(names,columns=['First_name'])\n",
    "display(df)\n",
    "df.loc[(df['First_name'] == 'Bill') | (df['First_name'] == 'Emma'), 'name_match'] = 'Match'  \n",
    "df.loc[(df['First_name'] != 'Bill') & (df['First_name'] != 'Emma'), 'name_match'] = 'Mismatch'  \n",
    "\n",
    "print (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Complaint Type\n",
       "AGENCY               9\n",
       "APPLIANCE       112831\n",
       "Appliance            4\n",
       "CONSTRUCTION      5078\n",
       "DOOR/WINDOW     205278\n",
       "Name: Complaint Type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfzc =  dfpk0.groupby('Complaint Type')['Complaint Type'].count()\n",
    "display(dfzc.head())\n",
    "display(dfzc.count())\n",
    "#display(dfzc)\n",
    "display(dfzc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfgg = dfpk0.groupby(['Complaint Type', 'Borough']) \n",
    "# Print the first value in each group \n",
    "#dfgg.first() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unique Key</th>\n",
       "      <th>Created Date</th>\n",
       "      <th>Closed Date</th>\n",
       "      <th>Location Type</th>\n",
       "      <th>Incident Zip</th>\n",
       "      <th>Incident Address</th>\n",
       "      <th>Street Name</th>\n",
       "      <th>Address Type</th>\n",
       "      <th>City</th>\n",
       "      <th>Status</th>\n",
       "      <th>Resolution Description</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Complaint Type</th>\n",
       "      <th>Borough</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">AGENCY</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">APPLIANCE</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>33031</td>\n",
       "      <td>33031</td>\n",
       "      <td>33031</td>\n",
       "      <td>32018</td>\n",
       "      <td>33031</td>\n",
       "      <td>33009</td>\n",
       "      <td>33031</td>\n",
       "      <td>33031</td>\n",
       "      <td>33012</td>\n",
       "      <td>33009</td>\n",
       "      <td>33031</td>\n",
       "      <td>33029</td>\n",
       "      <td>33009</td>\n",
       "      <td>33009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>30880</td>\n",
       "      <td>30880</td>\n",
       "      <td>30880</td>\n",
       "      <td>29948</td>\n",
       "      <td>30880</td>\n",
       "      <td>30827</td>\n",
       "      <td>30880</td>\n",
       "      <td>30880</td>\n",
       "      <td>30833</td>\n",
       "      <td>30827</td>\n",
       "      <td>30880</td>\n",
       "      <td>30872</td>\n",
       "      <td>30827</td>\n",
       "      <td>30827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>17604</td>\n",
       "      <td>17604</td>\n",
       "      <td>17604</td>\n",
       "      <td>16980</td>\n",
       "      <td>17604</td>\n",
       "      <td>17585</td>\n",
       "      <td>17604</td>\n",
       "      <td>17604</td>\n",
       "      <td>17587</td>\n",
       "      <td>17585</td>\n",
       "      <td>17604</td>\n",
       "      <td>17598</td>\n",
       "      <td>17585</td>\n",
       "      <td>17585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>11754</td>\n",
       "      <td>11754</td>\n",
       "      <td>11754</td>\n",
       "      <td>11349</td>\n",
       "      <td>11754</td>\n",
       "      <td>11709</td>\n",
       "      <td>11754</td>\n",
       "      <td>11754</td>\n",
       "      <td>11744</td>\n",
       "      <td>11725</td>\n",
       "      <td>11754</td>\n",
       "      <td>11748</td>\n",
       "      <td>11709</td>\n",
       "      <td>11709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>2238</td>\n",
       "      <td>2238</td>\n",
       "      <td>2238</td>\n",
       "      <td>2181</td>\n",
       "      <td>2238</td>\n",
       "      <td>2234</td>\n",
       "      <td>2238</td>\n",
       "      <td>2238</td>\n",
       "      <td>2235</td>\n",
       "      <td>2234</td>\n",
       "      <td>2238</td>\n",
       "      <td>2237</td>\n",
       "      <td>2234</td>\n",
       "      <td>2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>17324</td>\n",
       "      <td>17324</td>\n",
       "      <td>17324</td>\n",
       "      <td>16687</td>\n",
       "      <td>17324</td>\n",
       "      <td>17313</td>\n",
       "      <td>17324</td>\n",
       "      <td>17324</td>\n",
       "      <td>17324</td>\n",
       "      <td>17313</td>\n",
       "      <td>17324</td>\n",
       "      <td>17319</td>\n",
       "      <td>17313</td>\n",
       "      <td>17313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Appliance</th>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">CONSTRUCTION</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>871</td>\n",
       "      <td>871</td>\n",
       "      <td>871</td>\n",
       "      <td>825</td>\n",
       "      <td>871</td>\n",
       "      <td>860</td>\n",
       "      <td>871</td>\n",
       "      <td>871</td>\n",
       "      <td>863</td>\n",
       "      <td>860</td>\n",
       "      <td>871</td>\n",
       "      <td>867</td>\n",
       "      <td>860</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>1444</td>\n",
       "      <td>1444</td>\n",
       "      <td>1444</td>\n",
       "      <td>1359</td>\n",
       "      <td>1444</td>\n",
       "      <td>1435</td>\n",
       "      <td>1444</td>\n",
       "      <td>1444</td>\n",
       "      <td>1437</td>\n",
       "      <td>1435</td>\n",
       "      <td>1444</td>\n",
       "      <td>1434</td>\n",
       "      <td>1435</td>\n",
       "      <td>1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>577</td>\n",
       "      <td>621</td>\n",
       "      <td>618</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>618</td>\n",
       "      <td>618</td>\n",
       "      <td>621</td>\n",
       "      <td>620</td>\n",
       "      <td>618</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>461</td>\n",
       "      <td>498</td>\n",
       "      <td>491</td>\n",
       "      <td>498</td>\n",
       "      <td>498</td>\n",
       "      <td>496</td>\n",
       "      <td>491</td>\n",
       "      <td>498</td>\n",
       "      <td>497</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>114</td>\n",
       "      <td>118</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "      <td>117</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>1526</td>\n",
       "      <td>1526</td>\n",
       "      <td>1526</td>\n",
       "      <td>1485</td>\n",
       "      <td>1526</td>\n",
       "      <td>1523</td>\n",
       "      <td>1526</td>\n",
       "      <td>1526</td>\n",
       "      <td>1526</td>\n",
       "      <td>1523</td>\n",
       "      <td>1526</td>\n",
       "      <td>1526</td>\n",
       "      <td>1523</td>\n",
       "      <td>1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">DOOR/WINDOW</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>66277</td>\n",
       "      <td>66277</td>\n",
       "      <td>66277</td>\n",
       "      <td>65778</td>\n",
       "      <td>66277</td>\n",
       "      <td>66245</td>\n",
       "      <td>66277</td>\n",
       "      <td>66277</td>\n",
       "      <td>66252</td>\n",
       "      <td>66245</td>\n",
       "      <td>66277</td>\n",
       "      <td>66276</td>\n",
       "      <td>66245</td>\n",
       "      <td>66245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>70846</td>\n",
       "      <td>70846</td>\n",
       "      <td>70846</td>\n",
       "      <td>70624</td>\n",
       "      <td>70846</td>\n",
       "      <td>70815</td>\n",
       "      <td>70846</td>\n",
       "      <td>70846</td>\n",
       "      <td>70818</td>\n",
       "      <td>70815</td>\n",
       "      <td>70846</td>\n",
       "      <td>70844</td>\n",
       "      <td>70815</td>\n",
       "      <td>70815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>41240</td>\n",
       "      <td>41240</td>\n",
       "      <td>41240</td>\n",
       "      <td>40830</td>\n",
       "      <td>41240</td>\n",
       "      <td>41221</td>\n",
       "      <td>41240</td>\n",
       "      <td>41240</td>\n",
       "      <td>41226</td>\n",
       "      <td>41221</td>\n",
       "      <td>41240</td>\n",
       "      <td>41238</td>\n",
       "      <td>41221</td>\n",
       "      <td>41221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>22728</td>\n",
       "      <td>22728</td>\n",
       "      <td>22728</td>\n",
       "      <td>22645</td>\n",
       "      <td>22728</td>\n",
       "      <td>22670</td>\n",
       "      <td>22728</td>\n",
       "      <td>22728</td>\n",
       "      <td>22716</td>\n",
       "      <td>22686</td>\n",
       "      <td>22728</td>\n",
       "      <td>22727</td>\n",
       "      <td>22670</td>\n",
       "      <td>22670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>4187</td>\n",
       "      <td>4187</td>\n",
       "      <td>4187</td>\n",
       "      <td>4182</td>\n",
       "      <td>4187</td>\n",
       "      <td>4182</td>\n",
       "      <td>4187</td>\n",
       "      <td>4187</td>\n",
       "      <td>4187</td>\n",
       "      <td>4182</td>\n",
       "      <td>4187</td>\n",
       "      <td>4186</td>\n",
       "      <td>4182</td>\n",
       "      <td>4182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">ELECTRIC</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>74037</td>\n",
       "      <td>74037</td>\n",
       "      <td>74037</td>\n",
       "      <td>72200</td>\n",
       "      <td>74037</td>\n",
       "      <td>73838</td>\n",
       "      <td>74037</td>\n",
       "      <td>74037</td>\n",
       "      <td>73851</td>\n",
       "      <td>73838</td>\n",
       "      <td>74037</td>\n",
       "      <td>74032</td>\n",
       "      <td>73838</td>\n",
       "      <td>73838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>99683</td>\n",
       "      <td>99683</td>\n",
       "      <td>99683</td>\n",
       "      <td>97274</td>\n",
       "      <td>99683</td>\n",
       "      <td>99380</td>\n",
       "      <td>99683</td>\n",
       "      <td>99683</td>\n",
       "      <td>99392</td>\n",
       "      <td>99381</td>\n",
       "      <td>99683</td>\n",
       "      <td>99668</td>\n",
       "      <td>99380</td>\n",
       "      <td>99380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>43726</td>\n",
       "      <td>43726</td>\n",
       "      <td>43726</td>\n",
       "      <td>42357</td>\n",
       "      <td>43726</td>\n",
       "      <td>43594</td>\n",
       "      <td>43726</td>\n",
       "      <td>43726</td>\n",
       "      <td>43609</td>\n",
       "      <td>43594</td>\n",
       "      <td>43726</td>\n",
       "      <td>43718</td>\n",
       "      <td>43594</td>\n",
       "      <td>43594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>37871</td>\n",
       "      <td>37871</td>\n",
       "      <td>37871</td>\n",
       "      <td>36829</td>\n",
       "      <td>37871</td>\n",
       "      <td>37694</td>\n",
       "      <td>37871</td>\n",
       "      <td>37871</td>\n",
       "      <td>37809</td>\n",
       "      <td>37718</td>\n",
       "      <td>37871</td>\n",
       "      <td>37866</td>\n",
       "      <td>37696</td>\n",
       "      <td>37696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>6391</td>\n",
       "      <td>6391</td>\n",
       "      <td>6391</td>\n",
       "      <td>6239</td>\n",
       "      <td>6391</td>\n",
       "      <td>6373</td>\n",
       "      <td>6391</td>\n",
       "      <td>6391</td>\n",
       "      <td>6378</td>\n",
       "      <td>6373</td>\n",
       "      <td>6391</td>\n",
       "      <td>6388</td>\n",
       "      <td>6373</td>\n",
       "      <td>6373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>45602</td>\n",
       "      <td>45602</td>\n",
       "      <td>45602</td>\n",
       "      <td>43950</td>\n",
       "      <td>45602</td>\n",
       "      <td>45568</td>\n",
       "      <td>45602</td>\n",
       "      <td>45602</td>\n",
       "      <td>45602</td>\n",
       "      <td>45568</td>\n",
       "      <td>45602</td>\n",
       "      <td>45600</td>\n",
       "      <td>45568</td>\n",
       "      <td>45568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELEVATOR</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1755</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "      <td>1801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SAFETY</th>\n",
       "      <th>QUEENS</th>\n",
       "      <td>8535</td>\n",
       "      <td>8535</td>\n",
       "      <td>8535</td>\n",
       "      <td>8501</td>\n",
       "      <td>8535</td>\n",
       "      <td>8512</td>\n",
       "      <td>8535</td>\n",
       "      <td>8535</td>\n",
       "      <td>8529</td>\n",
       "      <td>8523</td>\n",
       "      <td>8535</td>\n",
       "      <td>8535</td>\n",
       "      <td>8512</td>\n",
       "      <td>8512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1223</td>\n",
       "      <td>1226</td>\n",
       "      <td>1225</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1225</td>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "      <td>1225</td>\n",
       "      <td>1225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">STRUCTURAL</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Safety</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>130</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>137</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">UNSANITARY CONDITION</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>136843</td>\n",
       "      <td>136843</td>\n",
       "      <td>136843</td>\n",
       "      <td>135635</td>\n",
       "      <td>136843</td>\n",
       "      <td>136778</td>\n",
       "      <td>136843</td>\n",
       "      <td>136843</td>\n",
       "      <td>136803</td>\n",
       "      <td>136780</td>\n",
       "      <td>136843</td>\n",
       "      <td>136841</td>\n",
       "      <td>136778</td>\n",
       "      <td>136778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>154272</td>\n",
       "      <td>154272</td>\n",
       "      <td>154272</td>\n",
       "      <td>153694</td>\n",
       "      <td>154272</td>\n",
       "      <td>154167</td>\n",
       "      <td>154272</td>\n",
       "      <td>154272</td>\n",
       "      <td>154182</td>\n",
       "      <td>154170</td>\n",
       "      <td>154272</td>\n",
       "      <td>154272</td>\n",
       "      <td>154167</td>\n",
       "      <td>154167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>85293</td>\n",
       "      <td>85293</td>\n",
       "      <td>85293</td>\n",
       "      <td>84232</td>\n",
       "      <td>85293</td>\n",
       "      <td>85242</td>\n",
       "      <td>85293</td>\n",
       "      <td>85293</td>\n",
       "      <td>85266</td>\n",
       "      <td>85242</td>\n",
       "      <td>85293</td>\n",
       "      <td>85287</td>\n",
       "      <td>85242</td>\n",
       "      <td>85242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>64061</td>\n",
       "      <td>64061</td>\n",
       "      <td>64061</td>\n",
       "      <td>63451</td>\n",
       "      <td>64061</td>\n",
       "      <td>63878</td>\n",
       "      <td>64061</td>\n",
       "      <td>64061</td>\n",
       "      <td>64030</td>\n",
       "      <td>63978</td>\n",
       "      <td>64061</td>\n",
       "      <td>64052</td>\n",
       "      <td>63878</td>\n",
       "      <td>63878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>11174</td>\n",
       "      <td>11174</td>\n",
       "      <td>11174</td>\n",
       "      <td>11131</td>\n",
       "      <td>11174</td>\n",
       "      <td>11171</td>\n",
       "      <td>11174</td>\n",
       "      <td>11174</td>\n",
       "      <td>11174</td>\n",
       "      <td>11171</td>\n",
       "      <td>11174</td>\n",
       "      <td>11173</td>\n",
       "      <td>11171</td>\n",
       "      <td>11171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">Unsanitary Condition</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>1684</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>0</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "      <td>0</td>\n",
       "      <td>1753</td>\n",
       "      <td>1753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>1814</td>\n",
       "      <td>1814</td>\n",
       "      <td>1814</td>\n",
       "      <td>1746</td>\n",
       "      <td>1814</td>\n",
       "      <td>1814</td>\n",
       "      <td>1814</td>\n",
       "      <td>1814</td>\n",
       "      <td>0</td>\n",
       "      <td>1814</td>\n",
       "      <td>1814</td>\n",
       "      <td>0</td>\n",
       "      <td>1814</td>\n",
       "      <td>1814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>1021</td>\n",
       "      <td>1021</td>\n",
       "      <td>1021</td>\n",
       "      <td>936</td>\n",
       "      <td>1021</td>\n",
       "      <td>1021</td>\n",
       "      <td>1021</td>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>1021</td>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "      <td>1021</td>\n",
       "      <td>1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "      <td>730</td>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "      <td>0</td>\n",
       "      <td>739</td>\n",
       "      <td>739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>152</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">VACANT APARTMENT</th>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WATER LEAK</th>\n",
       "      <th>BRONX</th>\n",
       "      <td>62374</td>\n",
       "      <td>62374</td>\n",
       "      <td>62374</td>\n",
       "      <td>61827</td>\n",
       "      <td>62374</td>\n",
       "      <td>62330</td>\n",
       "      <td>62374</td>\n",
       "      <td>62374</td>\n",
       "      <td>62352</td>\n",
       "      <td>62330</td>\n",
       "      <td>62374</td>\n",
       "      <td>62372</td>\n",
       "      <td>62330</td>\n",
       "      <td>62330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>69613</td>\n",
       "      <td>69613</td>\n",
       "      <td>69613</td>\n",
       "      <td>69348</td>\n",
       "      <td>69613</td>\n",
       "      <td>69572</td>\n",
       "      <td>69613</td>\n",
       "      <td>69613</td>\n",
       "      <td>69575</td>\n",
       "      <td>69574</td>\n",
       "      <td>69613</td>\n",
       "      <td>69611</td>\n",
       "      <td>69572</td>\n",
       "      <td>69572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>36739</td>\n",
       "      <td>36739</td>\n",
       "      <td>36739</td>\n",
       "      <td>36332</td>\n",
       "      <td>36739</td>\n",
       "      <td>36699</td>\n",
       "      <td>36739</td>\n",
       "      <td>36739</td>\n",
       "      <td>36714</td>\n",
       "      <td>36699</td>\n",
       "      <td>36739</td>\n",
       "      <td>36738</td>\n",
       "      <td>36699</td>\n",
       "      <td>36699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>21417</td>\n",
       "      <td>21417</td>\n",
       "      <td>21417</td>\n",
       "      <td>21303</td>\n",
       "      <td>21417</td>\n",
       "      <td>21379</td>\n",
       "      <td>21417</td>\n",
       "      <td>21417</td>\n",
       "      <td>21411</td>\n",
       "      <td>21391</td>\n",
       "      <td>21417</td>\n",
       "      <td>21416</td>\n",
       "      <td>21379</td>\n",
       "      <td>21379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3479</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "      <td>3488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Unnamed: 0  Unique Key  Created Date  \\\n",
       "Complaint Type Borough                                               \n",
       "AGENCY         BRONX                   3           3             3   \n",
       "               BROOKLYN                1           1             1   \n",
       "               MANHATTAN               3           3             3   \n",
       "               QUEENS                  2           2             2   \n",
       "APPLIANCE      BRONX               33031       33031         33031   \n",
       "...                                  ...         ...           ...   \n",
       "WATER LEAK     BRONX               62374       62374         62374   \n",
       "               BROOKLYN            69613       69613         69613   \n",
       "               MANHATTAN           36739       36739         36739   \n",
       "               QUEENS              21417       21417         21417   \n",
       "               STATEN ISLAND        3488        3488          3488   \n",
       "\n",
       "                              Closed Date  Location Type  Incident Zip  \\\n",
       "Complaint Type Borough                                                   \n",
       "AGENCY         BRONX                    3              3             3   \n",
       "               BROOKLYN                 1              1             1   \n",
       "               MANHATTAN                3              3             2   \n",
       "               QUEENS                   2              2             2   \n",
       "APPLIANCE      BRONX                32018          33031         33009   \n",
       "...                                   ...            ...           ...   \n",
       "WATER LEAK     BRONX                61827          62374         62330   \n",
       "               BROOKLYN             69348          69613         69572   \n",
       "               MANHATTAN            36332          36739         36699   \n",
       "               QUEENS               21303          21417         21379   \n",
       "               STATEN ISLAND         3479           3488          3488   \n",
       "\n",
       "                              Incident Address  Street Name  Address Type  \\\n",
       "Complaint Type Borough                                                      \n",
       "AGENCY         BRONX                         3            3             3   \n",
       "               BROOKLYN                      1            1             1   \n",
       "               MANHATTAN                     3            3             2   \n",
       "               QUEENS                        2            2             2   \n",
       "APPLIANCE      BRONX                     33031        33031         33012   \n",
       "...                                        ...          ...           ...   \n",
       "WATER LEAK     BRONX                     62374        62374         62352   \n",
       "               BROOKLYN                  69613        69613         69575   \n",
       "               MANHATTAN                 36739        36739         36714   \n",
       "               QUEENS                    21417        21417         21411   \n",
       "               STATEN ISLAND              3488         3488          3488   \n",
       "\n",
       "                               City  Status  Resolution Description  Latitude  \\\n",
       "Complaint Type Borough                                                          \n",
       "AGENCY         BRONX              3       3                       3         3   \n",
       "               BROOKLYN           1       1                       1         1   \n",
       "               MANHATTAN          2       3                       3         2   \n",
       "               QUEENS             2       2                       2         2   \n",
       "APPLIANCE      BRONX          33009   33031                   33029     33009   \n",
       "...                             ...     ...                     ...       ...   \n",
       "WATER LEAK     BRONX          62330   62374                   62372     62330   \n",
       "               BROOKLYN       69574   69613                   69611     69572   \n",
       "               MANHATTAN      36699   36739                   36738     36699   \n",
       "               QUEENS         21391   21417                   21416     21379   \n",
       "               STATEN ISLAND   3488    3488                    3488      3488   \n",
       "\n",
       "                              Longitude  \n",
       "Complaint Type Borough                   \n",
       "AGENCY         BRONX                  3  \n",
       "               BROOKLYN               1  \n",
       "               MANHATTAN              2  \n",
       "               QUEENS                 2  \n",
       "APPLIANCE      BRONX              33009  \n",
       "...                                 ...  \n",
       "WATER LEAK     BRONX              62330  \n",
       "               BROOKLYN           69572  \n",
       "               MANHATTAN          36699  \n",
       "               QUEENS             21379  \n",
       "               STATEN ISLAND       3488  \n",
       "\n",
       "[139 rows x 14 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dfgg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dfgg))\n",
    "#dfgg.count().loc[(dfgg['Complaint Type'] == 'HEATING') | (dfgg['Complaint Type'] == 'HEAT/HOT WATER')]\n",
    "#dfgg.get_group('HEATING')\n",
    "\n",
    "#for name_of_the_group, group in dfgg:\n",
    "#    print (name_of_the_group)\n",
    "#    print (group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfgg.count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borough\n",
      "BRONX            1617956\n",
      "BROOKLYN         1739886\n",
      "MANHATTAN        1055225\n",
      "QUEENS            645971\n",
      "STATEN ISLAND      87584\n",
      "Unspecified       873221\n",
      "Name: conditions_apply, dtype: int64\n",
      "Borough\n",
      "BROOKLYN    1739886\n",
      "Name: conditions_apply, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Incident Zip\n",
       "10001.0     9031\n",
       "10002.0    32385\n",
       "10003.0    25574\n",
       "10004.0      329\n",
       "10005.0      440\n",
       "           ...  \n",
       "11692.0    12498\n",
       "11693.0     4768\n",
       "11694.0    10557\n",
       "11697.0      269\n",
       "12345.0        1\n",
       "Name: conditions_apply, Length: 202, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident Zip\n",
      "11226.0    215709\n",
      "Name: conditions_apply, dtype: int64\n",
      "Incident Address\n",
      "34 ARDEN STREET    14298\n",
      "Name: conditions_apply, dtype: int64\n",
      "Status\n",
      "Assigned             4\n",
      "Closed         5886253\n",
      "In Progress        364\n",
      "Open            133220\n",
      "Pending              2\n",
      "Name: conditions_apply, dtype: int64\n",
      "Status\n",
      "Closed    5886253\n",
      "Name: conditions_apply, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/42240476/python-pandas-groupby-filter-according-to-condition-on-values\n",
    "#dfgg = dfpk0.groupby(['Complaint Type', 'Borough']) \n",
    "#df1['conditions_apply'] = (df1.foo >= lower_bound) & (df1.foo <= upper_bound)\n",
    "#selection = df1.groupby('bar')['conditions_apply'].min()  # any False will return False\n",
    "#selection = selection[selection].index.tolist()           # get all bars with Trues\n",
    "#df1 = df1[df1.bar.isin(selection)]                        # make selection\n",
    "#df1.drop(columns=['conditions_apply'], inplace=True)      # drop newly made column\n",
    "\n",
    "dfpk0['conditions_apply'] = (dfpk0['Complaint Type'] == 'HEATING') & (dfpk0['Complaint Type'] == 'HEAT/HOT WATER')\n",
    "selection1 = dfpk0.groupby('Borough')['conditions_apply'].count()\n",
    "print(selection1)\n",
    "#https://stackoverflow.com/questions/10202570/find-row-where-values-for-column-is-maximal-in-a-pandas-dataframe\n",
    "print(selection1[selection1==selection1.max()])\n",
    "selection2 = dfpk0.groupby('Incident Zip')['conditions_apply'].count()\n",
    "display(selection2)\n",
    "print(selection2[selection2==selection2.max()])#print(selection2.max())\n",
    "selection3 = dfpk0.groupby('Incident Address')['conditions_apply'].count()\n",
    "#print(selection3) #Too many results????\n",
    "print(selection3[selection3==selection3.max()])#print(selection3.max())\n",
    "selection4 = dfpk0.groupby('Status')['conditions_apply'].count()\n",
    "print(selection4) #Too many results????\n",
    "print(selection4[selection4==selection4.max()])#print(selection3.max())\n",
    "dfpk0.drop(columns=['conditions_apply'], inplace=True)      # drop newly made column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Borough\n",
      "BRONX            1617956\n",
      "BROOKLYN         1739886\n",
      "MANHATTAN        1055225\n",
      "QUEENS            645971\n",
      "STATEN ISLAND      87584\n",
      "Unspecified       873221\n",
      "Name: conditions_apply, dtype: int64\n",
      "Borough\n",
      "BROOKLYN    1739886\n",
      "Name: conditions_apply, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Incident Zip\n",
       "10001.0     9031\n",
       "10002.0    32385\n",
       "10003.0    25574\n",
       "10004.0      329\n",
       "10005.0      440\n",
       "           ...  \n",
       "11692.0    12498\n",
       "11693.0     4768\n",
       "11694.0    10557\n",
       "11697.0      269\n",
       "12345.0        1\n",
       "Name: conditions_apply, Length: 202, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incident Zip\n",
      "11226.0    215709\n",
      "Name: conditions_apply, dtype: int64\n",
      "Incident Address\n",
      "34 ARDEN STREET    14298\n",
      "Name: conditions_apply, dtype: int64\n",
      "Status\n",
      "Assigned             4\n",
      "Closed         5886253\n",
      "In Progress        364\n",
      "Open            133220\n",
      "Pending              2\n",
      "Name: conditions_apply, dtype: int64\n",
      "Status\n",
      "Closed    5886253\n",
      "Name: conditions_apply, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#dfpk0['conditions_apply'] = (dfpk0['Complaint Type'] == 'HEATING') #| (dfpk0['Complaint Type'] == 'HEAT/HOT WATER')\n",
    "dfpk0['conditions_apply'] = (dfpk0['Complaint Type'] == 'HEAT/HOT WATER')\n",
    "selection1 = dfpk0.groupby('Borough')['conditions_apply'].count()\n",
    "print(selection1)\n",
    "#https://stackoverflow.com/questions/10202570/find-row-where-values-for-column-is-maximal-in-a-pandas-dataframe\n",
    "print(selection1[selection1==selection1.max()])\n",
    "selection2 = dfpk0.groupby('Incident Zip')['conditions_apply'].count()\n",
    "display(selection2)\n",
    "print(selection2[selection2==selection2.max()])#print(selection2.max())\n",
    "selection3 = dfpk0.groupby('Incident Address')['conditions_apply'].count()\n",
    "#print(selection3) #Too many results????\n",
    "print(selection3[selection3==selection3.max()])#print(selection3.max())\n",
    "selection4 = dfpk0.groupby('Status')['conditions_apply'].count()\n",
    "print(selection4) #Too many results????\n",
    "print(selection4[selection4==selection4.max()])#print(selection3.max())\n",
    "dfpk0.drop(columns=['conditions_apply'], inplace=True)      # drop newly made column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module 3: Quiz on Affected Areas\n",
    "* For the complaint types that you selected in the previous module that had at least 800,000 complaints logged, which borough had the highest number of complaints submitted?\n",
    "* For the complaint types that you selected in the previous module that had a total number that exceeded 800,000 complaints, which borough had the lowest number of complaints submitted?\n",
    "* For the complaint types that you selected in the previous module that had at least 800,000 complaints logged, which ZIP code had the highest number of complainted submitted?\n",
    "* For the complaint types that you selected in the previous module that had at least 800,000 complaints logged, the address 89-21 Elmhurst Avenue had the highest number of complainted submitted?\n",
    "* For the complaint types that you selected in the previous module that had at least 800,000 complaints logged, how many of the submitted tickets were closed?\n",
    "\n",
    "Based on the above groupby counts analysis, I had to guess some of the answers (particularly for the 1st one and for the last one because the correct answers seem far off than what my analysis revealed and I had to guess from the closest value or something like that. This time I was lucky, it all worked out for this particular quiz.\n",
    "\n",
    "**Correct answers are:** (1) BRONX, (2) Staten Island, (3) 11226, (4) False, (5) 2,133,331 complaints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: What Is the Relationship between Housing Characteristics and Complaints?\n",
    "Estimated time needed: 3 hours\n",
    "\n",
    "### Objective for Exercise:\n",
    "* Use your data visualization skills to visualize the data and extract meaningful patterns to guide the modelling process.\n",
    "\n",
    "The goal of this exercise is to find the answer to the Question 3 of the problem statement:\n",
    "\n",
    "Does the Complaint Type that you identified in response to Question 1 have an obvious relationship with any particular characteristic or characteristic of the Houses?\n",
    "\n",
    "In this exercise, use the 311 dataset.\n",
    "\n",
    "You also need to read back the PLUTO dataset from Cloud Object Store that you saved previously in the course. Use the PLUTO dataset for the borough that you already identified to focus on the last exercise.Ensure that you use only a limited number of fields from the dataset so that you are not consuming too much memory during your analysis.\n",
    "\n",
    "The recommended fields are Address, BldgArea, BldgDepth, BuiltFAR, CommFAR, FacilFAR, Lot, LotArea, LotDepth, NumBldgs, NumFloors, OfficeArea, ResArea, ResidFAR, RetailArea, YearBuilt, YearAlter1, ZipCode, YCoord, and XCoord.\n",
    "\n",
    "At the end of this exercise, you should determine whether the type of complaint that you have identified as the response to Question 1 has an obvious relationship with any particular characteristic or characteristics of the houses.\n",
    "\n",
    "\n",
    "\n",
    "### Module 4: Quiz on Correlation\n",
    "* Can you determine the age of some building from the PLUTO dataset? (0.0/5.0 points) - No, Yes, Not sure\n",
    "* Which of the following methodologies can you use to identify whether any relationship exist between the building characteristics and the number of complaints? (0.0/7.0 points) - Pearson Correlation, Feature Importance using Decision Tree, None of the above\n",
    "* The cardinality of the data in PLUTO dataset is at the same level as the complaint dataset? (0.0/7.0 points) - True or False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cardinality:\n",
    "Ref: https://brilliant.org/wiki/cardinality/ \n",
    "\n",
    "The cardinality of a set is a measure of a set's size, meaning the number of elements in the set. For instance, the set A={1,2,4}A = \\{1,2,4\\} A={1,2,4} has a cardinality of 333 for the three elements that are in it. The cardinality of a set is denoted by vertical bars, like absolute value signs; for instance, for a set AAA its cardinality is denoted ∣A∣|A|∣A∣. When AAA is finite, ∣A∣|A|∣A∣ is simply the number of elements in AAA. When AAA is infinite, ∣A∣|A|∣A∣ is represented by a [cardinal number](https://brilliant.org/wiki/cardinality/#cardinal-numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Borough', 'Block', 'Lot', 'CD', 'CT2010', 'CB2010', 'SchoolDist',\n",
       "       'Council', 'ZipCode', 'FireComp', 'PolicePrct', 'HealthCenterDistrict',\n",
       "       'HealthArea', 'SanitBoro', 'SanitDistrict', 'SanitSub', 'Address',\n",
       "       'ZoneDist1', 'ZoneDist2', 'ZoneDist3', 'ZoneDist4', 'Overlay1',\n",
       "       'Overlay2', 'SPDist1', 'SPDist2', 'SPDist3', 'LtdHeight', 'SplitZone',\n",
       "       'BldgClass', 'LandUse', 'Easements', 'OwnerType', 'OwnerName',\n",
       "       'LotArea', 'BldgArea', 'ComArea', 'ResArea', 'OfficeArea', 'RetailArea',\n",
       "       'GarageArea', 'StrgeArea', 'FactryArea', 'OtherArea', 'AreaSource',\n",
       "       'NumBldgs', 'NumFloors', 'UnitsRes', 'UnitsTotal', 'LotFront',\n",
       "       'LotDepth', 'BldgFront', 'BldgDepth', 'Ext', 'ProxCode', 'IrrLotCode',\n",
       "       'LotType', 'BsmtCode', 'AssessLand', 'AssessTot', 'ExemptLand',\n",
       "       'ExemptTot', 'YearBuilt', 'YearAlter1', 'YearAlter2', 'HistDist',\n",
       "       'Landmark', 'BuiltFAR', 'ResidFAR', 'CommFAR', 'FacilFAR', 'BoroCode',\n",
       "       'BBL', 'CondoNo', 'Tract2010', 'XCoord', 'YCoord', 'ZoneMap', 'ZMCode',\n",
       "       'Sanborn', 'TaxMap', 'EDesigNum', 'APPBBL', 'APPDate', 'PLUTOMapID',\n",
       "       'FIRM07_FLAG', 'PFIRM15_FLAG', 'Version'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Borough</th>\n",
       "      <th>Block</th>\n",
       "      <th>Lot</th>\n",
       "      <th>CD</th>\n",
       "      <th>CT2010</th>\n",
       "      <th>CB2010</th>\n",
       "      <th>SchoolDist</th>\n",
       "      <th>Council</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>FireComp</th>\n",
       "      <th>...</th>\n",
       "      <th>ZMCode</th>\n",
       "      <th>Sanborn</th>\n",
       "      <th>TaxMap</th>\n",
       "      <th>EDesigNum</th>\n",
       "      <th>APPBBL</th>\n",
       "      <th>APPDate</th>\n",
       "      <th>PLUTOMapID</th>\n",
       "      <th>FIRM07_FLAG</th>\n",
       "      <th>PFIRM15_FLAG</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11201.0</td>\n",
       "      <td>L118</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302 007</td>\n",
       "      <td>30101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000010e+09</td>\n",
       "      <td>11/26/2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BK</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>302</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11201.0</td>\n",
       "      <td>L118</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302 007</td>\n",
       "      <td>30101.0</td>\n",
       "      <td>E-231</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BK</td>\n",
       "      <td>1</td>\n",
       "      <td>7501</td>\n",
       "      <td>302</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11201.0</td>\n",
       "      <td>L118</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302 007</td>\n",
       "      <td>30101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000010e+09</td>\n",
       "      <td>03/04/2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BK</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3002.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11201.0</td>\n",
       "      <td>L118</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302 007</td>\n",
       "      <td>30101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BK</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>302</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11201.0</td>\n",
       "      <td>L118</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302 007</td>\n",
       "      <td>30101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18V1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Borough  Block   Lot   CD  CT2010  CB2010  SchoolDist  Council  ZipCode  \\\n",
       "0      BK      1     1  302    21.0     NaN        13.0     33.0  11201.0   \n",
       "1      BK      1    50  302    21.0  2000.0        13.0     33.0  11201.0   \n",
       "2      BK      1  7501  302    21.0  2000.0        13.0     33.0  11201.0   \n",
       "3      BK      3     1  302    21.0  3002.0        13.0     33.0  11201.0   \n",
       "4      BK      3     5  302    21.0     NaN        13.0     33.0  11201.0   \n",
       "\n",
       "  FireComp  ...  ZMCode  Sanborn   TaxMap  EDesigNum        APPBBL  \\\n",
       "0     L118  ...     NaN  302 007  30101.0        NaN  3.000010e+09   \n",
       "1     L118  ...     NaN  302 007  30101.0      E-231  0.000000e+00   \n",
       "2     L118  ...     NaN  302 007  30101.0        NaN  3.000010e+09   \n",
       "3     L118  ...     NaN  302 007  30101.0        NaN  0.000000e+00   \n",
       "4     L118  ...     NaN  302 007  30101.0        NaN  0.000000e+00   \n",
       "\n",
       "      APPDate PLUTOMapID FIRM07_FLAG PFIRM15_FLAG Version  \n",
       "0  11/26/2013          1         1.0          1.0    18V1  \n",
       "1         NaN          1         1.0          1.0    18V1  \n",
       "2  03/04/2016          1         1.0          1.0    18V1  \n",
       "3         NaN          1         1.0          1.0    18V1  \n",
       "4         NaN          4         1.0          1.0    18V1  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathPL = \"/Users/kpadhikari/Desktop/BigFls/DS_ML/PLUTO_for_WEB/\"\n",
    "filePL = \"BK_18v1\"\n",
    "dfpl0 = pd.read_pickle('{}/{}.pkl'.format(pathPL,filePL))\n",
    "display(dfpl0.columns)\n",
    "dfpl0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 5: Predict Complaint Types\n",
    "Estimated time needed: 3 hours\n",
    "\n",
    "### Objective for Exercise:\n",
    "* Use your machine learning skills to build a predictive model to help a business function more efficiently.\n",
    "The goal of this exercise is to do Model Development and Validation to find the answer to the Question 4 of the problem statement:\n",
    "\n",
    "Can a predictive model be built for future prediction of the possibility of complaints of the specific type that you identified in response to Question 1?\n",
    "\n",
    "In this exercise, you will use a feature-engineered dataset to determine whether a predictive model can be built to predict the complaint (of the Complaint Type that you decided to focus on in Week 2) by using past data.\n",
    "\n",
    "Using the best model, you need to predict the number of future complaints (of the Complaint Type that you decided to focus on in Question 1).\n",
    "\n",
    "\n",
    "\n",
    "### Module 4: Predictive Model for the Top Complaint Type\n",
    "* Can the model that you developed use Number of Floors in an address as a possible predictive feature? (0.0/7.0 points) - Yes, No\n",
    "* Although you are developing a model for a particular Complaint Type, you can use data for other complaint types to build the model? (0.0/7.0 points) - Yes, No\n",
    "* The features that you can use to build the model can come from which datasets? Select all that apply. (0.0/7.0 points) - Complaint dataset, PLUTO dataset, Any other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
